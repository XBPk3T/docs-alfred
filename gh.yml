# lang

- type: lang
  repo:
    - url: https://github.com/langserver/langserver.github.io
      des: LSP (Language Support Protocol)


- type: Compiler
  md: false
  repo:
    - url: https://github.com/goccy/p5-Compiler-Lexer
    - url: https://github.com/jamiebuilds/the-super-tiny-compiler
      des: 基于js实现的compiler，合计不到1000行代码
    - url: https://github.com/skx/monkey
      des: 用golang实现的interpreter，是用来学习compiler的好资料
    - url: https://github.com/chai2010/go-ast-book
    - url: https://github.com/wa-lang/ugo-compiler-book
      des: 同样是用golang实现的interpreter
    - url: https://github.com/jacksplwxy/JavaScript-compiler
    - url: https://github.com/robertkrimen/otto
      des: golang call js. otto is much easier to use than goja. 可以理解为golang实现的js interpreter.
  qs:
    - q: Compare compiler and interpreter?
    - q: java是编译型语言吗?
      x: java可以看作是 semi-compiled 语言。具体来说，解释型语言在运行时使用 sapi 解释执行 PHP 时，通过 zend 转 opcode 码，再转为机器码。而java 则是运行前 JVM 先转为 bytecode(其实也是 opcode)，运行的时候 JVM 再将 bytecode 转为机器码。
    - q: How compiler works? What are the roles of FE and BE? And how does each step works?
      x: 这里的 FE 指的是编译器对程序代码的分析和理解过程。它通常只跟语言的语法有关，跟目标机器无关。而与之对应的 BE 则是生成目标代码的过程，跟目标机器有关。
    - q: CST(Parse Tree), AST
    - q: Compare compilers such as (LLVM, goc, rustc, HHVM, v8(Ignition), tsc, cpython, pypy)? # arch, feats, philosophy
    - q: 怎么学习“编译原理”？
      x: 结论：对于新手，一开始就写编译器不一定是很好的选择，因为编译器的重点在于后端，而后端知识对于普通程序员而言用处不大。编译原理相关的知识，其实对普通程序员而言用处不大。因为compiler的重点是后端，而后端对普通开发没啥用。应该先学着写一个interpreter，然后再实现一个简单而完整的compiler，基本上就足够了。对我们来说主要要学习与lang相关的部分，也就是fe，至于be的IR和之类的东西，虽然通常这些才是真正的优化点，但是我们只需要了解即可。

    - q: AOT, JIT
    - q: 编译器优化有哪些方法？
      x: 常量传播 cp, 常量折叠 cf, 死码消除, 公共子表达式消除 CSE, 循环不变代码移动, BCE(Bounds Check Elimination)
    - q: inline
    - q: IPA, LTO, PGO, FDO
    - q: SSA, Alias Analysis, Dependence Analysis, Vectorization, Data-flow
    - q: 循环不变式
    - q: 熟悉不同编译优化技术，如 IPA、LTO、PGO、FDO 等；理解部分编译优化概念，如 SSA、Alias Analysis、Dependence Analysis、Vectorization、Data-flow




- type: Malloc
  md: true
  repo:
    - url: https://github.com/google/tcmalloc
      qs:
        - q: How TCMalloc works?
          x: (CCMalloc, local memory-pool(multi-level, BestFit, free-lock), RSEQ)
        - q: TCMalloc = CCMalloc(CPU Caching Malloc)
      des: google. TCMalloc是专门对多线并发的内存管理而设计的，TCMalloc主要是在线程级实现了缓存，使得用户在申请内存时大多情况下是无锁内存分配。整个 TCMalloc 实现了三级缓存，分别是ThreadCache(线程级缓存)，Central Cache(CentralFreeeList)，PageHeap(页缓存)，最后两级需要加锁访问。*TCMalloc 的核心思想是，切分内存多级管理降低锁粒度*(把内存切成几块，通过多级管理降低锁的粒度)；将可用的堆内存采用二级分配的方式进行管理：每个线程都会维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时，才会向全局内存池申请，以避免不同线程对全局内存池的频繁竞争。*使用多级缓存将对象大小分类，并按照类别使用不同的分配策略*。
    - url: https://github.com/microsoft/mimalloc
      des: ms. better perf than others. 在微软的云服务, 虚幻引擎中使用.
      qs:
        - q: mimalloc 是lock-free的吗? 怎么实现的呢?
    - url: https://github.com/jemalloc/jemalloc
      des: facebook.  来自FreeBSD的内存分配器，在Firefox和Rust里被使用.
      qs:
        - q: jemalloc 是怎么通过使用多个 arena 来减少多线程间锁竞争?
    - url: https://github.com/polarsignals/rust-jemalloc-pprof
      des: convert jemalloc data to pprof format
  des: Memory Allocator
  qs:
    - q: "***Compare memory allocators. (jemalloc, TCMalloc, PTMalloc(glibc默认Malloc), Mimalloc)***"
      x: |
        (mechanism, )
        两个方面，
        系统向：看内存管理库是如何管理空闲内存的
        用户向：看用户程序如何向内存管理库申请内存(释放大致相似，可以参考申请)

        应该从 锁机制、内存利用率、内存分配粒度和效率、内存碎片 这5点来进行比较，其实都是“切分内存多级管理”来提高内存利用率和减少内存碎片的（当然具体切分粒度不同，比如Jemalloc的small, large, huge分别是56KB, 4MB，而TCMalloc则是256KB, 1MB），最大的区别在于锁机制（为了减少锁竞争，提高并发）的优化，比如PTMalloc直接mutex了，而其他三个则都有针对性优化，分别选择了“多个arena”、“小对象pool+大对象spinlock”、“lock-free”。




- type: GC
  md: true
  repo:
    - url: https://github.com/mkirchner/gc
      des: zero-dependency garbage collection for C
  qs:
    - q: "***GC的核心需求（关注的指标）? 如何设计一个好的 GC 算法?***"
      x: CPU(utilization and throughput, locality), STW(time, freq), memory fragmentation
    - q: "***有哪些GC方案? MS存在哪些问题? 对 MS 有哪些优化方案? 请从“各种指标”比较这些方案***"
      x: |
        分别针对mark阶段和sweep阶段 (Mark Compact, semispace(cheney, baker), Incremental GC, 分代回收)
         MS 有以下问题：
         - heap 容易出现碎片
         - 破坏引用本地性（由于对象不会被移动，存活的对象与空闲空间交错在一起）
         - GC 时间与 heap 空间大小成正比
         - 在进行 GC 期间，整个系统会被挂起，即 stop-the-world
        需要说明一点，RC 类 GC 同样有前两个问题，但是对于 RC 来说，并没有好的优化措施来缓解。下面我们就来看追踪类 GC 是如何解决上述问题。
    - q: 请比较各种主流语言的GC机制？
      x: java, erlang, ruby, v8


- type: ASM
  repo:
    - url: https://github.com/capstone-engine/capstone
      des: Capstone 反汇编框架



---


- type: Config
  repo:
    - url: https://github.com/spf13/viper
      key: true
      des: 用viper的目的是是兼容本地配置和远程配置中心两种模式，因为可以无感从local切换到etcd. viper可以读取JSON, TOML, YAML, HCL, .env, and Java properties等格式的配置文件.
      qs:
        - q: viper合并多个viper文件
          d: https://mp.weixin.qq.com/s?__biz=MzAxMTA4Njc0OQ==&mid=2651453499&idx=1&sn=8f6234b80b49df964dfe5b1070c7fb35)
        - q: viper读取单文件中的多个separate yaml
    - url: https://github.com/jinzhu/configor
      des: configor相比viper
    - url: https://github.com/joho/godotenv
      des: config, dotenv, 只支持从 .env 读取配置
    - url: https://github.com/mikefarah/yq
      des: 相当于 jq 的 golang 实现, yq is a portable command-line YAML, JSON, XML, CSV, TOML and properties processor

# [JSON库性能对比及实现探究 - MySpace](https://www.hitzhangjie.pro/blog/2023-08-23-json%E5%BA%93%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%8E%A2%E7%A9%B6/)
- type: JSON
  repo:
    - url: https://github.com/bytedance/sonic
      des: used to replace encoding/json, convert JSON to map or struct. faster than jsoniter, easyjson and go-json. easyjson need to generate file, jsoniter 比 gabs 好用.
    - url: https://github.com/buger/jsonparser
      des: jsonparser 比 simplejson 好用，因为 simplejson 要用逗号 ok 处理各种问题，还没有ArrayEach和ObjectEach两种遍历方法
    - url: https://github.com/json-iterator/go
      des: jsoniter 21年就废弃了，但是仍然是比较常用的json解析库
    - url: https://github.com/jqlang/jq
      des: used to parse JSON, very helpful. also support brew install, better than gojq.
    - url: https://github.com/glideapps/quicktype
      des: 类似jq，也是用来处理JSON的，但是这个是类似 JSON-To-Go 这样的工具，但是支持几乎所有语言。
    - url: https://github.com/brimdata/zed
      des: zq is a lot like jq but is built from the ground up as a search and analytics engine based on the Zed data model. Since Zed data is a proper superset of JSON, zq also works natively with JSON.




- type: yaml
  repo:
    - url: https://github.com/go-yaml/yaml
      des: config, yaml
    - url: https://github.com/yaml/yaml-spec
      doc: https://yaml.org/spec/1.2.2/
      qs:
        - q: "*yaml的key的value怎么复用*"
          x: 变量(${site.url.user}), anchors(&, <<), 只复用字符串(&, *)
        - q: yaml数据类型强制转换
        - q: yaml多文件怎么parse
        - q: yaml多行字符串的几种用法，有啥区别
        - q: yaml多值映射怎么搞（?和:分别用array标明key和val）




---

# golang

- type: golang
  md: true
  repo:
    - url: https://github.com/golang/go
      qs:
        - q: How to handle error in golang?
        - q: "**code specs in golang?**"
        - q: shallow copy and deep copy in golang?
          x: (is shared memory address) (basic value, or ref value) value type and ref type (allocate to stack or heap)
        - q: web framework? In another word, Why gin is popular than others?
          x: middleware, router(LCP using TrieTree)
        - q: golang project structure? (internal, pkg, cmd, api)
        - q: How to troubleshot? golang services often report 502. What are the possible reasons?

        - q: How to use set/bitset in golang?
      qq:
        - topic: string
          url: https://github.com/golang/go/blob/master/src/runtime/string.go
          des: string 没有 cap，所以 string 是个只读类型，这点可以对比 slice（slice 就有 cap，所以可以修改）
          qs:
            - q: What happens when convert string to []byte in golang? How to optimize the conversion between string and []byte?
        - topic: strings
          url: https://github.com/golang/go/tree/master/src/strings
          qs:
            - q: EqualFold()
            - q: Compare(), Contains()(Any()/Func()/Rune()), Count(), Cut(), CutPrefix(), CutSuffix(), Fields()(Func()), HasPrefix()/HasSuffix(), Index()/LastIndex()(Any()/Byte()/Func()/Rune()), Join(), Map(), Repeat(), Replace()/ReplaceAll(), Split()/SplitAfter()/SplitN()/SplitAfterN(), ToLower()/ToUpper()/..., Trim()/...
            - q: golang strings Builder.
            - q: golang strings Reader.
            - q: golang 字符串匹配算法
              x: RK+FNV hash

        # https://github.com/golang/go/tree/master/src/slices
        - topic: slice
          url: https://github.com/golang/go/blob/master/src/runtime/slice.go
          qs:
            - q: 对 slice 赋值的具体实现？
              x: 底层数组是可以同时被多个 slice 指向，所以对一个 slice 的元素进行操作是有可能会影响到其他 slice 的
            - q: How to implement slice? =  (pointer, cap, len) Why cap? (相当于pool, 允许切片在一定范围内动态增长，避免频繁的内存分配操作) + How does slice create and expand?
              x: (growslice, oldCap < 256(threshold)指数增长, >256 for..., 更平滑)
            - q: Compare golang slice and redis list? 既然array完胜DLL，为啥redis还要用DLL实现list，而不是用array?
              x: 核心区别就是slice基于Array，redis基于DLL。空间复杂度（slice内存开销更小）、读操作时间复杂度（slice更快）、扩容机制（预分配/按需分配）和使用场景的区别都是表现。很明显，DLL相比array更适合写多读少的场景，然而redis...DLL和Array就像绿皮火车和高铁
            - q: slice pseudo shrink
              x: slice和map都是pseudo shrink，且回收都要靠GC来完成（事实上只要是带GC的语言都是pseudo shrink，都是靠GC完成回收）三种：c/cpp这种无GC的真缩容、带GC的都是伪缩容、rust
            - q: golang slice是否原生支持并发? Why?
              x: 如果定义了len，并发读是安全的，因为一旦定义len，就不能在不重新分配底层数组的情况下改变。但是并发写操作仍然是不安全的。
          use:
            - url: https://go.dev/play/p/i7uq2OxZ82g
              des: 删除slice中的元素
            - url: https://gist.github.com/hxhac/14753a2822ef1d060077a78c38fba355
              des: How to remove element from slice of struct?
            - url: https://gist.github.com/hxhac/20fc39ea8fcc6eaee461e341d473f540
              des: append 无法修改传入参数 slice？
            - url: https://gist.github.com/hxhac/14d35f334ae25151a4795e720daec2b8
              des: SliceToMapSlice() struct切片转为map切片
            - des: golang 怎么用双向链表实现双向队列？
            - des: 怎么优化`[]Foo`转`[]Bar`这种问题？
            - des: golang slices pkg. Clip(), Clone(), Grow(), Insert(), Replace(), Reverse(), Func(BinarySearch(), Compact(), Compare(), Contains(), Delete(), Equal(), IsSorted(), Max(), Min(), Index(), Sort())
            - des: Compare slice concat methods? append(), copy(), slices.Concat()
            - des: Delete, DeleteFunc, Replace, Compact, CompactFunc等函数，缩容操作之后原slice的被缩掉的那部分数据被修改为0

        - topic: map
          url: https://github.com/golang/go/blob/master/src/runtime/map.go
          qs:
            - q: map 在遍历时，并不是从 0 号 bucket 开始遍历，而是从一个随机 bucket 的随机 cell 开始遍历
            - q: 为什么 map 增删改会触发标志位，导致 panic？
            - q: 通过 hash 函数获取目标 key 的哈希，哈希和数组的长度通过位运算，获取数组位置的索引。遍历 bmap 里的 key，和目标 key 对比获取 key 的索引。根据 key 的索引通过计算偏移量，获取到对应 value。
              x: 用位运算转换求余操作，m % n，当 `n = 1 << B` 的时候，可以转换成 `m & (1 << B - 1)`
            - q: tophash 数组的设计加速了 key 的查找过程，tophash 也被复用来标记扩容操作时的状态
            - q: mapassign
            - q: 双桶, mapextra 用来优化 GC,
            - q: hmap struct 中有哪些是主要字段？hmap 的 extra 有啥用？
            - q: hmap 中的负载因子 B 是什么？为什么是 6.5？负载因子如何影响map的性能？溢出率
              x: LB是最大可容纳元素数，用来衡量当前哈希表中空间利用率的核心指标。是因为负载因子太大了，会有很多溢出的桶；太小了，就会浪费很多空间。
            - q: bmap 是什么？为什么golang的map还需要bmap？ bucket
            - q: map扩容机制
              x: 查看 hashGrow() 以及 渐进式扩容 growWork(). 当 map 的负载因子超过预设的阈值（通常是 6.5）或者溢出桶（overflow buckets）数量过多时，Go 会触发 map 的扩容机制。
            - q: map 有缩容机制吗？
              x: |
                伪缩容，因为map 的扩缩容的主要区别在于 hmap.B 的容量大小改变，而缩容由于 hmap.B 压根没变，内存空间的占用也是没有变化的（具体来说就是，在删除元素时，并不会释放内存），所以一定不要往 golang 的 map 中塞入太多数据。

                若是扩容，则 bigger 为 1，也就是 B+1。代表 hash 表容量扩大 1 倍。不满足就是缩容，也就是 hash 表容量不变。可以得出结论：map 的扩缩容的主要区别在于 hmap.B 的容量大小改变。而缩容由于 hmap.B 压根没变，内存空间的占用也是没有变化的。
            - q: golang中map进行 读操作 的具体过程(查找数据的具体流程)?
              x: key 经过 hash 后共 64 位，根据 hmap 中 B 的值，计算它到底要落在哪个桶时，桶的数量为 2^B，如 B=5，那么用 64 位最后 5 位表示第几号桶，在用 hash 值的高 8 位确定在 bucket 中的存储位置，当前 bmap 中的 bucket 未找到，则查询对应的 overflowbucket，对应位置有数据则对比完整的哈希值，确定是否是要查找的数据。如果当前 map 处于数据搬移状态，则优先人 oldbuck-ets 查找。
            - q: golang中map进行 写操作 的具体过程?
            - q: golang map是怎么解决hash collision的? Why?
              x: CA

            - q: 用hashtable实现hashmap，和用search-tree实现hashmap，有啥区别？为啥golang, java, redis使用hashtable实现map，而cpp使用RBT实现map？
              x: 这类问题的本质实际上还是比较hashtable, RBT和trie-tree
            - q: "***Compare golang map and redis HashMap?***"
              x: 双 table、渐进式 rehash、扩容条件、缩容条件、bgsave、COW 机制
          use:
            - des: "***golang 修改map中的元素?***"
            - des: How to convert []map to []struct?
            - des: map[string]interface{} to struct
            - des: 怎么用map实现并发读写?  # 比较 "mutex+map" 和 sync.Map
            - des: How to check efficiently if a map contains a key in Go? # comma ok idiom (whether err/kv/chan exist, datatype detect)
            - des: How to check whether the key of map exists?
            - des: "***手写实现 golang 中 map 的有序查找，且支持 add、支持 delete、支持迭代？构造一个辅助 slice***" # How does map read data? And the specific process for finding key, assigning key, deleting key and traversing key?
              url: https://gist.github.com/hxhac/ddab2b9d20186ff27ec0e159e835e779


        - topic: sync.Map
          url: https://github.com/golang/go/blob/master/src/sync/map.go
          qs:
            - q: "***How does sync.Map implemented? 能否认为sync.Map是read-preferring呢?***"
              x: 使用了读写分离来去保证线程安全的，sync.map 的数据结构分为读 map(read)、写 map(dirty)、还有mutex以及一个记录穿透次数的值(misses)。具体实现是每次读取都会先读取读部分的 kv，没有则去读写部分的 kv(操作写部分时都会上锁)。当穿透到写部分的次数大于写部分的长度时，就会将写部分同步到读部分，并且把写部分清空。所以多协程下一般都会先打到无锁的读部分，这能保证读取性能。
            - q: "***sync.Map feats? 逐一说明 double-checking, 读写分离和动态调整, 延迟删除(在 sync.Map 中删除一个键值对实际上只是将其标记为删除，真正的删除操作会在 read 升级时进行，这样可以减少锁的持有时间。), read-preferring ***"
              x: |
                read map(atomic.Value), dirty map(mutex) 之间互相转化，分别在什么样的时机下会进行？nil, normal
                entry的p可能的状态，有哪些？
                entry 的 p 可能的状态包括 nil（空值）、指向正常数据的指针、指向脏数据的指针、锁定状态的指针、等待状态的指针和过期状态的指针。


            - q: Store(), Load(), Delete() 各自的实现
            #        - "***Why is map not thread-safe? How to make map achieve concurrent reading and writing?***"
            - q: "***Why is sync.Map rarely used in golang? What's the pros and cons?***"
              x: sync.Map适合读多写少的场景（...），这就是“使用sync.Map时需要考虑读写比”这个说法
            - q: pseudo shrink leads to mem-leak, How to resolve?


        - topic: golang compiler
          url: https://github.com/golang/go/tree/master/src/cmd/compile
          qs:
            - q: golang compiler directives?
              x: (linkname, noescape, nosplit, noinline, norace, notinheap), go doc compile
            - q: Why golang compiler using SSA (to optimize compiler backend)? # (BCE+CSE)
            - q: "steps of golang compile?"
              x: fe(lex, syntax, semantic analysis), be(IR, optimization, code-generation, asm(Plan9))  compiler的两个阶段中的be，其实就是AST转IR，再转Plan9 asm code，最后再转成机器码。那么实际上这里的Plan9实际上就是asm
            - q: Compare cpp and golang memory management.
              x: (arena, heap, chunk, memory)
            - q: escape analysis



        - topic: golang malloc
          url: https://github.com/golang/go/blob/master/src/runtime/malloc.go
          des: 在我看来，golang内存管理由TCMalloc+compiler逃逸分析+GC组成。其中compiler解决掉了栈内存的问题，stack由compiler自动分配和回收（比如说栈上的函数参数、局部变量、调用函数栈），这些都是自动随着函数创建而分配，执行完成而销毁。而heap则有两部分，其中heap内存分配由golang实现的类似TCMalloc的malloc来管理，而heap回收则由GC实现。
          qs:
            - q: What about golang memory management? (mutator, allocator, collector)
              x: 当 mutator 申请内存时，会通过 allocator 申请新内存，而 allocator 会负责从堆中初始化相应的内存区域
            - q: (stack(compiler)+heap(TCMalloc+GC))
            - q: What's mspan, mcache, mcentral, mheap?
              x: |
                (8kb, DLL)
                - mcache(tiny allocs， 线程缓存，为每个逻辑处理器 P 提供一个本地 span 缓存, < 16kb)
                - mcentral(中心缓存，被所有的逻辑处理器 P 共享)
                - mheap(large allocs, 页堆，可以认为是 golang 程序持有的整个堆空间，mheap 全局唯一, > 32kb)



          # gc.go - 这个文件包含了垃圾回收的主要逻辑和控制流程。
          # mheap.go - 管理堆内存的源码，包括内存的分配和回收。
          # mgc.go - 包含了与并发垃圾回收相关的后台标记和清扫工作。
          # gcbss.go - 包含了BSS段的垃圾回收逻辑。
          # gcmark.go - 包含了标记阶段的实现细节。
          # gcsweep.go - 包含了清扫阶段的实现细节。
        # https://github.com/golang/go/tree/master/src/cmd/compile/internal/gc
        - topic: golang GC
          url: https://github.com/golang/go/blob/master/src/runtime/mgc.go
          qs:
            - q: 内存屏障是啥？为啥有了MESI还需要内存屏障？
            - q: golang GC的大概执行过程（四个阶段）？STW 发生在什么时候？
            - q: golang如何实现的“并发三色标记扫描”？
            - q: golang GC现在还存在哪些问题
            - q: golang GC有哪些优化？为何需要辅助标记和辅助清扫？
            - q: golang为什么选择使用三色标记，而不是分代或者复制？
            - q: 什么时候启动GC？
            - q: 通过哪些指标来判断要启动GC？
            - q: GC应该如何与scheduler进行交互？
            - q: 如何暂停一个mutator线程足够长时间，以扫描器stack？
            - q: 如何表示white、grey和black三种颜色来实现高效地查找、扫描grey对象？
            - q: 如何知道roots对象在哪里？
            - q: 如何知道一个指向对象的指针的位置？
            - q: 如何最小化内存碎片？
            - q: 如何解决cache性能问题？
            - q: heap应该设置为多大？
            - q: 怎么调优golang GC？

        - topic: context
          url: https://github.com/golang/go/tree/master/src/context
          qs:
            - q: What's context? usage scenario? # cancel goroutine, store kv,
            - q: How to implement context?
            - q: How to use? # context.WithValue(), WithCancel(), WithTimeout(), WithDeadline()
            - q: How to get current goroutine's ID?
            - q: 有哪些常用的runtime库?
            - q: context misuses? How to avoid? What are the usage spec for using context?
        - topic: atomic
          url: https://github.com/golang/go/tree/master/src/sync/atomic
          qs:
            - q: What's atomic? Why and When to use atomic, rather than sync package?
            - q: How to use? (Add/(Store+Load)/CAS)
            - q: atomic是怎么实现的？
        - topic: GMP
          url: https://github.com/golang/go/tree/master/src/runtime
          qs:
            - q: "***GMP分别是啥? 为啥协程(G)和线程(M)是M:N的映射关系? G和M直接绑定就可以了，为什么要有P (抢占式调度器相较于之前调度器的优势?)? golang异步抢占的整体流程???***"
              x: |
                多对一的缺点是OS 无法感知到用户态的线程，所以可能造成一个线程被阻塞，导致整个进程被阻塞挂掉，M:N 模型就解决了这个问题。
                sched
                Runtime 起始时会启动一些 G：垃圾回收的 G，执行调度的 G，运行用户代码的 G；并且会创建一个 M 用来开始 G 的运行。随着时间的推移，更多的 G 会被创建出来，更多的 M 也会被创建出来。

            - q: work stealing, handoff 分别是啥? handoff为啥要释放掉线程绑定的processor，转移给其他空闲thread执行呢? 按理说，thread和processor不是一一绑定的嘛?
              x: |
                都是为了“复用线程”，避免频繁创建和销毁thread

                还是用公司项目做类比，如果你们项目组本身没有什么任务（M上没有G），那么就从其他项目组抢任务。这个就是work stealing嘛。如果你们项目组因为某个任务阻塞掉了（需要注意的是，这里实际上对应的thread的blocked或者waiting状态，而不是直接挂掉了），那就把这个项目所绑定的项目经理（也就是Processor，用来调度任务）释放掉，把这个项目经理让给其他项目组。
            - q: "***goroutine, type and state***"
              x: 要搞清楚goroutine的type和state是不同的，type分为buffered chan和unbuffered chan，state则分为nil, active, closed三种
            - q: "***golang 内存泄漏的常见场景? goroutine leak? How to detect memory leak? How to find and fix?***"
              x: |
                goleak

                subslices, substring, not reset pointers, hanging goroutines, time.Ticker

            - q: GMP主动调度有哪些抢占时机?
              x: GC(GC的STW是一个GMP主动调度的抢占时机), syscall(goroutine执行syscall时，Go调度器会主动选择一个合适的时机来调度其他可运行的goroutine), 时间片用尽（类似kernel里CFS tick的时候，也是最常见的抢占时机）
            - q: goroutine OOM了，会发生什么？怎么处理？
          use:
            - des: Can you implement a lock-free queue using atomic in golang?
            - des: "***How to limit the max number of goroutines in golang?***"
            - des: "*How to control goroutine numbers?*" # chan+wg, ants
            - des: "*How to close goroutine?*" # chan, context
        - topic: struct
          url: https://github.com/golang/go/blob/master/src/reflect/type.go
          qs:
            - q: golang 匿名结构体 # 在某些场景下，比struct或者map[string]interface都更实用
            - q: misuse # private fields, pass pointer(other than pass value)
            - q: field alignment # CPU clock cycle, minimize the size of the struct(in memory), Data Types in golang(bool(1), int/map(8), string(16), slice(24))
            - q: tag (name, omitempty, -), What other tags are there? # (json, xml, protobuf, yaml, gorm, mapstructure)
            - q: How tag works? # reflect
          use:
            - url: https://go.dev/play/p/kIDCniLJxek
              des: struct的omitempty
            - url: https://go.dev/play/p/KlmCr1-01Ng
              des: struct的tag -
        - topic: channel
          url: https://github.com/golang/go/blob/master/src/runtime/chan.go
          qs:
            - q: "***How to implement chan? data structure?***"
              x: |
                (ring buffer, FIFO) (hchan, )
                chan 收发遵循先进先出 FIFO 的原则
                chan 中包括 buffer、sendx 和 recvx 收发的位置 (ringbuffer 记录实现)、sendq、recv。当 chan 因为缓区不足而阻塞了队列，则使用DLL存储
            - q: Compare channel types(buffered chan, unbuffered chan)? # capacity, is block
            - q: "***What happens when close/read/write a nil/closed/normal chan?***"

            - q: channel patterns (pipeline, fan-in, fan-out, barrier, (future, workers-pool, pub/sub, or-chan))? pros and cons? Please implement.
              x: |
                - barrier模式: 用来阻塞直到聚合所有 goroutine 返回结果
                - pipeline模式: 与 barrier 的区别在于 pipeline 是有序的; 可以让一组线程按照顺序并发或者串行的执行;
                - future模式: 在异步处理中称为 promise 模式，具体来说，就是主 goroutine 不等子 goroutine 执行完就直接返回了，然后等到执行完成之后再去取结果
                - workers-pool模式: 高并发任务
                - pub/sub模式: 一种消息通知模式，发布者发送消息，订阅者接收消息
                - or-chan: 当多个 chan 合并成一个，关闭任意一个，关闭全部

            - q: 为啥不同状态的channel在执行读写操作时，会阻塞或者panic呢？怎么理解呢？

            - q: Compare barrier and fan-in?
            - q: select...case # random select(avoid hungry), timeout, default
            - q: select for loop
            - q: select, deadlock
            - q: How does "select" works? # OSELECT, OCASE
            - q: "***How to loop chan? Iterate over Channel in Golang***" # (for, )
            - q: 如何检查channel是否已满？
            - q: 如何使用select语句在多个channel上进行连续读取？
            - q: select语句如何实现超时机制？
          use:
            - des: 事实上，chan的使用相当简单。比如说最简单的pipeline模式吧，先定义两个chan的变量，作为in和out（也可以理解为this和next），然后写两个go func，第一个pub，第二个sub。注意两个go func里都要close chan。最后再把outChan循环处理一下就可以了。几个需要注意的地方：go func里最好 `defer close()`，而不是直接在func最后写close。其次，最需要注意的就是最后的循环，也就是“遍历 chan”，无非是普通for循环和for...select两种。肯定推荐使用for...select，可以做更多类似超时、默认、ticker等自定义操作。
        - url: https://github.com/golang/go/blob/master/src/sync/mutex.go
          topic: sync.Mutex{}
          qs:
            - q: "***How to implement mutex in golang? mutex running mechanism?***" # (sema), critical section 临界区. mutex 底层使用 atomic 包中的 CAS 操作来保证加锁时的原子性，CAS 底层就是通过 LOCK+CMPXCHGL 汇编指令实现的
            - q: mutex 的 sema 和 state 有什么用？ # mutex 对 goroutine 的阻塞操作和唤醒操作就是通过 sema 实现的，具体来说，runtime 维护了一个全局的变量 semtable，里面有全部的信号量，每个信号量都由一个变量地址指定
            - q: mutex的normal, starvation两种模式
            - q: misuses # lock/unlock not in pairs(deadlock, panic), nocopy(vet), non-reentrant(goid)
            - q: Implement spinlock? # CAS+runtime.Gosched()
            - q: 为啥 golang 的 mutex 不可重入呢？ # 为了避免deadlock
            - q: What's noCopy in golang? and why are mutex, rwmutex, wg, pool and cond all noCopy? (cuz all of these is based on )
          use:
            - url: https://go.dev/play/p/lw5jSOdpRqh
              des: mutex的拓展实现，TryLock(), IsLocked(), IsWoken(), IsStarving(). How to check if a mutex is locked?
              sol: 其实就是提取 state 字段的中数据，state是个int32类型的数据，从0~3分别代表 mutexLocked, mutexWoken, mutexStarving, mutexWaiterShift
            - url: https://gist.github.com/hxhac/3e7996df3159d6862c2e833ccd0d2120,
              des: How to implement ReentrantMutex? Why mutex not support ReentrantLock in golang?
              sol: 关键是获取goid。mutex 不是可重入锁，因为 mutex 的实现本身就是没有记录哪个协程持有锁，所以当然是不可重入的。所以想实现可重入锁，核心就是记录持有锁的协程。方法无非是两种，获取 goid，或者直接使用 uuid 进行标识。
            - des: "*怎么用 mutex 实现自旋锁？*"
              sol: spinlock 和 TryLock 的实现很类似，都是加个了 CAS 操作
            - des: 用 mutex 实现一个带 timeout 的锁？超时直接解锁

        - url: https://github.com/golang/go/blob/master/src/sync/rwmutex.go
          topic: sync.RWMutex{}
          qs:
            - q: What's RWMutex? How to implement?
              x: |
                (readers-writers problems) rwmutex=mutex+conditional variables+sema
                struct (w, writerSem, readerSem, readerCount, readerWait, rwmutexMaxReaders)
                starvation
                读锁获取锁流程? 释放读锁流程? 写锁获取锁流程? 释放写锁流程?


            - q: (read-preferring, write-preferring)
            - q: Compare the perf between mutex and rwmutex in golang? # read-write ratio
            - q: misuses? # similar with mutex(no-copy, non-reentrant)

        - url: https://github.com/golang/go/blob/master/src/sync/waitgroup.go
          topic: sync.WaitGroup{}
          qs:
            - q: What's wg? How to implement wg? # (state1(counter, waiter, sema), noCopy), align64. 64bit(8bytes) 的值分成两段，高 32bit 是计数值，低 32bit 是 waiter 的计数
            - q: How to implement (Add/Done/Wait)? # Done() similar with Add()
            - q: Add、Done 和 Wait 三个方法的具体实现？(自己看源码)
            - q: WaitGroup 内部怎么实现无锁操作？(自己看源码)
        - topic: interface
          qs:
            - q: How to implement interface in golang? (eface, iface)
              x: |
                eface就是empty interface, iface则相反. type内置了各种数据结构, data指针。这两个结合之后，其实很类似string的数据结构。iface的数据结构也很类似，区别在于itab，itab是把eface的type又包了一层。

                - type 接口自身的元信息
                - hash _type里也有一个同样的hash，此处多放一个是为了方便运行接口断言
                - fun 函数指针，指向具体类型所实现的方法
        - topic: defer
          qs:
            - q: When to use? # Delayed call, LIFO, recover panic, close(file, conn, mutex, chan, goroutine...)
            - q: defer Close(), EIO. How to avoid?
        - topic: golang http pkg
          url: https://github.com/golang/go/blob/master/src/net/http/client.go
          use:
            - url: https://mp.weixin.qq.com/s?__biz=MzkyOTU5MTc3NQ==&mid=2247499280&idx=2&sn=5437a3549daef00178845766519a4261
              des: 使用golang的HTTP请求时，怎么正确地给每个长连接请求设置timeout?, 应该加在http.Client的Timeout中，而不是http.Transport中
        - url: https://github.com/golang/go/tree/master/src/html/template
          topic: html/template
          use:
            - url: https://go.dev/play/p/d8kzvdR5kjy
              des: html/template用法
            - url: https://github.com/x1ah/gena/blob/master/generators/webstack.go#L19
              des: golang中渲染html的方法，用template而不是自己手动渲染html
        - url: https://github.com/golang/go/tree/master/src/reflect
          topic: reflect

        - url: https://github.com/golang/go/blob/master/src/sync/once.go
          topic: sync.Once{}
          qs:
            - q: usage scenarios # (delay init(lazy loading) in construct)
            - q: implement # atomic(CAS, preliminary check) + Double-checked locking, singleton
            - q: sync.Once 是如何保证只执行一次的语义的？ # sync.Once 使用内部的 Mutex 来保证并发安全。它首先尝试通过原子操作检查 done 标志是否为 0，如果是，则进入慢路径（slow path），在慢路径中，它会加锁并再次检查 done 标志。如果仍然为 0，则执行函数并设置 done 标志为 1。这个过程中使用 defer 来确保即使函数执行过程中发生 panic，done 标志也能被正确设置。
            - q: 为什么 sync.Once 的 Do 方法中没有使用 CAS 原子判断？ # 使用 CAS 原子判断虽然看似能提高性能，但它无法保证在 o.done 变为 1 时，传入的函数 f 已经完全执行。sync.Once 不仅要保证只执行一次，还要保证其他 goroutine 在 Once.Do 返回时，f 函数的执行已经完成。
            - q: sync.Once 的使用场景有哪些？ # sync.Once 适用于需要延迟加载或单次初始化的场景，例如加载配置、初始化日志系统、创建单例对象等。它可以确保即使在高并发环境下，这些操作也只被执行一次，从而避免资源浪费和潜在的竞态条件。
        - url: https://github.com/golang/go/blob/master/src/sync/pool.go
          topic: sync.Pool{}
          qs:
            - q: sync.Pool 实现原理? # (lock-free) (local+victim) *保存和复用临时对象，减少内存分配，降低 GC 压力*，但是这些对象会被 GC 定期清除，所以不要用来存数据库连接之类的长连接，*sync.Pool 最常用的场景就是 buffer 池*(缓冲池)(因为 byte slice 是经常被创建和销毁的一类对象，使用 buffer 池可以缓存已经创建的 byte slice)。Pool 使用两层回收策略 (local+victim) 避免性能波动。
            - q: sync.Pool 是怎么实现 thread-safe 的? # (temp data, GC, buffer pool) Pool 本身就是线程安全的 (可以并发地调用它的方法存取对象)，并且是lock-free的，因为给每个 P 都分配 cache 数组，这样 cache 结构就不会有并发安全问题
            - q: How to use it?
            - q: misuses?
            - q: sync.Pool 内存池的内容会被清理吗？清理会造成数据丢失吗？
            - q: 只 Get 不 Put 会造成内存泄漏吗？
        - topic: sync.Cond
          des: 从开发实践上，我们真正使用 Cond 的场景比较少。因为一旦遇到需要使用 Cond 的场景，我们更多地会使用 chan 的方式去实现 wait/notify 机制，因为那才是更地道的 golang 的写法。对于简单的 wait/notify 场景，比如等待一组 goroutine 完成之后继续执行余下代码，我们会使用 waitgroup 实现，使用简单还不容易出错。

        - url: https://github.com/golang/go/tree/master/src/log/slog
          topic: slog
          des: log相比于slog没有日志分级、没有结构化日志、没有拓展性
          use:
            - url: https://colobu.com/2024/03/10/slog-the-ultimate-guide/
            - url: https://gist.github.com/hxhac/d39d47d2f967884ff09856273ef45820

        - url: https://github.com/golang/go/tree/master/src/net/http/httptrace
          topic: golang httptrace pkg.

        - url: https://github.com/golang/go/tree/master/src/regexp
          topic: golang regex
          use:
            - url: https://go.dev/play/p/LUH7Ib-QvqY,
              des: regexp
            - url: https://github.com/1jz/wisa/blob/master/wisa.go,
              des: wisa对regexp的使用，MustCompile()
        - url: https://pkg.go.dev/encoding/json
          topic: encoding/json
          use:
            - url: https://go.dev/play/p/-J16F7AmMXO
              des: json反序列化时
            - url: https://go.dev/play/p/DjDLYB8ES5n
              des: JSON pointer
            - url: https://gist.github.com/hxhac/0e7a917e8b07c9f6f5529d62fa4e80f7
              des: JSON handle
            - des: Golang 中使用 JSON 时如何区分空字段和未设置字段？具体来说，struct tag 如果设置为omitempty执行update操作时会把该field设置为空字符串，导致出错，怎么避免该问题？如果给该field赋值恰好等于默认空值的话，Marshal后为nil，又怎么解决该问题？ # 给该field加指针类型

            # [[转]Golang 中使用 JSON 的小技巧](https://colobu.com/2017/06/21/json-tricks-in-Go/)
            - des: 怎么临时忽略struct空字段，忽略指定field，或者临时添加额外的字段，一个json切分成两个struct，临时改名struct的字段，又或者临时粘合两个struct？
            - des: 用字符串传递数字
            - des: 用jsoniter 模糊模式实现容忍字符串和数字互转，或者容忍空数组作为对象？
            - des: json 数字精度丢失问题
            - des: json 包的时间格式问题
            - des: Precision is lost when deserializing json in golang, How to resolve?
            - des: How to convert between struct, map and json in golang?
            #    - 使用 MarshalJSON支持time.Time
            #    - 使用 RegisterTypeEncoder支持time.Time
            #    - 使用 MarshalText支持非字符串作为key的map
            #    - 使用 json.RawMessage
            #    - 使用 json.Number
            #    - 使用 jsoniter 统一更改字段的命名风格
            #    - 使用私有的field


        - topic: golang net pkg.
          url: https://github.com/golang/go/blob/master/src/runtime/netpoll.go
          qs:
            - q: golang的网络模型？存在什么问题？netpoll和gnet做了什么优化？
        - url: https://github.com/golang/go/tree/master/src/testing
          topic: golang test
          des: 其中包括了对benchmark和fuzz的实现
          qs:
            # test
            - q: gotest # testdata, table-driven, Tags
            - q: 四种测试函数？注意事项？
            - q: Which unittest lib should we use? # gotest, testify, goconvey
            - q: testdata, .input, .golden
            - q: 如果需要测试辅助函数 (无状态函数), 就用`testify`进行`table driven`测试。如果需要测试业务逻辑，就用`goconvey`, 更有层次感。
            # benchmark
            - q: benchmark, metrics
            - q: benchmark 有哪些注意事项？ # b.ResetTimer(), b.StopTimer(), b.StartTimer()
            - q: 有哪些常用方法？ # b.ReportAllocs(), b.SetBytes()
            - q: benchmark 的返回参数都是啥意思？
            # fuzz
          use:
            - des: 如何重复执行 gotest？怎么重复执行某个或者某组测试用例？ # Don't use build tags for integration tests. use env replaced with build tags in golang test 不够显式
            - des: go test 如何禁用缓存？  # 使用 -count=1 flag 禁用，不要GOCACHE=off，否则会影响 go.mod

        - topic: filepath
          url: https://github.com/golang/go/tree/master/src/path/filepath
          des: Use filepath.Walk() instead of for...range folders, `path` equals to `filename := dir + sep + fi.Name()`
        - topic: golang errors pkg.
          url: https://github.com/golang/go/tree/master/src/errors
          qs:
            - q: "***处理 golang Error?***"
              x: 首先要分清楚Error, Exception和panic。go 源代码很多地方写 panic, 但是工程实践业务代码不要主动写 panic，理论上 panic 只存在于 server 启动阶段，比如 config 文件解析失败，端口监听失败等等，所有业务逻辑禁止主动 panic，所有异步的 goroutine 都要用 recover 去兜底处理。
            - q: 写一堆 `err != nil` 的问题 # 自定义错误记得要实现 error 接口
            - q: 怎么 wrapping 多个 errors？
            - q: 操作数据库时，比如 dao 层中遇到一个 sql.ErrNoRows 时，是否应该 wrap 这个 error，抛给上层；为什么？应该怎么做？请写出代码
              x: 总结一下，错误处理的原则就是：错误只在逻辑的最外层处理一次，底层只返回错误。底层除了返回错误外，要对原始错误进行包装，增加错误信息、调用栈等这些有利于排查的上下文信息。
            - q: golang的哨兵错误、自定义错误以及隐式错误三种
              x: ???

          use:
            - des: errors.Join()使用场景 # 比如说对并发task的error的统一收集，类似ErrorGroup
            - des: # 如果需要格式化错误，*应该用`fmt.Errorf(...)`代替`errors.New(fmt.Sprintf(...))`*；如果不需要格式化错误，直接`errors.New()`即可.
            - des: golang中用errors.New(), errors.Is() 怎么判断err是否相同？ # 需要注意
            - des: 不要直接return err，应该使用fmt.Errorf()自定义error，自己封装一个newError
              url: https://akavel.com/go-errors

        - topic: slog
          doc: https://colobu.com/2024/03/10/slog-the-ultimate-guide/

        - topic: golang generics
          qs:
            - q: 类型参数 (类型形参param 和类型实参arg)
            - q: 类型集 Type Set
            - q: 类型union
            - q: 泛型receiver
            - q: What does the tilde ~ do? (~T) # 表示所有底层类型是 T 的类型，比如~string表示所有底层类型是 string 的类型集合。后面只能是基本类型。
            - q: 约束类型推断
            - q: generics是否有性能问题？
      cmd:
        - c: go get -u
          x: 更新项目依赖到最新版本
        - c: go clean -modcache
          x: 清除模块缓存
        - c: go build -gcflags '-m -l' main.go
          x: 使用 go build -gcflags='-m=2' 查看编译器报告，来查看是否发生了内存逃逸。(-m 最大为 4，通常使用 2，否则返回信息太多)
        - c: go test ./...
          x: 运行当前文件夹下的所有 case
        - c: go test foo/...
          x: 指定目录下的所有 case
        - c: go test foo...
          x: 指定前缀的所有 case
        - c: go test ...
          x: 运行 GOPATH 下的所有 case ⚠️
        - c: go test -cover
          x: 代码覆盖率
        - c: go test -covermode=set
          x: 覆盖测试模式，有三种值 set,count,atomic, 其中 set 代表的是这个语句运行吗？count 代表的是这个语句执行多少次，atomic 代表的是多线程正确使用的，耗资源的。
        - c: go test -v -coverprofile=c.out && go tool cover -html=c.out -o=tag.html
          x: 生成测试覆盖率报告，并转化为 html 文件进行预览
        - c: go test -bench=.
          x: 基准测试
        - c: go test -benchtime=3s -bench=.
          x: 在持续时间 3s 内运行每个基准测试
        - c: go test -benchmem -bench=.
          x: 打印基准测试时的内存分配
        - c: go test -count=2 -bench=.
          x: 执行指定次数的基准测试，在 - count=1 时相当于禁用缓存
        - c: go test -cpu=1 -bench=.
          x: 设置指定的 cpu 数量来进行基准测试，可以指定多个不同的 cpu 个数列别，比如：-cpu=1,2,4
        - c: go test -timeout=3s
          x: 默认情况下，测试执行超过 10 分钟就会超时而退出，我们可以通过这个时间指定超时时间
        - c: go test -parallel=2
          x: 当测试使用 t.Parallel () 方法将测试转为并发时，将受到最大并发数的限制，默认情况下最多有 GOMAXPROCS 个测试并发，其他的测试只能阻塞等待，这个可以用来并发安全的测试。
        - c: go test -v -cpuprofile=cpuprof.out
          x: 生成 cpuprof 的文件
    - url: https://github.com/golang/sync
      des: singleflight, ErrorGroup, Sema, Sync.Map
      qs:
        - q: What's ErrorGroup? When to use? How to use ErrorGroup? # timeout control, error return
        - q: misuses? # defer, for(block),
        - q: 什么是 ErrorGroup？怎么使用？实现原理？
        - q: singleflight is used to prevent multi goroutines from doing the same thing simultaneously and repeatedly.
      use:
        - url: https://go.dev/play/p/A5vj4Pe-CQ8
          des: CyclicBarrier. CyclicBarrier是一种同步原语，它允许一组线程在某个临界点处等待，直到所有线程都达到该点，然后同时继续执行。与Barrier不同的是，CyclicBarrier在每个线程到达临界点后会自动重置，可以重复使用。
    - url: https://github.com/golang/mod
    - url: https://github.com/golang/mobile
    - url: https://github.com/golang/term
    - url: https://github.com/golang/exp
    - url: https://github.com/golang/sys
    - url: https://github.com/golang/text
    - url: https://github.com/golang/crypto
      des: 主要使用场景就是用来存用户密码，md5(pwd+salt)这种传统方案已经被证明安全性非常差，不同于md5的方案，bcrypt.GenerateFromPassword每次生成的秘串都不同。既然每次生成的秘串都不同，怎么知道密码是否正确呢？使用bcrypt.CompareHashAndPassword
    - url: https://github.com/golang/net
    - url: https://github.com/golang/tools



#- golang os pkg # https://blog.51cto.com/u_15289640/5840461
#- golang time pkg. time.Since()
#- golang builtin functions, clear(), min(), max()
#- golang io.FS. How to embed FS?
## [超全总结：Go 语言如何操作文件](https://mp.weixin.qq.com/s?__biz=MzUxMDI4MDc1NA==&mid=2247496305&idx=2&sn=8f3d13db24875c13fef12862b885f570)
#- Higher-order function # 就是把func作为入参或者出参
#
##     comma-ok, options, builder, private-struct(avoid call), Callback as param
#- des: How to use "Builder Pattern"?
#- des: How to use "Functional Options Pattern"?
#
#- des: type func的写法
#  url: https://github.com/jorgelbg/pinentry-touchid/blob/main/main.go
#- des: 把func作为参数的写法
#  url: https://github.com/91go/docs-training/blob/main/cmd/all.go
#  des: 我的 actions() 和 batch() 都需要复用 Xz()，只有 ExtractQuestion() 需要替代，所以就把 func() 作为参数使用
#- des: LOOP, time
#  url: https://go.dev/play/p/tl2-QGEbkv9
#
#- des: chan
#  url: https://gist.github.com/hxhac/350b22095801614111c3fe8485b87e5e
#- des: context
#  url: https://go.dev/play/p/zCXAJiROScH
#
#- des: xxx
#  url: https://go.dev/play/p/VO7T6abmODn
#- des: struct搭配generics的写法
#  url: https://github.com/Edouard127/reddit-placebot-2023/blob/master/web/websocket.go
#- des: xxxx
#  url: https://github.com/solana-labs/token-list/blob/main/automerge/automerge.go#L79
#  des: 写得不错
#
#- des: 数组
#  url: https://go.dev/play/p/pGBrqP9DGn-
#- des: time.Ticker time的打点器Ticker和定时器Timer
#  url: https://go.dev/play/p/tKkj6mebb-f
#- 两个整数相除，为什么不返回 float？怎么得到 float？ # 用 fmt.Sprintf("%.2f", a/b) 返回 float

#  [Go Playground - The Go Programming Language](https://go.dev/play/p/ZUnQAvquU67)

#  [html.NewTokenizer()](https://gist.github.com/hxhac/e2b7ecf5974f2fd591e9c40c9d4d1d3c)

# [Go Playground - The Go Programming Language](https://go.dev/play/p/SCC82s2JyuU?v=)

# [rsa](https://gist.github.com/hxhac/dc94137af2127d11fad5f08f44e1b22c)


# [一些常用的enum](https://gist.github.com/hxhac/17b67e09ca05c808a4bdeb8b34b2bfb9)

# [创建高并发场景下订单号](https://gist.github.com/hxhac/4a9de86688fb2d596c4db27dfa7f4d8a)

# [GetFilesOfFolder](https://gist.github.com/hxhac/8aff5f69d117d305c7df58b04ef33d8a)

# [GetURL](https://gist.github.com/hxhac/a3e71019b0b8206a1953b7c1d1581295)

# [GetFilesOfFolder](https://gist.github.com/hxhac/8aff5f69d117d305c7df58b04ef33d8a)

# [dijkstra](https://gist.github.com/hxhac/8f31ab4703098d1768ac4818c2c72279)

# [sync.Map + generics](https://go.dev/play/p/ij-ZL3bo17v)

# [用Bitmap与AST做一个配置化时长系统](https://gist.github.com/hxhac/67e6066dc1e9dcd404ef3fba6f4c22cd)


# [mkmik/syncpool: generic sync.Pool](https://github.com/mkmik/syncpool) generics sync.Pool


# [generics](https://gist.github.com/hxhac/98ec5811f97969b7667da52c3357ed20)

# [interface+struct](https://gist.github.com/hxhac/fddd94f0a85410ff01f0cf93b5cfa396)

#   [golang channel barrier usage](https://gist.github.com/hxhac/6e40ad06d80bbd8d74f0792688a9cf7b)
#
#  [Go Playground - The Go Programming Language](https://go.dev/play/p/V2i7oeEE071)
#
#
#  [Go Playground - The Go Programming Language](https://go.dev/play/p/b5PZoRzZPfS?v=)
#
#  [channel fanout](https://gist.github.com/hxhac/96706d2e07ea6680695636a868db7950)
#
#  [sync.code usage](https://gist.github.com/hxhac/8b9c7e42d9f3cfb67f6cbd50b4c10b86)
#
#  [for...select and exit goroutine usage](https://gist.github.com/hxhac/d9d391a6ce36c4964c832835aec761eb)


# [Go Playground - The Go Programming Language](https://go.dev/play/p/DjDLYB8ES5n)

# [io teeReader](https://gist.github.com/hxhac/c3a9e47c79a82b74e062af0d794e167b)

# [sync map](https://gist.github.com/hxhac/0f8b39b10b790b6c00b788d869493d4c)

# https://github.com/Wowo10/RetryWorkerPool

# [CARP hash](https://gist.github.com/hxhac/29b87f876a3e9df4eaa3304445d8e4e7)

# [lock-free using atomic](https://gist.github.com/hxhac/df52327e6badac2f8f4e74663b537c91)

# [worker pool](https://gist.github.com/hxhac/ace505f5ce8d8be5338e2c70dc5bbc1a)


# [for循环时的变量问题](https://gist.github.com/hxhac/e9449acb4abc65cb620e0928c1d5fc7b)



# [Go：用规则引擎让你一天上线十个需求](https://mp.weixin.qq.com/s?__biz=MzAxMTA4Njc0OQ==&mid=2651451957&idx=2&sn=1c8892b83cc5641e5e90856c9eb5bf5f)
- type: Rules-Engine
  repo:
    - url: https://github.com/Knetic/govaluate
      des: 类似 Drools或者Activiti那样的规则引擎，但是17年之后就EOL了。有很多针对性优化的repo可供挑选。
    - url: https://github.com/casbin/govaluate
    - url: https://github.com/nwkl-home/govaluate


- type: pprof
  repo:
    - url: https://github.com/google/pprof
      cmd:
        - c: pprof top10 -cum
        - c: pprof web
        - c: pprof web mapaccess1
        - c: pprof web mallocgc
        - c: pprof list DFS
        - c: pprof list FindLoops
      qs:
        - q: pprof 的各项参数
        - q: 怎么用pprof快速定位内存泄漏的代码？
        - q: pprof 指标 metrics ((profile(CPU), heap), allocs, threadcreate, goroutine, block, mutex) # profile(CPU profile), heap, (allocs, block, goroutine, mutex, , threadcreate)
        - q: "***pprof 的运行原理？***"
        - q: pprof 应该监控 RSS、PSS 和 USS 中的哪个内存指标？
        - q: 内存怎么采样？pprof是怎么实现内存分析的？
    - url: https://github.com/grafana/pyroscope
      des: Used to achieve continuous profiling
    - url: https://github.com/grafana/pyroscope-go
      des: pyroscope client in golang, Better than holmes
    - url: https://github.com/mosn/holmes
      des: 类似pyroscope，也是“自动采样工具”
    - url: https://github.com/smallnest/zhuge
      des: 搭配pyroscope使用，在程序CPU、内存等异常的情况下，自动生成Profile并提交到Profiler以便分析。
    - url: https://github.com/arl/statsviz
      des: |
        功能与pprof类似，metrics也相同，也都需要添加route，都有侵入性，但是使用环境不同，为啥呢？
        本质上来说是因为pprof需要打开开关才开始采集metrics，而statsviz则默认采集。所以相应的，statsviz的性能开销更大，就不适合生产环境。

        想要持续收集golang的runtime，也可以通过Grafana，Graphite，Statsd等组件来采用UDP协议采集metrics上报到Grafana来进行一系列的展示，但是这种方案的成本比statsviz更高。


    - url: https://github.com/parca-dev/parca
      des: 非常好用，Parca 是一个利用 eBPF 技术进行高效、低开销的性能分析工具，同时它与 pprof 格式兼容，使得它可以轻松集成到现有的性能分析工作流程中。并且相比于pprof等工具，parca 可以自动发现运行在 k8s 或 systemd 环境中的所有目标，也就是说parca是非侵入式的。并且内置了Web UI以及storage机制。metrics和pprof相差不大，也都是CPU, memory, IO之类的。
    - url: https://github.com/dominikh/gotraceui
      use:
        - url: https://colobu.com/2024/03/18/execution-traces-2024/
      des: flight recording

#go install golang.org/x/tools/cmd/goimports@latest
#go install golang.org/x/tools/cmd/stringer@latest
- type: golang-Cli-Tools
  repo:
    - url: https://github.com/cortesi/modd
      des: |
        Pretty Useful.
        go install github.com/cortesi/modd/cmd/modd@latest.
        支持通过监听文件系统的变化来自动重启服务，这在快速迭代和频繁更改代码时非常有用
        不仅是pm2, supervisor或者forever这样的process manager，还支持类似

        modd强制使用conf格式作为配置文件，非常蠢

    - url: https://github.com/cosmtrek/air
    - url: https://github.com/go-eagle/eagle
      des: go install github.com/go-eagle/eagle/cmd/eagle@latest
    - url: https://github.com/uber-go/nilaway
      key: true
      des: 用来在编译时捕获nil，来规避生产环境出现nil panic问题。确实非常实用，帮我避免了很多坑。
    - url: https://github.com/dkorunic/betteralign
      key: true
      des: |
        Another filedalignment Tool. 相比于filedalignment，不会去修改各种 xxx_gen.go 以及 xxx_test.go 代码
        go install github.com/dkorunic/betteralign/cmd/betteralign@latest


- type: SDK
  repo:
    - url: https://github.com/go-pay/gopay
      des: 微信、支付宝、通联支付、拉卡拉、PayPal、Apple 的Go版本SDK。【极简、易用的聚合支付SDK】
    - url: https://github.com/silenceper/wechat
    - url: https://github.com/wechatpay-apiv3/wechatpay-go
      des: 微信支付
    - url: https://github.com/royalrick/weapp
      des: 微信小程序


- type: feeds
  repo:
    - url: https://github.com/mmcdole/gofeed
      des: parse rss
    - url: https://github.com/gorilla/feeds
      des: generate rss





- type: golang-unittest
  repo:
    # [你该刷新gomonkey的惯用法了](https://mp.weixin.qq.com/s?__biz=MzI4NDM0MzIyMg==&mid=2247490825&idx=1&sn=ea12de64c3aee953820174dc1e8fb1d4)
    - url: https://github.com/agiledragon/gomonkey
      des: Similar tools include mockery, testify-mock, gostub. But gomonkey not suppport interface, just support func and struct.

    - url: https://github.com/brianvoe/gofakeit
      des: 随机数据生成器。目前，它提供了160多个函数，涵盖少数不同的主题/类别，如Person、 Animals、 Address、 Games、 Cars、 Beers等等。这里的关键词是随机。
    - url: https://github.com/johannesboyne/gofakes3
      des: A simple fake AWS S3 object storage (used for local test-runs against AWS S3 APIs)

    - url: https://github.com/stretchr/testify
      des: 某种gotest的替代品，但是没啥必要
    - url: https://github.com/go-testfixtures/testfixtures
      des: 用来模拟数据库进行测试的工具，把样本数据保存在fixtures文件中。在执行每个测试之前，测试数据库都会被清理并将fixture数据加载到数据库中。
    - url: https://github.com/testcontainers/testcontainers-go
      des: 用来在测试中启动Docker容器，主要用于自动化集成/冒烟测试中。Testcontainers支持各种数据库、消息代理和其他服务，以便在测试中模拟外部依赖项。
    - url: https://github.com/xhd2015/xgo
      des: 非常好用的golang单测工具，xgo提供了一个全功能的Golang测试工具集，包括 Mock, Trace, Trap和增量覆盖率
    - url: https://github.com/maxatome/go-testdeep
      des: ???
    - url: https://github.com/orlangure/gnomock
      des: ???
    - url: https://github.com/mfridman/tparse
      des: CLI tool for summarizing go test output. Pipe friendly. CI/CD friendly.
    - url: https://github.com/onsi/ginkgo
      des: ginkgo 是 BDD 开发模式工具，测试框架，没用
    - url: https://github.com/traefik/mocktail
    - url: https://github.com/smartystreets/goconvey
    - url: https://github.com/dvyukov/go-fuzz
    - url: https://github.com/quasilyte/qbenchstat
      des: Better benchstat. Support "Colored output" and "significance test".
    - url: https://github.com/axw/gocov
      des: 感觉没啥用，类似goconvey之类的工具都内置类似 "coverage reporting tool" 了
    - url: https://github.com/pingcap/failpoint
      doc: https://www.luozhiyun.com/archives/595
      des: 相当于代码级别的chaos，支持在代码中精确地指定故障注入点，比chaos粒度更细
    - url: https://github.com/chaosblade-io/chaosblade
    - url: https://github.com/chaos-mesh/chaos-mesh
    - url: https://github.com/Netflix/chaosmonkey

    # [选择合适的测试框架 - MySpace](https://www.hitzhangjie.pro/blog/2020-08-19-go%E5%BC%80%E5%8F%91%E5%A6%82%E4%BD%95%E5%81%9A%E6%B5%8B%E8%AF%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/)
    - url: https://github.com/go-redis/redismock
      des: redis mock
    - url: https://github.com/tokopedia/gripmock
      des: gRPC mock
    - url: https://github.com/DATA-DOG/go-sqlmock
      des: go-mysql-driver mock # [[Go] 使用 go-sqlmock 模拟数据库驱动编写单元测试用例 - piaohua's blog](https://piaohua.github.io/post/golang/20220813-go-sqlmock/)
    - url: https://github.com/h2non/gock
      des: 用来模拟 HTTP 请求的工具，在我们写单元测试时，经常会遇到一些逻辑是需要请求别人的接口的场景，而我们无法完美模拟这些接口所需要的参数。这个时候就需要一个工具，当我们请求一些第三方接口时拦截请求，并返回我们的预设的返回值.比`httpexpect` 和 `httpmock`好用很多，推荐使用.
    - url: https://github.com/gavv/httpexpect
      des: Really? Let's try it out.
    - url: https://github.com/jarcoal/httpmock
    - url: https://github.com/uber-go/mock
      des: gomock, mockgen, fork from golang/mock(EOL). ***使用 gomock 来做接口 mock，不要使用 testify-mock/mockery/gomonkey, 都不好用***. mock 不是用来处理简单的无状态函数，其应用场景主要在于处理不可控的第三方服务、数据库、磁盘读写等。如果这些服务的调用细节已经被封装到 interface 内部，调用方只看到了 interface 定义的一组方法，那么在测试中 mocks 就能控制第三方服务返回任意期望的结果，进而实现对调用方逻辑的全方位测试。
    - url: https://github.com/ory/dockertest
      des: Dockertest helps you boot up ephermal docker images for your Go tests with minimal work. Ephemeral images and containers. 具体来说，通常用来模拟数据库，但是与sqlmock或者redismock不同的是，dockertest需要启动docker容器，所以相应的，开销更高，也不易集成到CI中，但是可以模拟更真实的场景，使用数据库的所有feats，也能发现更多bug




- type: network
  repo:
    - url: https://github.com/panjf2000/gnet
      des: 高性能、轻量级、非阻塞的事件驱动 Go 网络框架
    - url: https://github.com/gnet-io/gnet-examples
    - url: https://github.com/cloudwego/netpoll
      des: 专注于RPC场景的network库，这是netpoll和gnet, evio的最大区别。字节自家的Kitex和Hertz都是用了netpoll
      qs:
        - q: netpoll为啥性能很好？
          x: netpoll 底层基于 epoll, kqueue, iocp 这些 IO 多路复用技术来做封装，又借助runtime-scheduler对协程的高效调度，从而在通用性和性能上都足够满足绝大部分的应用场景
        - q: netpoll 有哪些问题？netpoll 为啥没有惊群问题吗？
          x: 没有惊群问题，netpoll 用 sync.Once 保证只初始化一次 epoll 实例 (也就是一个 listener 支持有一个 epoll 实例来管理网络连接)，既然只有一个 epoll 实例，也就不存在`惊群问题`了
        - q: netpoll 和 gnet 这种基于 Reactor 模型的网络库有什么区别？(为什么 gnet 会比 golang 原生的 net 包更快？)




- type: Markdown
  repo:
    - url: https://github.com/yuin/goldmark
      des: Markdown Render. Most leading markdown-about service uses goldmark as markdown render service, rather than blackfriday.
    - url: https://github.com/JohannesKaufmann/html-to-markdown
      des: Used to convert HTML to markdown
    - url: https://github.com/alecthomas/chroma
      des: 可以理解为golang生态下的prism或者shiki。hugo, gitlab, sourcegraph all use chroma to achieve syntax highlighting. 除了上述应用，chroma还可以用在IDE语法高亮、各种blog的Code Block语法高亮、命令行工具的语法高亮中使用。
    - url: https://github.com/mattn/godown
      des: Convert HTML into Markdown
    - url: https://github.com/hibbitts-design/docsify-this
      des: markdown viewer online platform github actions. 用来直接在线预览markdown文档，支持TOC，非常好用
    - url: https://github.com/hedgedoc/hedgedoc
      des: 在线共享的markdown平台，相当于腾讯文档或者google docs
    - url: https://github.com/pandao/editor.md




- type: ORM
  repo:
    - url: https://github.com/go-gorm/gorm
      doc: https://gorm.io/
      des: orm, better than xorm or sqlx, support for mysql, pgsql and sqlite.
      qs:
        - q: gorm 多对多关系的多表联查怎么搞？
        - q: golang 里 tinyint(1) 和 bool 的问题 # 建议用 tinyint(3)，status 两种，1 和 2
        - q: gorm 的 update的坑？ 如果参数类型为struct，则gorm默认不更新struct里的“零值字段”
        - q: 结构体查询时int类型的0值问题 # 当进行整个结构体查询时 gorm会默认把没有设置的值为0 所以无法进行查询 gorm只能进行非零字段查询。（不推荐结构体查询）目前的解决方法是： 当要进行结构体查询时将结构体中的int改为指针int类型
        - q: gorm哪些查询语法无法避免sql注入？
        - q: 自动生成uuid或者时间戳 # gorm:"type:uuid;primaryKey;default:gen_random_uuid()" 这种tag只有 DB.Create(&agent) 才能自动生成，直接insert不支持
    # [Using mysql in Go - creating pool of connection. Is it really needed? : golang](https://www.reddit.com/r/golang/comments/18g211c/using_mysql_in_go_creating_pool_of_connection_is/) no need to config connection-pool, but we need to
    # db.SetMaxOpenConns(25)
    - url: https://github.com/go-sql-driver/mysql
      des: mysql driver for golang
      qs:
        - q: 怎么解决go-sql-driver读取timestamp时间戳时会出现错误的问题？
          x: 需要在go-sql-driver的dsn中标明loc，否则默认使用UTC
          d: https://mp.weixin.qq.com/s?__biz=MzAxMTA4Njc0OQ==&mid=2651453861&idx=1&sn=63b98cb5154a9b46f898e561b112bd8f
    - url: https://github.com/gohouse/gorose
      des: 支持 mysql、postgres、sqlite、mssql、oracle，类似laravel的Eloquent，但是性能不如gorm
    - url: https://github.com/jmoiron/sqlx
      des: sqlx
    - url: https://github.com/go-mysql-org/go-mysql
      des: MySQL协议解析库，专注于底层的协议解析和处理，可用于构建MySQL客户端程序、代理或实时读取binlog等应用。。而不是MySQL Client。应该说，可以使用这个pkg来实现MySQL Client。
    - url: https://github.com/jackc/pgx
    - url: https://github.com/uptrace/bun
      des: SQL-first Golang ORM
    - url: https://github.com/tidwall/buntdb
      des: kvdb, 支持 ACID、并发读、自定义索引和空间信息数据, 只用一个golang文件就实现了以上功能，是用来学习数据库开发的好
    - url: https://github.com/nutsdb/nutsdb
      des: 类似buntdb，但是支持List、Set、Sorted Set这些数据结构。
    - url: https://github.com/Snapchat/KeyDB
      des: KeyDB is a multi-threaded fork of Redis, meaning it is fully compatible with the Redis protocol, changes and modules while promising to stay aligned with the upstream changes Redis will be doing in the future.
    - url: https://github.com/dolthub/go-mysql-server
    - url: https://github.com/prisma/prisma
      des: 我用不到. ORM for Node.js & TypeScript. Support pgsql, mysql, MariaDB, SQLite, MongoDB.
    - url: https://github.com/steebchen/prisma-client-go
      des: ??? 相当于prisma的golang client, 其实就是个ORM嘛，类似gorm之类的



- type: ms-framework
  repo:
    - url: https://github.com/go-micro/go-micro
      des: 内置的身份验证和数据存储设计。一个轻量级的微服务框架，做为一个在 2015 年就开源的项目，在当时那个市面上开源的微服务框架稀少的年代，它是为数不多的选择。主要槽点就是作者重心做云服务去啦，相应的社区维护力度较弱。
    - url: https://github.com/go-kratos/kratos
      des: 一个轻量级的微服务框架，B 站开源项目；web 和 rpc 服务的 DSL 协议直接采用 protobuf 和 grpc 进行定义，采用 wire 做依赖注入、自动生成代码。框架定位于解决微服务的核心诉求。社区建设：社区建设和维护上，算是做的中规中矩，官网更新一般，有公众号和微信群问题解答。
    - url: https://github.com/TarsCloud/TarsGo
      des: tarsgo 做为 tars 这个大的 C++ 重量级微服务框架下的 go 语言服务框架，腾讯开源项目；对于有个好爹的这个事情，总是喜忧参半的；好处在于很多能力不用从头开始做起，直接依托母体；劣势就是独立性相对较差，要选用这个 tarsgo 的前提，就是要先选用 tars 这个大的框架。社区建设：Tars 已经是 linux 基础会项目，社群上做的还算可以，毕竟 tars 作为腾讯开源影响力最大的项目之一，有 QQ、微信群。
    - url: https://github.com/apache/dubbo-go
      des: dubbogo 做为 dubbo 这个大的 Java 重量级微服务框架下的 go 语言服务框架，阿里开源项目；优劣基本跟 tarsgo 一样。
    - url: https://github.com/go-kit/kit
      des: go-kit 从严格意义上来说，并不能做为一个微服务框架，而应该是一个微服务的工具集，其官方定义上也是这么说，提供各种选项让你自由选择。做为一个在 2015 年就开源的项目，也是当时很多 go 项目为数不多的选择之一。
    - url: https://github.com/douyu/jupiter
      des: jupiter 做为一个重量级的微服务框架，斗鱼开源项目；整体思路上跟 tars 和 dubbo 力图提供一个大一统的框架，更确切的说是一个微服务平台，也带类似 tars 和 dubbo 那样的管理控制台，提供各种控制和 metric 的继承，这也无形中给选用此框架带来了不少代价，tars 和 dubbo 本身是有历史沉淀和大厂背景的，很多腾讯系、阿里系公司会采用。
    - url: https://github.com/tx7do/kratos-transport
      des: kratos生态，把消息队列、任务队列，以及Websocket、HTTP3等网络协议实现为微服务框架 Kratos 的transport.Server。在使用的时候,可以调用kratos.Server()方法，将之注册成为一个Server。
  des: golang的各种微服务框架比如gozero, gomicro, kratos, gokit, gizmo, kite, go-chassis, ego, eagle







- type: gozero
  md: true
  repo:
    - url: https://github.com/zeromicro/go-zero
      key: true
      des: go-zero 整体上做为一个稍重的微服务框架，提供了微服务框架需要具备的通用能力，同时也只带一部分的强约束，例如针对 web 和 rpc 服务需要按照其定义的 DSL 的协议格式进行定义，日志配置、服务配置、apm 配置等都要按照框架定义的最佳实践来走。
      doc: https://go-zero.dev/docs/tasks
      cmd:
        - c: goctl api new <project>
          x: 用这个命令生成的项目结构
        - c: goctl api go -api *.api -dir . --style=goZero
        - c: goctl rpc protoc *.proto --go_out=../ --go-rpc_out=../ -zrpc_out=../ --style=goZero
        - c: goctl model mysql
        - c: goctl model mysql datasource
        - c: goctl model mysql ddl
          x: goctl model mysql ddl -src blog.sql -dir ./model
        - c: goctl model mysql ddl -src user.sql -dir ./users -c
          x: 用来生成model层的CURD代码
      qs:
        - q: gozero 的使用场景？以及各个场景下的优势
        - q: 介绍 core 中好用的组件，比如 timingwheel 等
        - q: 怎么快速增加一种 rpc 协议支持，将跨机发现改为本机节点，并关闭复杂 filter 和负载均衡功能？
        - q: 日志和监控和链路追踪的设计和实现思路？
        - q: gozero 在 api 的 middleware 与 rpc 的 interceptor的tracing是怎么实现的？ jaeger
        - q: go-zero 有哪些池化技术？
        - q: go-zero 用到了哪些性能测试框架？
        - q: gozero 怎么实现自动管理缓存？
        - q: gozero 的自适应熔断算法？
        - q: goctl 解决了哪些问题？
        - q: gozero 中布隆过滤器的使用
        - q: gozero内置链路追踪是怎么实现的？

        - q: gozero怎么无缝接入dtm？
        - q: 聊聊gozero的zrpc是啥？基于grpc实现了哪些附加功能？
          x: |
            zrpc 是基于 grpc 的一个 rpc 框架，内置了服务注册、负载均衡、拦截器等模块。这个我们后面会通过源码来说明。
            zrpc 实现了 gRPC 的 resolver.Builder 接口和 balancer 接口，自定义了 resolver 和 balancer。
            zrpc 提供了丰富的拦截器功能，包括自适应降载、自适应熔断、权限验证、prometheus 指标收集等。

        - q: gozero的redis只支持0库，因为默认支持redis-cluster
        - q: 多级 goroutine 的异常捕获，怎么设计？
          x: |
            1. 微服务系统请求异常，应该隔离，不能让单个异常请求带崩整个进程。
            2. go-zero 自带了 RunSafe/GoSafe，用来防止单个异常请求导致进程崩溃。
            3. 需要监控，防止异常过量。
            4. fail fast 和故障隔离的矛盾
        - q: 能否聊聊 gozero 的缓存的设计和案例
          x: |
            1. 分布式多 redis 集群，线上最大几十个集群为同一个服务提供缓存服务。
            2. `无缝扩容`和`无缝缩容`
            3. 不存在没有过期时间的缓存，避免大量不常使用的数据占用资源，默认一周。
            4. `缓存穿透`没有的数据会短暂缓存一分钟，`避免刷接口`或者`大量不存在的请求`拖跨系统。
            5. 缓存击穿。一个进程只会刷新一次同一个数据，避免热点数据被大量同时加载。
            6. 缓存雪崩。对缓存过期时间自动做了 jitter(抖动)，5% 的标准变差，使得一周的过期时间分布在 16 小时内，有效防止了雪崩。
            7. 自动缓存管理已经内置于 go-zero，我们可以通过 goctl 自动生成代码。
        - q: 如果打算换 go-zero 框架重构业务，如何做好线上业务稳定安全用户无感切换？另外咨询下如何进行服务划分？
          x: |
            1. 逐步替换，从内到外。加个 proxy 来校对，校对一周后可以切换。
            2. 如果数据库重构，就需要做好新老同步。
            3. 服务划分按照业务来，遵循从粗到细的原则，避免一个 api 一个微服务。
            4. 数据拆分对于微服务来讲，尤为重要。上层好拆，数据难拆，尽可能保证按照业务来拆分数据。
        - q: 微服务系统怎么拆分？
          x: |
            1. 先粗后细，切忌过细，切忌一个请求一个服务
            2. 横向拆分，而非纵向，一般不超过三层
            3. 单向调用，严禁循环调用
            4. 禁止接口类型透传
            5. 没有依赖关系的串行调用，改为并行调用
        - q: gozero开发规范
          x: |
            - 请求最好单独配置，最好以 Req 开头。相应的，响应也单独配置，以Resp开头。
            - 如果我们修改了 api 文件，可以追加生成吗？
            - 同一个微服务的所有 api 文件，可以放在一起。比如说，用户系统，会涉及到登录相关操作、用户信息、关注和被关注等模块。这些模块可以加个 `group: friend`，就会自动生成到一个子文件夹。

            - 用好api的import，分开写，然后import到主api，不要写在一起（需要各自的 service name 相同）
            - api文件的@server，group, prefix, middleware


        - q: ms架构下，gozero目录结构怎么组织最合理？goctl api/rpc生成的几个目录，分别有啥用？
          x: |
            internal/handler 目录：API 文件里定义的路由对应的 handler 实现
            internal/logic 目录：用来放每个路由对应的业务处理逻辑，之所以区分 handler 和 logic 是为了让业务处理部分尽可能减少依赖，把 HTTP requests 和逻辑处理代码隔离开，便于后续按需拆分成 RPC service
            internal/svc 目录：用来定义业务逻辑处理的依赖，我们可以在 main 里面创建依赖的资源，然后通过 ServiceContext 传递给 handler 和 logic
            internal/types 目录：定义了 API 请求和返回数据结构

        - q: 添加配置
          x: |
            1. Add Config struct
            2. Add ServiceContext struct

        - q: gozero的logging怎么配置
          x: |
            用 go-stash 代替 logstash
            filebeat 收集我们的业务日志，然后将日志输出到 kafka 中作为缓冲，go-stash 获取 kafka 中日志根据配置过滤字段，然后将过滤后的字段输出到 elasticsearch 中，最后由 kibana 负责呈现日志

        - q: gozero怎么解决多环境下配置管理方案？给我具体代码
          x: |
            无非是两种方案
            - env + 各环境单独配置文件
            - 如果是ms的话，就需要etcd之类配置中心了，更安全（配置隔离，否则）并且实时生效，本身就适合低频修改但是需要保证分布式节点强一致性的需求。那就是viper+etcd嘛


    - url: https://github.com/wuyan94zl/IM
      des: 一个单体、只有api的gozero项目，说是“聊天室”，实际上核心是用户模块和好友模块，我的gozero-feeds中借鉴了很多代码
    - url: https://github.com/zeromicro/goctl-swagger
      des: gozero swagger
    - url: https://github.com/zeromicro/awesome-zero
    - url: https://github.com/zhoushuguang/lebron
      des: gozero实现电商项目
    - url: https://github.com/gphper/cinema-shop
      des: 基于go-zero的影票售卖系统。项目用到了 mysql, redis, etcd, rabbitMQ
    - url: https://github.com/xiaopenggithub/zindle
      des: gozero实现bookstore
    - url: https://github.com/feihua/zero-admin
      des: gozero实现的电商项目，表设计可以借鉴
    - url: https://github.com/zeromicro/zeromall
    - url: https://github.com/kevwan/mapreduce
      des: mapreduce, 并发编排任务。用 mapreduce 把正交逻辑并行化，就可以大幅度降低服务响应时长 (不需要优化 DB/缓存，重写业务逻辑)。
    - url: https://github.com/SpectatorNan/gorm-zero
      des: gozero 中用 gorm 代替默认的 sqlx
    - url: https://github.com/Mikaelemmmm/gozerodtm
      des: gozero中使用dtm的教程
    - url: https://github.com/nivin-studio/go-zero-mall
      doc: https://mp.weixin.qq.com/s?__biz=Mzg2ODU1MTI0OA==&mid=2247485055&idx=1&sn=474d13c6a31a9dbbce953bd6fada5daa
      des: 一个gozero实现的电商项目
    - url: https://github.com/Mikaelemmmm/go-zero-looklook
      des: |
        doc 文件夹下就有该项目的全部教程，但是这个教程只有大概思路和关键代码讲解，不是那种跟着一步一步实现的。bz也有视频，但是不用看，直接看文档教程就行。

        技术栈: gozero(go-queue) + mysql + redis + EFK(+ go-stash) + PAG + jaeger + kafka + asynq




- type: Websocket
  repo:
    - url: https://github.com/centrifugal/centrifugo
      des: Centrifugo can instantly deliver messages to application online users connected over supported transports (WebSocket, HTTP-streaming, SSE/EventSource, GRPC, SockJS, WebTransport)
    - url: https://github.com/gorilla/websocket
      des: Use websocket in golang



- type: sync
  repo:
    - url: https://github.com/sourcegraph/conc
      des: 相当于对sync的封装，可以用来写更简洁和标准的并发代码（增加代码可读性），并且可以有效避免很多“低级失误”（也就是他所说的 Make it harder to leak goroutines，比如各种 defer <-done来关闭goroutine，防止leak）。比如说对wg和mutex的封装，以及用Catcher来封装recover逻辑，来统一处理panic
      qs:
        - q: Catcher对recover逻辑的封装
        - q: 提供了哪几种worker pool (ContextPool, ResultContextPool, ResultPool, ErrorPool)
        - q: stream （用来保证结果有序）
        - q: ForEach、map操作（用来处理slice）
    - url: https://github.com/uber-go/atomic
      key: true
      des: uber-go/atomic比atomic更简洁，并且还提供了一些atomic本身没有提供的操作，比如sub, MarshalJSON, UnMarshalJSON 这些高频，但是需要自己实现的atomic操作。
    - url: https://github.com/lotusirous/go-concurrency-patterns




- type: IM
  repo:
    - url: https://github.com/openimsdk/openim-sdk-core
    - url: https://github.com/openimsdk/open-im-server




- type: cron
  repo:
    - url: https://github.com/go-co-op/gocron
      des: cron, "robfig/cron" have been EOL, so we use gocron



- type: qrcode
  repo:
    - url: https://github.com/skip2/go-qrcode
      des: 性能是 barcode 的三倍左右，但是生成的图片白边很宽，不好看，自己取舍吧。二维码通常是各种营销场景，方便用户使用。url 过长导致二维码像素点过密，怎么解决？把长链转短链，也就是所谓的动态二维码。
    - url: https://github.com/yeqown/go-qrcode




- type: Crypto
  des: En/Decrypt
  repo:
    - url: https://github.com/FiloSottile/age
      des: used to encrypt and decrypt
    - url: https://github.com/phpseclib/phpseclib
      des: 一些对称加密(AES)和非对称加密(RSA/DSA)的PHP实现，可以用来实现数据加密
    - url: https://github.com/deatil/go-cryptobin
      key: true
      des: 非常好用，与js兼容的AES加密库，省得折腾了
  qs:
    - q: DES/AES是基于XOR实现的？
    - q: RSA
      x: RSA 加密基于`Diffie–Hellman 密钥交换算法`的模幂运算，*简单来说就是，正向计算简单，逆向求解困难*


- type: Excel
  repo:
    - url: https://github.com/qax-os/excelize
    - url: https://github.com/tealeg/xlsx

- type: rate-limiter
  repo:
    - url: https://github.com/mennanov/limiters

    # [这个限流库两个大bug存在了半年之久，没人发现？](https://colobu.com/2023/12/05/two-bugs-of-uber-ratelimit/)
    # [更精准的sleep](https://colobu.com/2023/12/07/more-precise-sleep/)
    - url: https://github.com/uber-go/ratelimit
      des: 比juju/ratelimit更易用。这个pkg之前因为time.Sleep()导致的bug在golang1.23已经fix了（之前time.Sleep()设定50us, 实际上会sleep 80us左右，还是在可用状态，但是在golang1.16之后会sleep 1ms以上，也就是20倍以上，如果设定5000qps，实际上则是5000/20=250qps，属于完全不可用状态。）。结论是，time.Sleep()的精度问题是普遍存在的，也无法解决，目前只能做到ms级精度，部分pkg能做到us级精度，至于ns级精度就不要想了。


- type: OAuth
  repo:
    - url: https://github.com/casbin/casbin
      doc: https://editor.casbin.org/
      des: access controls
      qs:
        - q: storage? Model Storage, Policy Storage,
        - q: Multi-tenancy? RBAC with Domains
    - url: https://github.com/Permify/permify
      des: 也是类似casbin那样的Auth服务，但是permify更类似Google Zanzibar，更适用于复杂业务系统，提供更细粒度的权限。但是也与RBAC, ReBAC, ABAC兼容。与casbin的使用场景不同。
    - url: https://github.com/casdoor/casdoor
      des: casdoor和casbin的maintainer差不多，也是casbin社区项目统一使用的鉴权平台。Casdoor 是一个基于 OAuth 2.0 / OIDC 的 UI 优先集中认证 / 单点登录 (SSO) 平台，简单点说，就是 Casdoor 可以帮你解决 用户管理 的难题，你无需开发用户登录注册等与用户鉴权相关的一系列功能，只需几个步骤，简单配置，与你的主应用配合，便可完全托管你的用户模块，简单省心，功能强大。。
    - url: https://github.com/markbates/goth
      des: 第三方认证. gh, google, gitlab, apple, twitter, etc.
    - url: https://github.com/zitadel/zitadel
    - url: https://github.com/kanidm/kanidm
  qs:
    - q: OAuth 协议的工作原理？
    - q: OAuth2 有哪几种授权模式？ # 主流是密码模式，授权码模式和简化模式适用于大型网站，客户端模式很少被使用


- type: TUI/cli
  repo:
    - url: https://github.com/spf13/cobra
      key: true
      des: Better than urfave/cli. As Trivy said "Trivy has a lot of capabilities and needs a configuration file now. spf13/cobra has a better integration of configuration files. ... We should move to spf13/cobra.". Support feats like sub-cmd, flags, hooks(PreRun, PostRun), integrate with viper
      qs:
        - q: 为啥用cobra而不是urfave/cli
        - q: hook(PostRun, PreRun)
        - q: "***How to integrate with viper? 也就是“把config.yml作为默认flag并解析后，就可以直接使用config.yml中的所有key”，这样就不需要bind太多flag了***"
        - q: 怎么在所有命令的入口判断 env 是否存在，并且在所有子命令中都可以直接调用？
          x: 给rootCmd加个checkEnv()的PersistPreRun
        - q: 有哪几种flag
          x: PersistentFlags()、local (Flags())、required 必填
        - q: PersistentFlags()
          x: Must be matched, if flag use `PersistentFlags()`, should use `MarkPersistentFlagRequired()` as a matched required flag.
        - q: flag的P(), Var(), VarP()的用法有啥区别？
        - q: cmd的Args参数验证，有哪些内置验证规则？
          x: |
            ValidArgs(), 用`Args: func()`直接自定义参数的验证, 还有一些用来限制args数量的方法比如NoArgs, ExactArgs, RangeArgs等
        - q: how best to handle errors in Run? # SilenceErrors, SilenceUsage, RunE

      cmd:
        - c: cobra-cli add config
          x: need to notice command-name should be camel case, e.g. 'cobra-cli add addUser'
        - c: cobra-cli add create -p 'configCmd'
          x: used to assign a parent command to the newly added command
    - url: https://github.com/spf13/cobra-cli
      key: true
      des: go install github.com/spf13/cobra-cli@latest
    - url: https://github.com/charmbracelet/bubbletea
      key: true
      des: prompt cli/TUI  (better than promptui) 用来实现 TUI 应用的框架
      use:
        - url: https://github.com/charmbracelet/huh
        - url: https://github.com/sheepla/srss
        - url: https://github.com/robherley/snips.sh
    - url: https://github.com/charmbracelet/lipgloss
      des: Style definitions for nice terminal layouts. Built with TUIs in mind.
    - url: https://github.com/charmbracelet/gum
      des: gum并不能作为mod集成到golang应用，只是一个用来增强shell交互性和用户体验的cli工具。直接基于bubbletea+lipgloss实现。
    - url: https://github.com/alecthomas/kong
      des: CLI parser for golang
    - url: https://github.com/gdamore/tcell
    - url: https://github.com/rivo/tview
    - url: https://github.com/pterm/pterm
      des: a ALL-in-One console output utils, it support progressbar, charts, tables, tree, text input, single-select/multi-select, etc. it will replace other single-function cli-tools like schollz/progressbar, gosuri/uiprogress, cheggaaa/pb, olekukonko/tablewriter, termtables. In fact, pterm is just a render tool, It can be used by itself with cobra to provide a better Terminal experience.
    - url: https://github.com/olekukonko/tablewriter
      des: pterm不能完全取代tablewriter。这个repo支持各种table自定义样式（Without Border / Footer / Bulk Append, Custom Separator, cells merging、无边框）、支持自定义table颜色、支持多种数据源（CSV）、支持输出多种格式（Markdown）



- type: Local-Cache
  repo:
    - url: https://github.com/ben-manes/caffeine
    - url: https://github.com/google/guava
    - url: https://github.com/orca-zhang/ecache
      des: Local Cache. Support LRU.
    - url: https://github.com/golang/groupcache
      des: Local Cache.
    - url: https://github.com/eko/gocache
    - url: https://github.com/allegro/bigcache
  qs:
    - q: Compare bigcache, cachego, freecache, gcache, gocache, groupcache, lrucache.




- type: Golang-Template
  repo:
    - url: https://github.com/evrone/go-clean-template
    - url: https://github.com/golang-standards/project-layout
    - url: https://github.com/amitshekhariitbhu/go-backend-clean-architecture


- type: Golang-Logging
  repo:
    # zap 和 zerolog 都支持 取样器 Sampler 来限制每秒写入的日志数量，以减少性能开销。也都支持zero allocs.
    - url: https://github.com/uber-go/zap
      des: |
        log, zap 性能比 logrus 更好，logrus 更好用，跟标准库 log 包在 api 层面兼容. 不要使用 logrus，因为 logrus 使用了大量反射，导致大量内存分配。golang logging真正有必须要学的只有zap和内置的slog，一个重量一个轻量，并且都功能强大。

        使用 zap 或者 zerolog，这两种是没有使用反射，没有内存分配

        基础需求：

        - 自定义字段（json 格式（自定义格式化日志和输出））和日志级别
        - hooks
        - 线程安全
        - 性能要好
        - 其他特性（旋转日志、自动分割日志、支持修改时间格式）
      qs:
        - q: zap怎么同时输出到文件、console和kafka? 并且以不同格式（比如Text和JSON）
        - q: logging的前端和后端分别是啥？
        - q: 怎么分割logging
        - q: 怎么实现不同service把日志打到
        - q: sugared和logger除了perf（通过减少使用interface和reflect）还有啥区别吗? 原生支持格式化
        - q: slog相比zap
        - q: 怎么把zap集成到gin中？
        - q: SugaredLogger, format, with(kv)
        - q: NewExample()/NewDevelopment()/NewProduction()这 3 个函数可以传入若干类型为zap.Option的选项，从而定制Logger的行为
        - q: zap.NewDevelopment() 默认console. zap.NewProduction() 默认json.

    - url: https://github.com/rs/zerolog
      des: According benchmark zap provided, zerolog is better than zap in terms with time and allocs.
    - url: https://github.com/go-simpler/sloglint
      des: 搭配log/slog使用的Linter，直接配置到 golangci-lint 的配置文件 .golangci.yml 里
    - url: https://github.com/samber/slog-sampling
      des: slog sampling工具
  qs:
    - q: 日志降级是啥？怎么实现？
      x: 将日志会拆分成info，err两种日志文件，可以对info日志很好的降级，但err日志不会受任何影响，能够更好的去监控我们服务的错误问题。
    - q: access log 包括哪些字段
      x: |
        lv(info, err, warn, ...), ts, msg, aid, iid, host, cost

        req

        - req.aid
        - req.method
        - req.path
        - req.len
        - req.cip

        rep

        - rep.len
        - rep.code
        - rep.err





- type: uuid
  md: true
  repo:
    - url: https://github.com/rs/xid
      des: better than gofrs/uuid
    - url: https://github.com/oklog/ulid
      des: sequential, database-friendly ID generation
      use:
        - url: https://github.com/superseriousbusiness/gotosocial/blob/main/internal/id/ulid.go
    - url: https://github.com/google/uuid
    - url: https://github.com/sony/sonyflake
      des: snowflake
      qs:
        - q: 手写snowflake算法？（id 全局唯一且自增，怎么设计？）
    - url: https://github.com/jetpack-io/typeid
      key: true
      des: 基于UUIDv7实现，易用性更好，按照UUIDv7 spec，支持K-Sortable，不同于UUIDv4，作为DB主键使用时可以获得更好的locality。另外，支持type用来分割不同业务。
    - url: https://github.com/josethz00/snowflake-vs-uuid
      des: snowflake vs UUIDv4 benchmark. 实际上相差不大，与普遍认知中的“uuid比snowflake慢很多”的印象完全不同，uuid与snowflake除了在generate场景下性能相差一倍以外，其他CURD场景没啥区别。这点是必然的，毕竟snowflake直接位运算和位移操作即可生成，而UUID需要hash-func。也就是说，UUIDv7完全完全取代snowflake，毕竟UUIDv7支持自增和type，性能也相差不大。
    - url: https://github.com/sqids/sqids-go
      doc: https://colobu.com/2024/05/05/Sqids-short-unique-identifiers-generators/
      des: sqids 出乎意料的不错，Sqids = Short Quick Unique Identifiers
  qs:
    - q: 不同UUID version (UUIDv1, UUIDv4, UUIDv7) 的feat（换句话说，各版本之间的优化）？分别是怎么实现的？
      x: MAC address -> UUIDv4不依赖系统时钟和MAC -> SHA-1(需要输入ns和name)




- type: mail
  repo:
    - url: https://github.com/axllent/mailpit
      des: send mail
    - url: https://github.com/emersion/go-imap
      des: send mail, IMAP4rev2
  qs:
    - q: SMTP, POP, IMAP, MIME 有啥区别？为啥需要这么多种发邮件的协议？




- type: Golang-Web-Framework
  repo:
    - url: https://github.com/gin-gonic/gin
      des: Better than echo, iris, fiber, chi, goravel, beego, go-spring
      qs:
        - q: Gin框架中如何处理HTTP请求
        - q: "***聊聊gin的路由算法 Trie-Tree、路由算法LCP、生命周期、中间件原理***"
          x: |
            - CTT, 在TrieTree的基础上，通过合并唯一子树预期父节点来节约空间
    - url: https://github.com/julienschmidt/httprouter
      des: ???
    - url: https://github.com/gogf/gf
    - url: https://github.com/avtion/goamis
      des: gf搭配aims实现的后台，FRO
    - url: https://github.com/CrazyRocks/goadmin
      des: 同上，也是个gf实现的后台，他的这个 middleware/rtoken 写的不错，FRO
    - url: https://github.com/goflyfox/gtoken
      des: Better JWT.
    - url: https://github.com/bufanyun/hotgo
      des: 企业级应用的gf实现的后台项目
    - url: https://github.com/zhouyaozhouyao/goframe-admin
      des: 这个项目搞了casbin，用 kustomize 部署 k8s。internal 文件夹下有 MVC 层，里面用了gf对Transaction的封装，不错
    - url: https://github.com/vbenjs/gf-vben
      des:
    - url: https://github.com/gobuffalo/buffalo
      des: EOL, No longer maintained
    - url: https://github.com/go-nunu/nunu
      des: 类似buffalo, 也开始类似
    - url: https://github.com/ent/ent
      des: ???
    - url: https://github.com/swaggo/swag
      des: Swagger for golang
    - url: https://github.com/rookie-ninja/rk-boot
      des: ??? 其实是个Generator，用单个yaml管理一些web相关的一些常用服务（其实还是framework+db+cache+middleware这些），比较基础，其实没啥意思
    - url: https://github.com/flipped-aurora/gin-vue-admin
      des: gva 仅供参考
    - url: https://github.com/suyuan32/simple-admin-core
      des: Simple Admin 是一个强大的、易扩展的后台管理系统，基于 Go-Zero、Vben Admin、Ent、Casbin 等开源项目构建，提供了完整的用户管理、权限管理、角色管理、菜单管理、日志管理、配置管理等功能，支持多语言等特性，适用于小型或大型企业快速搭建分布式后台管理系统。
    - url: https://github.com/cloudwego/hertz
      key: true
      des: |
        [Golang Middleware]
        What middleware is built into hertz? Middleware, contains Auth middlewares like casbin, JWT, Paseto. And CSRF, CORS, Etag, cache middleware. Tracing middlewares like OpenTelemetry, OpenTracing, Limiter, etc.




- type: goframe
  repo:
    - url: https://github.com/xinjiayu/NoticeServices
    - url: https://github.com/pibigstar/go-todo
    - url: https://github.com/xuanyanwow/LogkitByGo
    - url: https://github.com/xuanyanwow/GoFrameNotifyConsumer
    - url: https://github.com/CrazyRocks/autocreate
    - url: https://github.com/mlogclub/bbs-go
    - url: https://github.com/PasteUs/PasteMeGoBackend


- type: Goroutine
  repo:
    - url: https://github.com/uber-go/automaxprocs
      key: true
      des: 自动设置 GOMAXPROCS 来最大化利用当前 CPU
    - url: https://github.com/KimMachineGun/automemlimit
      des: 类似 GOMAXPROCS 之于 CPU，但是 automemlimit 是用来限制内存的，通过自动设置 golang 的 GOMEMLIMIT 环境变量，以便与 Linux cgroups 的内存限制相匹配。它的主要目的是帮助限制 Go 程序的内存使用，确保程序不会超出在 cgroups 中设置的内存限制。
    # [Go 每日一库之 tunny - 大俊的博客](https://darjun.github.io/2021/06/10/godailylib/tunny/)
    - url: https://github.com/panjf2000/ants
      key: true
      des: 协程池, 来控制协程的并发数量. Better than tunny. tunny只支持同步的方式执行任务，虽然任务在另一个 goroutine 执行，但是提交任务的 goroutine 必须等待结果返回或超时。不能做其他事情。正是由于这一点，导致tunny的设计稍微一点复杂，而且为了支持超时和取消，设计了多个通道用于和执行任务的 goroutine 通信。一次任务执行的过程涉及多次通信，性能是有损失的。从另一方面说，同步的编程方式更符合人类的直觉。ants完全是异步的任务执行流程，相比tunny性能是稍高一些的。但是也因为它的异步特性，导致没有任务超时、取消这些机制。而且如果需要收集结果，必须要自己编写额外的代码。
    - url: https://github.com/Jeffail/tunny
    - url: https://github.com/oxtoacart/bpool
    - url: https://github.com/valyala/bytebufferpool
      des: 协程池 buffer pool






- type: Build-Tool
  repo:
    - url: https://github.com/go-task/task
      des: = Makefile. 相比于 makefile，这个还需要多安装一个 go-task。好处是用了 yaml 文件，执行命令更清晰。Makefile 的优势在于 IDE，以及各种平台都原生支持，这点非常重要。缺点就在于格式确实不太清晰。
      use:
        - url: https://github.com/SkYNewZ/github-notifications-rss
          des: FRO Taskfile.yml
    - url: https://github.com/casey/just
      des: 某种Makefile或者Taskfile，没发现有什么比较特别的feats
    - url: https://github.com/dnaeon/makefile-graph
      des: 用来生成Makefile依赖图的



- type: Golang-Error-Handle
  repo:
    - url: https://github.com/hashicorp/go-multierror
      des: 用来将多个error添加到MultiError中，并在需要时一起处理。可以避免传统handle error时的繁琐代码。
    - url: https://github.com/samber/oops
      des: Error handling library with context, assertion, stack trace and source fragments






- type: Golang-HTTP-Request
  repo:
    - url: https://github.com/go-resty/resty
    - url: https://github.com/valyala/fasthttp
      des: 10 times faster than net/http, but only for scenario that needs to handle thousands of small to medium requests per second. For most cases net/http is much better as it's easier to use and can handle more cases. For most cases you won't even notice the performance difference. (fasthttp 使用goroutine-multi-conn，而非CPC(coroutine per conn)，减轻了runtime调度goroutine的压力，所以性能更好)
      qs:
        - q: 为啥fasthttp选择slice而不是map来存储请求数据？

    - url: https://github.com/sethvargo/go-retry
      des: 用于重试逻辑和回退。它是高度可扩展的，可以完全控制重试发生的方式和时间。还可以通过实现backoff接口编写自己的自定义后退函数。
    - url: https://github.com/hashicorp/go-retryablehttp
    - url: https://github.com/guonaihong/gout
    - url: https://github.com/aceld/zinx
      des: TCP server


- type: Image
  repo:
    - url: https://github.com/h2non/bimg
      des: too heavy, I just need compress image, so didn't use it. dependency on libvips. BIMG compression is used for PNG only.
    - url: https://github.com/imgproxy/imgproxy
      des: pls read docs, it's a webserver, not a cli-tool.
    - url: https://github.com/h2non/imaginary
    - url: https://github.com/davidbyttow/govips
      des: need to process them separately according to the image format
    - url: https://github.com/Kagami/go-avif
      des: It supports encoding of JPEG and PNG files to AVIF.
    - url: https://github.com/cshum/imagor
    - url: https://github.com/Comdex/imgo
    - url: https://github.com/n7olkachev/imgdiff
    - url: https://github.com/issue9/watermark
      des: 简单的图片水印功能，支持 GIF
    - url: https://github.com/corona10/goimagehash
    - url: https://github.com/disintegration/imaging
    - url: https://github.com/kornelski/pngquant
      des: pngquant only support PNG images, not support other image formats.
    - url: https://github.com/dropbox/lepton
      des: Lepton is a lossless image compression algo developed by Dropbox. Lepton compress images, and it saved as .lep file. jpeg-xl ARHC filetype
    - url: https://github.com/imazen/imageflow
      des: ALL-IN-ONE image-tools, build by rust

    # upload images
    - url: https://github.com/eleven26/goss
    - url: https://github.com/aliyun/aliyun-oss-go-sdk
      des: 因为OSS和COS这些也是基于S3标准实现的（或者说是兼容S3的），所以
    - url: https://github.com/tencentyun/cos-go-sdk-v5
    - url: https://github.com/googleapis/google-cloud-go
    - url: https://github.com/mingcheng/obsync
    - url: https://github.com/burybell/osi
    - url: https://github.com/tutengdihuang/cloud_storage


- type: Tokenizer
  repo:
    - url: https://github.com/huichen/sego
      des: How to implement a chinese tokenizer? (DAT) golang 中文分词，类似ansj, jieba, hanlp, Thulac.
    - url: https://github.com/hankcs/HanLP
      des: Better than jieba.
    - url: https://github.com/blueshen/ik-rs
      des: Chinese Tokenizer.


- type: Golang-DI
  repo:
    - url: https://github.com/google/wire
      des: |
        DI. wire is much easier to use than uber-go/fx. dig 是通过运行时反射实现的依赖注入。

        而 wire 是根据自定义的代码，通过命令，生成相应的依赖注入代码，在编译期就完成依赖注入，无需反射机制。

        这样的好处是：首先，方便排查，如果存在依赖错误，编译时就能发现。而 dig 只能在运行时才能发现依赖错误。

        其次，避免依赖膨胀，wire 生成的代码只包含被依赖的，而 dig 可能会存在好多无用依赖。依赖关系静态存在源码，便于工具分析。
    - url: https://github.com/samber/do





- type: regex
  repo:
    - url: https://github.com/mvdan/xurls
      des: xurls provides a lot of commonly used regex. e.g. xurls.Strict.FindAllString() will extract all urls from text.
      use:
        - url: https://github.com/superseriousbusiness/gotosocial/blob/main/internal/regexes/regexes.go
    - url: https://github.com/mingrammer/commonregex
      des: = xurls
      qs:
        - q: 常用regex
          x: |
            \\D只保留数字

            \s.*  以空格开始的所有字符

            [u4e00-\u9fa5] 选择所有汉字

            [^\u4e00-\u9fa5]^[-,.?:;'\"!'] 选择所有非汉字，但是不包括-,.?:;'"!'这些标点符号

            ^((?!abc).)*admin((?!abc).)*$ 包含 admin 且不包含 abc。


    - url: https://github.com/rust-lang/regex
  qs:
    - q: "*regex syntax?*"
      x: (characters, quantifiers, groups, white-space, character classes, anchors and boundaries, inline modifiers, back-references, lookarounds, flags)
    - q: 多行修饰符
    - q: 量词（重复次数）
      x: "*, +, ?, {}"
    - q: 特殊单字符（简写字符集）
      x: \d, \D, \w, \W, \s, \S
    - q: 空白符（其他项）
      x: \f, \n, \r, \t, \v
    - q: 特殊运算符
      x: 锚点(^, $), 范围(转义运算符\, 或运算符|, 点运算符., 特征标群(...), be[^ou]r), , 不保存子组
    - q: 模式修正符
      x: 忽略大小写i (?i), 全局搜索g, 多行匹配m, 惰性匹配(在量词后加上 ? 将使得相关匹配项变成惰性模式, 正则默认贪婪匹配), 具名捕获
    - q: 断言（零宽度断言）
      x: 正向断言 (?=), 正向否定断言 (?!), 反向断言 (?<=), 反向否定断言 (?<!)
    - q: unicode
      x: emoji, 汉字






- type: Golang-Validator
  repo:
    - url: https://github.com/go-playground/validator
      des: filed-validator. go-playground/validator 没有内置支持regex，需要添加CustomRegex才能实现. validator的优势是内置了很多常用rules，开箱即用，比如ip验证、string验证、format验证、image验证等（README里有写），但是没有内置支持regex。
    - url: https://github.com/bytedance/go-tagexpr
      des: go-tagexpr 则更灵活，可以定义更复杂的rules. 但是没有什么内置rules.
    - url: https://github.com/asaskevich/govalidator
      des: 好像还不错，支持很多常用rules，也内置支持regex。README很详细，直接搜 "Here is a list of available validators for struct fields (validator - used function)"
    - url: https://github.com/gookit/validate
      des: Go通用的数据验证与过滤库，使用简单，内置大部分常用验证、过滤器，支持自定义验证器、自定义消息、字段翻译。







- type: captcha
  repo:
    - url: https://github.com/dchest/captcha
      des: captcha, outdated. need to think about whether will be broken by OCR.


- type: Golang-Struct
  repo:
    - url: https://github.com/jinzhu/copier
      key: true
      des: |
        copier, copy value. 用于各种 struct 互相转换

        要标明 copier:"must" 的 tag，有三种 tag. must/nopanic/-

        - 调用同名方法为字段赋值；
        - 以源对象字段为参数调用目标对象的方法，从而为目标对象赋值（当然也可以做其它的任何事情）；
        - 将切片赋值给切片（可以是不同类型哦）；
        - 将结构体追加到切片中。
    - url: https://github.com/mitchellh/mapstructure
      key: true
      des: convert map to struct. 如果 map 中没有该参数，需要保证数据库中该参数的默认值为 0，因为没有参数时 mapstructure 会赋值为 0，如果不为 0 就会出错；`mapstructure:",omitempty"` 如果为空就不展示。
    - url: https://github.com/darccio/mergo
      key: true
      des: merge structs and maps



- type: Golang-xxx
  repo:
    - url: https://github.com/yinggaozhen/awesome-go-cn
      des: awesome-go的中文版
    - url: https://github.com/golang-module/carbon
      key: true
      doc: https://github.com/hxhac/carbon-test
      des: 轻量级的、易于使用的、语义智能的日期时间库。基本上所有时间相关的操作，都能满足，非常好用。
    - url: https://github.com/PaulXu-cn/go-mod-graph-chart
      des: gmchart非常实用，每次遇到pkg conflict的时候，就很抓狂，你根本不知道到底是哪个indirect的pkg冲突了。用gmchart就可以快速定位具体是哪个pkg的version问题。
    - url: https://github.com/saintfish/chardet
      des: used to detect charset of text.

    - url: https://github.com/adaptive-scale/dbchaos
      des: Database Stress-Test Tool.

    - url: https://github.com/Xuanwo/gg
      des: |
        [gg: 像写 Golang 一样生成代码](https://xuanwo.io/2021/09-gg/)
    - url: https://github.com/bytedance/godlp
      des: 身份证号码、地址之类的脱敏pkg，不是cli, 只能作为pkg在golang中引入，字节的实现


    ## others

    - url: https://github.com/emicklei/go-restful
      des: provide a more elegant way to write RESTful API. Through several examples generated using ChatGPT, I can see that this is more similar to a routing lib, which is equivalent to eliminating a "Response struct" that we often write.


    - url: https://github.com/shopspring/decimal
      key: true
      des: 挺好用的，相当于math库。longzhu项目里用来处理float的精度问题（struct里定义为float64，然后在具体计算时的精度问题用这个pkg处理）。

    - url: https://github.com/ebitengine/oto
      des: used to play sound on multiple platforms(linux, mac, ios, android, ns, xbox, ...)


    - url: https://github.com/johnkerl/miller

    - url: https://github.com/RichardKnop/machinery

    - url: https://github.com/x1ah/gena
      des: 就是之前玩的那个webstack template的generator。通过这个项目学到了怎么实现一个 github template，搭配 ci 可以直接生成静态网站。可以一键部署到 gh-pages 上，还是很方便的。


    - url: https://github.com/projectdiscovery/subfinder
      des: Used to find subdomains


    - url: https://github.com/appleboy/gorush
      des: ???

    - url: https://github.com/dustin/go-humanize
      des: human friendly formatter

    - url: https://github.com/mat/besticon
      des: 这类工具很多，就是用来输入url直接返回该网站的icon，之前使用过一些都不太好用，不知道这个怎么样？

    - url: https://github.com/adnanh/webhook

    - url: https://github.com/atotto/clipboard
      des: clipboard for golang


    - url: https://github.com/gopasspw/gopass
      des: 用命令行生成和管理密码，golang 实现，可以看看
    - url: https://github.com/muesli/crunchy
      des: Finds common flaws in passwords. 比如说很多密码生成工具，用来判断密码强弱，就可以用这个pkg
    - url: https://github.com/wagslane/go-password-validator
      des: 同上，也可以用来判断密码强弱。

    - url: https://github.com/jpillora/ipfilter
      des: IP 过滤，有针对国家、单个 IP、IP 段等各种过滤模式，还可以作为中间件使用
    - url: https://github.com/coreos/go-iptables
      des: operates iptables in golang. Cuz we need to update iptables rules dynamically, so we need some libs like go-iptables. Actually, through why kube-proxy does not use iptables libs, we can see why iptables-pkg is not used much in actual scenarios. It is not as good as using the iptables command directly in terms of ease of use, performance, maintainability, cross-platform, etc. (kube-proxy why not use iptables libs like go-iptables to modify the rules? If we directly use the iptables commands to modify it, is it possible to ensure reliability?)

    - url: https://github.com/x-way/iptables-tracer
      des: ???

    - url: https://github.com/tinygo-org/tinygo
      des: wasm in golang. golang 的标准库支持编译成 wasm 文件，但是基本已经停止维护了。所以，需要使用 tinygo 才能更好地用 golang 开发 wasm。需要使用 wasmer-go 才能在 golang 调用 .wasm 代码。wasm 的主要应用场景，就是各种 cloud native 平台，各种 serverless 服务，比如 Envoy、Istio 等组件的二次开发，比如可以用 wasm 把自定义 filter 集成到 Envoy，实现 Envoy 代理的功能增强。

    - url: https://github.com/go-faker/faker
      des: Generate Fake Data

    - url: https://github.com/mazrean/formstream
      des: ???


    - url: https://github.com/uber-go/goleak
      des: Used to detect goroutine leaks

    - url: https://github.com/chainbound/shardmap
      des: implement hashmap using generics. Can be used as a reference to implement hashmap.

    - url: https://github.com/spf13/cast
      des: switch...case... + string(xxx) will cause data copy, bad performance

    - url: https://github.com/hellofresh/health-go
      des: Library to provide basic healthcheck functionality to Go applications.


    - url: https://github.com/shirou/gopsutil
      des: psutil for golang

    - url: https://github.com/hashicorp/go-plugin
      des: ??? 没看懂

    - url: https://github.com/samber/lo
      des: Pretty useful. golang utils for map and slice
    - url: https://github.com/gookit/goutil
      des: 常用dump.Print()来打印数据，很好用的golang工具函数包
    - url: https://github.com/csunny/argo
      des: 使用go语言实现数据结构与算法，涵盖字符串、数组、链表、队列、栈、树、图等数据结构。
    - url: https://github.com/ecodeclub/ekit
    - url: https://github.com/bytedance/gopkg
      des: 字节开源的，也是工具库，提供了一些std不提供，但是比较常用的操作。collection中提供了hashset, skipmap, skipset, zset等数据类型。lang对chan, string, sync添加了一些自定义方法。
    - url: https://github.com/duke-git/lancet
      des: |
        - sort算法
        - 数据结构 (list, link list, stack, queue, set, tree, heap, hashmap)
        - compare
        - condition
        - cryptor算法 (AES, DES, md5, sha1, sha256, sha512, RSA)
        - datetime
        - math
        - random
        - retry
        - LRU
    - url: https://github.com/sohaha/zlsgo
      des: 类似lancet，比较杂。支持处理JSON、字符串，还支持作为HTTP服务、DI、HTML解析、hot reload之类的。也可以参考其实现。

    - url: https://github.com/google/go-cmp
      des: Used to compare values in golang. If we use reflect.DeepEqual to compare, unexported fields are not compared by default.

    - url: https://github.com/go-echarts/go-echarts
      des: echarts in golang, not bad

    - url: https://github.com/nitishm/go-rejson
      des: ???

    - url: https://github.com/spf13/afero
      des: 类似kernel VFS那样的，将不同文件系统统一抽象为一个通用接口。当然，这个不是kernel层面，而只是应用层面的抽象。

    - url: https://github.com/riverqueue/river
      des: Background Jobs

    - url: https://github.com/cloudflare/tableflip
      des: Graceful process restarts in Go

    - url: https://github.com/samber/mo
      des: monads and popular FP abstractions

    - url: https://github.com/deanishe/go-fuzzy
      des: awgo的fuzzy search就是基于这个lib实现的，确实挺好用

    - url: https://github.com/nfx/go-htmltable
      des: Extract Data from HTML's table, but we have to construct a matched struct. We just need to input the URL of webpage, and we can extract wanted data.

    - url: https://github.com/authelia/authelia
      des: 用来提供2FA认证和passkey的，类似gh现在的这样。可以作为pkg被使用，也可以直接集成到caddy, traefik之类的服务里，提供服务。

    - url: https://github.com/mritd/touchid
      des: mac TouchId

    - url: https://github.com/progrium/macdriver
      des: Native Mac APIs for Go. 相当于python生态下的AppKit，但是不如AppKit好用。之前写oss-workflow时用来从mac clipboard获取图片用的。类似工具还有几个，这个比较好用。

    - url: https://github.com/jeessy2/ddns-go
      des: 跟DNSMasq或者BIND还不太一样，ddns-go是用来动态更新DNS记录的服务，以便将域名映射到动态分配的IP地址。而DNSMasq则功能更多，它们提供了完整的DNS服务，包括域名解析、DNS缓存、区域传输等功能。它们可以作为本地DNS服务器，提供域名解析和缓存功能，还可以作为权威DNS服务器，管理特定域名的DNS记录。换句话说，ddns-go只是DNSMasq的一部分，只提供了动态更新DNS记录的功能。

    - url: https://github.com/cloudflare/cloudflare-go

    - url: https://github.com/ovh/utask
      des: utask 可以理解为分布式调度平台（但是也支持其他功能，比如他Real-world examples中提到的几个），需要通过docker-compose来使用，是一个单体服务，而不是pkg

    - url: https://github.com/montanaflynn/stats
      des: math 库，提供了各种中位数、平均值之类 golang 没有官方那个 pkg 的东西

    - url: https://github.com/gabriel-vasile/mimetype
      des: used to detect filetype. 与golang通常用http.DetectContentType(buffer)获取mimetype不同的是，mimetype会读取文件的字节，在MIME这个二叉树结构的数据（各种filetype的magic number）中进行前序遍历，而不需要依赖文件名或其他元数据。相比之下，mimetype比 DetectContentType 和 filetype 的性能都更好（README里贴了benchmark）。并且，mimetype 提供了更易用的API可以直接使用，使用DetectContentType函数则需要自己打开文件并读取字节，略微繁琐。

    - url: https://github.com/lionsoul2014/ip2region
      des: 好用的IP解析库，也就是用IP反推用户地址，需要下载一个50MB左右的ip.merge.txt文件。相当于开源的IPIP.NET。



---

# Database

- type: mysql
  md: true
  repo:
    - url: https://github.com/mysql/mysql-server
      key: true
      doc: https://dev.mysql.com/doc/refman/8.0/en/
      qs:
        - q: "***How does mysql works? arch of mysql?***" # cpoes
        - q: mysql, CHANGELOG # JSON, Iterator Model, document store
        - q: "***How to optimize mysql service and sql?***"
          x: |
            **分析执行计划、矫正行数、添加索引、避免回表、使用 ICP、优化字符串索引、控制 flush 时机、加快 innoDB 刷盘、避免对索引字段做函数操作。**

            - 预发跑 sql explain
            - 看一下行数对不对，不对可以用`analyze table <t>`矫正
            - 添加索引，索引不一定是最优的，`force index`强制走索引，但是不建议使用
            - 查看是否存在回表的情况
            - 覆盖索引避免回表，不用*
            - 合理安排联合索引的顺序
            - MySQL5.6 之后使用 ICP 减少回表次数
            - 给字符串加索引，用`前缀索引`、`倒序存储`、`hash`
            - 数据库的 flush 时机
            - innoDB 刷盘速度，脏页比例、redolog 写盘速度
            - 索引字段不要做函数操作，会破坏索引值的有序性，优化器会放弃走树结构。如果触发隐式转换，也会走 cast 函数，会放弃走索引

        - q: "*mysql middleware, core requirements?*"
        - q: uuid、自增 id、snowflake 作为主键，分别有什么优缺点？为啥 mysql 不推荐使用 uuid 作为主键？
        - q: "*What optimization methods does optimizer have?*" # ICP and index dive, (MRR, BKA, BNL)
        - q: What's Index Dive?
        - q: ICP 的原理？有什么好处？使用 ICP 的注意事项？
          x: |
            - ICP 只能用于二级索引，不能用于主索引。
            - 不是全部 where 都能用 ICP 筛选，如果 where 条件的字段不在索引中，当然还是要读取整条记录做筛选，在这种情况下，仍然要到 server 端做 where 筛选。
            - ICP 的加速效果取决于在存储引擎内通过 ICP 筛选掉的数据的比例。

        - q: "*Execution order of mysql query statements?*" # FWG(H)SDO
        - q: Volcano Model(iterator executor)

      qq:
        - topic: Index
          qs:
            - q: "***Index 创建原则?***"
              x: 左选小写修（最左前缀索引、选择性、小字段、写操作频率、修改索引）最主要的索引创建原则其实就是最左前缀和选择性。除此之外就是一些tips，比如什么查询频率、写操作频率（更新非常频繁的字段不适合创建索引）、小字段（对于大的文本字段甚至超长字段，不要建索引）、反向开闭（用修改代替新增）之类的
            - q: Index选择性是啥?
              x: 就是字段不重复的比例`count(distinct col)/count(*)`（不重复的索引值（也称为基数 cardinality) 和数据表的记录总数的比值），区间为`(0,1]`，*识别度越高，扫描相同行数，需要的次数就越少，这是由 B+ 树的性质决定的*
            - q: 最左前缀的本质是啥?
              x: “最左前缀”实际上就是前缀索引在复合索引场景下的使用，也就是说，复合索引中field顺序也要按照“index创建原则”来排序。最左前缀的本质就是ICP，ICP只在满足"最左前缀"条件时起作用。如果查询条件中包含了索引的非最左前缀列，ICP将无法生效，MySQL会在存储引擎层面进行完整的行过滤，这可能会导致性能下降。总结来说，"最左前缀"原则和ICP的本质是基于索引列的前缀进行索引范围扫描，以减少需要访问的行数，提高查询性能。
            - q: What's clustered and non-clustered index?
            - q: explain命令的结果集分析?
              x: extra (index, temporary, filesort), type (const, range, index, ALL, ref, fulltext (system, eq_type, ref_or_null, index_merge, unique_subquery, index_subquery))
            - q: Why MySQL use B+Tree, other than btree or skiptable?
            - q: How To Leverage MySQL Database Indexing?
            - q: MySQL8 索引跳跃扫描 Index Skip Scan.
              x: MySQL Optimizer提供的机制，不需要设置索引来开启
            - q: 聚簇索引和非聚簇索引，分别是什么?
              x: 聚簇索引和非聚簇索引的区别就是，叶子节点是不是存有行数据。聚簇索引是一种物理存储方式，它决定了数据在磁盘上的物理排序顺序。聚簇索引的目的是将相关的行物理上存储在一起，以提高范围查询的性能。聚簇索引是以主键 ID 为节点生成的，非子节点都是 id，叶子节点（最下面一层）会相互连接变成双向链表，并且叶子节点会存储对应的行记录。而非聚簇索引的节点是基于索引列，找到了对应叶子节点的索引值后，会根据叶子节点存储的行记录们指针们，回到聚簇索引去查找行记录（这个过程也叫做回表）。

            - q: mysql 索引 退化
            - q: 聊聊MySQL8新增的隐藏索引、降序索引、函数索引这三种索引?
              x: |
                - 隐藏索引:
                应用场景：软删除、灰度发布。

                在没有hiding index之前，只能通过显式的方式删除索引，如果删除后发现索引删错了，又只能通过创建索引的方式将删除的索引添加回来，如果数据库中的数据量非常大，或者表比较大，这种操作的成本非常高。

                在MySQL 8.0中，只需要将这个索引先设置为隐藏索引，使查询优化器不再使用这个索引，但是，此时这个索引还是需要MySQL后台进行维护，当确认将这个索引设置为隐藏索引系统不会受到影响时，再将索引彻底删除。这就是软删除功能。

                灰度发布，就是说创建索引时，首先将索引设置为隐藏索引，通过修改查询优化器的开关，使隐藏索引对查询优化器可见，通过explain对索引进行测试，确认这个索引有效，某些查询可以使用到这个索引，就可以将其设置为可见索引，完成灰度发布的效果。

                - 降序索引:
                - 函数索引: 在索引中使用函数（表达式）的值，函数索引基于虚拟列功能实现


        - topic: MSR
          qs:
            - q: MSR的工作原理? MSR过程中，主从服务器分别使用了哪些线程?
              x: 写入、复制、重放 (write, replication, replay) (sql thread, io thread) (parallel MSR)

            - q: What's GTID? Compare with binlog position-based MSR?
              x: (GTID=server_uuid:tag:transaction_id), Auto-Positioning
            - q: GTID Auto-Positioning
            - q: 怎么解决 Replication Lagging 问题?
              x: (relaylog) (refer to the process of MSR) 主从复制的流程就三步，写入/复制/重放。写操作完成后会实时写入 binlog，没有优化点。所以优化点在于后面两步，复制和重放都可以通过多线程并行。所以核心
            - q: MMR, Master HA, shadow-master
            - q: mysql-cluster,
            - q: What's read-write separation? How to achieve?


        - topic: MySQL Optimize
          qs:
            - q: "***How to optimize MySQL?***"
              u: https://dev.mysql.com/doc/refman/8.0/en/performance-schema.html
            - q: mysql内置了哪些用来优化sql的工具，和soar对比呢?
            - q: 怎么用optimizer-trace来优化sql？ 如何分析trace来改善查询的执行效率？
              x: 通过trace，我们可能发现一些我们在explain中看不到的东西，当发现query并未产生并行查询计划时，可以将trace打开，可以协助我们
            - q: explain-analyzer
              x: mysql8 提供的优化工具，他会做出查询计划，并且会实际执行，以测量出查询计划中各个关键点的实际指标，比如耗时、条数、循环次数
            - q: explain-analyzer 返回的 cost, actual, time, rows, loops 分别是啥? cost 多少说明优化
              x: cost是估算值，actual是实际执行 . cost < 100就都不错了
            - q: “Query Profiler 工具”已经废弃了



        # geektime MySQL实战45讲
        #        - 一条 SQL 查询语句是如何执行的？
        #        - 一条 SQL 更新语句是怎么执行的？
        #        - 事务隔离（为什么你改了我还看不见？）
        #        - 索引（上下）
        #        - 全局锁和表锁；（给表加个字段怎么有这么多阻碍？）
        #        - 行锁；（怎么减少行锁对性能的影响？）
        #        - 事务到底是隔离的，还是不隔离的？
        #        - 普通索引和唯一索引，应该怎么选择？
        #        - MySQL 为什么有时候会选错索引？
        #        - 怎么给字符串字段加索引？
        #        - 为什么我的 MySQL 会抖动一下？
        #        - 为什么表数据删掉一半，表文件大小不变？
        #        - count(*) 这么慢，我该怎么办？
        #        - order by 是怎么工作的？
        #        - 如何正确地显示随机消息？
        #        - 为什么这些 SQL 语句逻辑相同，性能却差异巨大？
        #        - 为什么我只查一行的语句，也执行这么慢？
        #        - 幻读是什么？幻读有什么问题？
        #        - 为什么我只改了一行的语句，锁这么多？
        #        - MySQL 有哪些“饮鸩止渴”提高性能的方法？
        #        - MySQL 是怎么保证数据不丢的？
        #        - MySQL 是怎么保证主备一致的？
        #        - MySQL 是怎么保证高可用的？
        #        - 备库为什么会延迟好几个小时？
        #        - 主库出问题了，从库怎么办？
        #        - 读写分离有哪些坑？
        #        - 如何判断一个数据库是不是出问题了？
        #        - 误删数据之后，除了跑路，还能怎么办？
        #        - 为什么还有 kill 不掉的语句？
        #        - 我查了这么多数据，会不会把数据库内存打爆？
        #        - 到底可不可以使用 join？
        #        - join 语句优化？
        #        - 为什么临时表可以重名？
        #        - 什么时候会使用内部临时表？
        #        - 都说 innoDB 好，那还要不要使用 memory 引擎？
        #        - 自增主键为什么不是连续的？为什么 MySQL 的自增主键不单调也不连续？ # mysql8 之后通过 redolog 解决了自增主键不单调的问题，但是不连续的问题依然存在。*mysql8 对于自增计数器做了修改，每次计数器的变化都会写入到系统的 redolog，并在每个检查点存储在引擎私有的系统表中；当 mysql 服务器被重启后，可以从`持久化的检查点`和`redolog`中恢复出最新的自增计数器，避免出现不单调的主键*
        #        - insert 语句的锁为什么这么多？
        #        - 怎么最快地复制一张表？
        #        - grant 之后要跟着 flush privileges 吗？
        #        - 要不要使用分区表？
        #        - 自增 ID 用完了怎么办？
        - topic: InnoDB
          qs:
            - q: "***InnoDB, feats? (checkpoint, buffer-pool, read-ahead, insert-buffer, double-write, adaptive-hash-index) 这些都是啥?***"
              x: |
                - 事务相关：支持 ACID 事务、MVCC、InnoDB 锁机制、redolog
                - 性能相关：插入缓冲、二次写、缓冲池、自适应哈希索引
                但是实际上事务相关特性，本质上也还是为了优化性能，比如说之所以用 MVCC 就是为了能够并发事务，而 InnoDB 锁机制和 redolog 本质上来说都是为了保证 MVCC 正常运行。另外，也有一些其他特性，比如外键、行级锁定、共享表空间和独立表空间等等，这些都比较简单，就不太重要了。

                 - `插入缓冲 (insert buffer)`，*加速插入操作*，插入缓冲用于非聚簇索引的插入和更新操作，先判断插入的非聚簇索引是否在缓存池中，如果在则直接插入，否则插入到`插入缓存对象`中。再以一定的频率进行插入缓冲和辅助索引叶子节点的 merge 操作，将多次插入合并到一个操作中，提高对非聚簇索引的插入性能
                 - `二次写 (double write)`由两部分组成，一部分是内存中的`double write buffer`，大小为 2MB，另一部分是物理磁盘上共享表空间连续的 128 个页，大小也为 2MB。在对缓冲池的脏页刷新时，并不直接写磁盘，而是通过 memcpy 函数将脏页先复制到内存中的该区域，之后通过`double write buffer`再分两次，每次 1MB 顺序地写入共享空间的物理磁盘上，然后马上调用 fsync 函数，同步磁盘，避免 OS 缓冲写带来的问题
                 - `自适应哈希索引 (adaptive hash index)`*自动在内存中创建 hash 索引来加速读操作*，innoDB 会根据访问的频率和模式，为热点页建立哈希索引，来提高查询效率。索引通过缓存池的 B+ 树页构造而来，因此建立速度很快，innoDB 存储引擎会监控对表上各个索引页的查询，如果观察到建立哈希索引可以带来速度上的提升，则建立哈希索引，所以叫做`自适应哈希索引`
                 - `缓存池`为了提高数据库的性能，引入缓存池的概念，通过参数可以设置缓存池的大小和实例个数，缓存池可以存储一下内容：索引页、数据页、undo 页、插入缓冲、自适应哈希索引、innoDB 存储的锁信息和数据字典信息 (data dict)

            - q: "*InnoDB, arch? How does it works?*"
            - q: InnoDB, redolog
            - q: InnoDB 为什么要使用 bptree？
            - q: 为啥mysql的InnoDB使用bptree，而不是btree或者skiptable？
            - q: checkpoint是啥? 只跟redolog 相关吗? 跟其他日志有关吗?
              x: 其实就是刷盘操作（当然还有其他刷盘操作，具体的触发条件、执行方式和优化策略不同，比如同步写入、异步写、定时写等等），用来把内存中的脏页（尚未写入磁盘的修改数据页）写入磁盘，并更新相关的日志信息，以确保数据的持久性（防止系统崩溃时数据丢失）和一致性。


        - topic: Transaction
          qs:
            - q: 什么是 CC？有哪些单版本的 CC 方法？基于这些单版本 CC 方法，MVCC 有哪些不同的实现?
              x: CC 由数据库的调度器负责，事务本身感知不到可能导致数据一致性的冲突事务，调度器会 delay 或者 abort，如果 delay 就延迟到合法时机，如果 abort 就直接回滚。本质上是一个取舍问题，乐观锁不维护锁，吞吐很高，但是相应回滚也会比较多，而回滚比延迟的成本要高很多，所以在冲突较少和 validation 开销小的情况下，使用 OCC。LBCC 的方案则相反。
            - q: 三种实现 MVCC 的方法?
              x: 其实就是三种，乐观锁、悲观锁和ts。也就是 MV-2PL(悲观锁)和MV-OCC(乐观锁，读写时不做验证，延迟到提交时验证)，以及MV-TO(ts-based)
            - q: MySQL的2PL是啥?
              x: 2PL就是通过组合使用innodb的S锁和X锁来在保证事务隔离的情况下，提高并发性能

            - q: "***InnoDB是怎么保证事务ACID的？***"
              x: |
                事务的原子性/A让你在提交前能随时中止事务并丢弃所有写入，相应地，事务的持久性/D则承诺一旦事务成功提交，即使发生硬件故障或数据库崩溃，写入的任何数据也不会丢失。事务的隔离性/I确保每个事务可以假装它是唯一在整个数据库上运行的事务 —— 数据库会确保当多个事务被提交时，结果与它们一个接一个地串行运行是一样的，尽管实际上它们可能是并发运行的。而原子性与隔离性则服务于 一致性/Consistency —— 也就是应用的正确性/Correctness —— ACID 中的C是应用的属性而非事务本身的属性，属于用来凑缩写的。然而在工程实践中，完整的隔离性/I是很少见的。

                - `一致性`，*一致性是最基本属性，其他三种都是为了实现一致性而存在的*
                - `隔离性`，用事务的`隔离级别`保证事务的隔离性，为了保证并发场景下的一致性，引入隔离性，不同事务之间互不影响
                - `原子性`，用 undolog 保证事务执行失败后，直接回滚
                - `持久性`，用 redolog 保证事务提交后，对数据的修改是永久性的，即使系统故障也不会丢失
            - q: ANSI SQL92 用三种并发异常（Anomaly），划分出四种不同的隔离级别，将这种利弊权衡进行了（糟糕的）标准化
            - q: MySQL对MVCC的实现? MVCC = 版本链+ReadView(undolog)
              x: |
                通过版本链的 trx_id 和 ReadView 的高低水位比较后，决定使用哪个版本。ReadView 就是快照，用来做可见性判断。
                - ReadView 的结构 (m_ids, min_trx_id 低水位, max_trx_id 高水位, creator_trx_id)
                - undolog 版本链的结构 (trx_id 事务 id, roll_pointer 回滚指针)


            - q: "***事务的四种隔离级别是什么？RU、RC、RR、SR 分别是什么？RR 和 RC 的区别？RC 和 RR 的 MVCC 机制为什么不同？各自会解决和导致什么问题?***"
              x: |
                隔离就是类似linux kernel的可见性，通过可见性来解决事务在并发请求（包括读写操作）时的数据一致性问题。比如什么RU、RC、RR、SR，随着隔离级别的加强，分别解决了脏写、脏读、不可重复读和幻读的问题。隔离级别越来越高，并发性就越差。

                RU、RC、RR、SR 分别是什么？

                - `RU`读操作不加锁，可能会`脏读`(解决了`脏写`问题)
                - `RC`只对记录加记录锁，而不会在记录之间加间隙锁，所以允许新的记录插入到被锁定记录的附近。所以在多次读操作时，会发生`不可重复读`(解决了`脏读`问题)
                - `RR`多次读取同一范围的数据会返回第一次查询的快照，不会返回不同的数据行，但是可能会发生`幻读`(解决了`不可重复读`问题)
                - `SR`InnoDB 隐式地将全部查询语句加上共享锁，解决了`幻读`问题，但是性能很差

            - q: 为什么 MySQL 把 RR 作为默认的隔离级别呢?
            - q: RR 和 RC 在锁、复制、一致性读方面的区别?
              x: |
                *RC 和 RR 的区别在于 ReadView 快照生成时机不同，导致可见性不同*，RC 在每次读取数据前都生成一个 ReadView，而RR 在第一次读取数据时生成一个 ReadView
            - q: "*MySQL（中 InnoDB）的事务是怎么实现的？怎么实现 RR 的?*"
            - q: "***不同隔离级别，可能导致哪些问题?***"
            - q: 并发事务之间的相互影响?
            - q: 脏读、不可重复读、幻读分别是什么?
              x: |
                - `脏读`，t1 在修改之前提交，t2 读取，t1 回滚，t2 读取了从未提交的数据，*读未提交时，读事务直接读取主记录，无论更新事务是否完成*
                - `不可重复读`t1 读取，t2 修改该数据并提交，t1 重新读取，数据已被修改，数据不同
                - `幻读`数据不同*每次都能读到最新数据*
            - q: MySQL 遇到脏读怎么办?

            - q: "*MVCC 机制的原理和实现：MVCC 是什么?ReadView 是什么？高水位、低水位?*"
              x: (m_ids, min_trx_id, max_trx_id, creator_trx_id), undolog(trx_id, roll_pointer)
            - q: "*RR 是怎么实现的？RR 怎么用间隙锁解决幻读?*(常见问题)"
            - q: MySQL 的 RR 无法避免 PMP / G-Single 异常，Hermitage 将其实际等级定为 单调原子视图/MAV
              d: https://zhuanlan.zhihu.com/p/675251957

            - q: MySQL 事务中的加锁和解锁时机？
              x: |
                - 对记录进行更新操作，或者`select for update`(X 锁)、`lock in share mode`(S 锁) 时，会对记录进行加锁，锁的种类很多，不赘述
                - 在一个事务中，只有在`commit`或者`rollback`时，才会解锁


        - topic: InnoDB 缓冲池(buffer-pool)
          qs:
            - q: 避免每次读操作都进行磁盘 IO，具体来说，缓冲池缓存了大量数据页，让 CPU 读取和写入数据时，直接和缓冲区交互，不需要操作磁盘，从而避免磁盘拖慢数据库性能的问题（*注意缓冲池是 innoDB 引擎的特性，而不是 mysql 的*）
            - q: 缓冲池存哪些数据？
              x: 缓存表数据与索引数据，把磁盘上的数据加载到缓冲池，避免每次访问都进行磁盘 IO，起到加速访问的作用。
            - q: 缓冲池的工作机制？

        - topic: InnoDB 预读
          qs:
            - q: 什么是预读？
              x: 磁盘按页读取，如果要读取的数据就在页中，就能节省后面的磁盘 io，提高效率。数据访问遵循`集中读写`的原则，使用一些数据，大概率会使用附近的数据，这就是`局部性原理`
            - q: 什么是预读失败？
            - q: 如何对预读失败进行优化？
            - q: 什么是缓冲池污染？
            - q: 怎么解决缓冲池污染的问题？

        - topic: redolog
          qs:
            - q: redolog 是啥？为什么需要记录 redolog？
              x: "*undolog是逻辑日志，redolog是物理日志。但是redolog是由undolog产生的*"
            - q: 需要什么样的 redolog？
              x: 为了获得更好的读写性能，innoDB 将数据缓存到内存 (innoDB Buffer Pool)，对磁盘数据的修改也会落后于内存，如果进程崩溃就会导致内存数据丢失，所以 innoDB 就维护了 redolog，内存数据丢失后，innoDB 会在重启时，通过重放 REDO，恢复数据
            - q: redolog 中记录了什么内容？
            - q: redolog 是怎么组织的？
            - q: 如何高效地写 redolog？
            - q: 如何安全地清除 redolog？

        - topic: InnoDB Lock
          qs:
            - q: 聊聊innodb锁机制？
            - q: 多粒度锁机制
              x: 行锁分为共享锁和排他锁，但是 InnoDB 还有两种内部使用的意向锁，这两种意向锁都是表锁。表锁、页锁、行锁、字段锁，当然是锁粒度更小的，开销更小、加锁更快，这个是毫无疑问的。
            - q: 共享锁 (SL, shared lock), 排他锁 (XL, exclusive lock), 意向锁(I锁, intention lock), 记录锁(LOCK_REC_NOT_GAP), 间隙锁 (LOCK_GAP), 临键锁(LOCK_ORDINARY), 插入意向锁(LOCK_INSERT_INTENTION)
              x: XL和SL就是mutex和rwmutex，所有语言里都有类似的锁机制，不多说。IL其实就是IsLocked，用来判断是否加锁，进而决定下一步操作是sleep还是spin什么的，也很常用。下面的gap lock, next-key lock 都是MVCC相关的锁，可以理解。自增锁auto-inc lock是用来保证自增字段唯一性的，防止并发插入时，某个自增字段的数据重复。Record Lock相当于行级X锁。
            - q: 怎么理解插入意向锁? 到底是I锁还是gap锁? #
            - q: innoDB 间隙锁是什么？
              x: InnoDB 的锁定是通过在指向数据记录的第一个索引键之前和最后一个索引键之后的空域空间标记锁定信息实现的。这种锁定方式被称为 "NEXT-KEY locking"（间隙锁）
            - q: innoDB 间隙锁有哪些缺点？
              x: 锁定一个范围之后，即使某些不存在的键值也会被无辜锁定，造成锁定的时候无法插入键值锁定内的任何数据

            - q: MySql Lock wait timeout exceeded该如何处理?
              x: |
                Lock wait timeout exceeded; try restarting transaction

                死锁导致事务超时

                update语句锁全表导致的等待超时问题


        - topic: MySQL use
          qs:
            - q: 多表联查，有哪些连接查询？
              x: 内连接, 左/右连接, 全连接(有就是有，没有就写 Null，但是 MySQL 不支持，可以同时使用left join和right join), 交叉连接(笛卡尔积，交叉连接返回左表中的所有行，左表中的每一行与右表中的每一行组合，cross join)
            - q: 为啥最好用“子查询”而不是“联查”?
              x: 数据量小的时候，join 查询好用，大的时候，子查询好用。另外， join 查询最好不要超过 3 个表的关联，大公司一般是禁止用 join 的。
            - q: "***已经有大量数据的表怎么改字段? 为什么大佬都喜欢建表的时候加个 ext 字段?***"
              x: 因为大表加字段，执行alter操作会直接锁表，所以冗余几个JSON类型的ext字段。这样就可以直接把整个json发给前端，让他们自己处理。当然，mysql8的online ddl优化了加字段的操作，直接操作metadata了，可以秒加字段。但是建议还是建表时冗余几个ext字段。
            - q: 数据库不应该默认 null（因为负向查询`id!=1`不能命中索引，导致全表扫描）
            - q: "*是否要使用 in？*"
            - q: uuid、自增 id、snowflake 作为主键，分别有什么优缺点？
            - q: 金额应该用什么字段类型？金额为什么不能用 float 存？ (int, float, decimal)
            - q: 时间类型用什么字段类型？timestamp 还是 datetime，有什么区别？ 时区切换
            - q: 身份证图片存数据库，应该用什么字段类型？
            - q: 如何描述性别数据？ # 用 int，通常默认 0 未填写，1 男性，2 女性
            - q: 状态用什么字段类型？ # 状态的字段类型用枚举类型 enum 或者 tinyint
            - q: 为什么应该使用软删除，而不是硬删除？
            - q: select/insert/update for update 引发死锁
            - q: MySQL 分页排序时的数据重复问题？ (mysql8 order by priority queue, heapsort) 怎么解决？
            - q: 用 show status 查看 sql 的执行效率，定位执行效率低的 SQL 语句，有哪些关键字段？
            - q: 怎么监控 MySQL 索引的使用率？
            - q: "*监控 MySQL 需要采集哪些指标？怎么监控 MySQL 的流量？*" #
      use:
        - des: 怎么避免“批量插入操作太多”，报错 Prepared statement contains too many placeholders?
          sol: 分批插入嘛，insert操作最大限制65535
      # [MySQL CLI Cheatsheet](https://gist.github.com/hofmannsven/9164408)
      cmd:
        - c: CREATE <?FULLTEXT|PRIMARY> INDEX <索引名> ON <表名> <要加索引的字段>;
          x: 添加索引
        - c: DROP INDEX <index_name> ON <talbe_name>;
          x: 删除索引
        - c: SHOW INDEX FROM <table_name>;
          x: 查看索引
        - c: optimize table <table_name>
          x: 硬删除数据库数据后，清除对应文件，从而优化索引效率的。但是实际开发中不会使用硬删除，所以该语句的使用场景很有限
        - c: show variables like '%partition%'
          x: 查看 MySQL 是否支持分表
        - c: SHOW PROCESSLIST
        - c: select left()/right()/substr()/substring_index();
          x: 字符串函数
        - c: select cast(date as datetime) as date from table1;
        - c: select CONVERT('123', SIGNED);
          x: string转int，也可以使用select CAST('123' AS SIGNED);进行转换
        - c: avg(), min(), max(), count(), sum()
          x: 聚合函数
        - c: group_concat()
        - c: select COUNT(IF(channel_type=1,IF(check_status=6,1,0),0)) FROM tougao_record WHERE accept_company_id=100;
          x: 控制流函数if(), ifnull(), when case
        - c: 'select date_format(date_entered, "%Y-%m-%d") as ud, count(id) as cs FROM ttrss_entries GROUP BY ud;'
          x: 时间戳按天分组
        - c: select MONTH(date_entered) month, count(id) FROM ttrss_entries WHERE YEAR(date_entered) = 2020 GROUP BY month;
          x: 每个月的数据统计
        - c: select count(id) FROM ttrss_feeds WHERE DATE_SUB(CURDATE(), INTERVAL 7 DAY) <= DATE(last_successful_update);
          x: xxx时间内的数据统计
        - c: time_to_sec(timediff(t2, t1)), timestampdiff(second, t1, t2), unix_timestamp(t2) -unix_timestamp(t1)
          x: 怎么获取格式化时间的差值 (不要用datetime类型的时间直接相减，因为datetime相减做了一个隐式转换，将时间的Y-m-d H:i:s直接拼接起来转换为整数，而没有使用unix_timestamp()进行转换，由于时间不是十进制的，所以时间会出错)
        - c: select * from tablename WHERE 1=1 order by CONVERT( name USING gbk ) COLLATE gbk_chinese_ci ASC;
          x: 按中文字母排序：先使用 convert 把 column 进行 gbk 编码，再把编码后的内容根据 gbk_chinese_ci 进行 collate 排序
        - c: select elt(interval(score, 0, 60, 80, 100), '0-60', '60-80', '80-100') as 'score_interval', count(id) FROM student_score GROUP BY socer_interval;
          x: 目前有分数散布在1-100的n组数据，怎么根据统计区间呢？用interval()和elt()对结果进行分组
        - c: insert into test_tbl (id,dr) values (1,2),(2,3),(x,y) on duplicate key update dr=values(dr);
          x: insert into ... on duplicate key update
        - c: insert ignore into
          x: 批量插入时，如何不插入重复数据？没有 ignore 的话，插入数据如果有重复数据，直接报错，后面不执行。加上 ignore，不返回错误，只返回 warning
        - c: replace into test_tbl (id,dr) values (1,2),(2,3),(x,y);
          x: 不存在则插入，存在则修改 replace into 操作本质是对重复的记录先 delete 后 insert，如果更新的字段不全会将缺失的字段置为缺省值

    - url: https://github.com/jeremycole/innodb_ruby
      des: InnoDB Viewer. 具体来说就是用来学习InnoDB的可视化工具
    - url: https://github.com/zput/innodb_view
      des: 同上
    - url: https://github.com/cashapp/spirit
      des: MySQL Migrate工具，只支持MySQL8. 据说性能比 github/gh-ost 更好。
    - url: https://github.com/pressly/goose
      des: Database Migrate Tool that support postgres, mysql, sqlite, mssql, redshift, tidb, clickhouse, vertica, ydb, duckdb.
    - url: https://github.com/XiaoMi/soar
      des: |
        soar之类基于SQL指纹实现的sql优化工具，可以对sql进行预优化（也就是搭配slow-log在服务还没上线之前就对sql进行优化）。目前soar只支持mysql。
        feats包括索引优化、EXPLAIN解读、sql打分、自动SQL重写以及启发式规则建议（就是类似各种Linter或者logger一样，解释sql的具体问题）。试用了几个，在同类工具里算是比较好用的。
      qs:
        - q: 要求实现一个sql optimizer来给sql打分和美化，怎么实现？ # 具体来说就是用go-sql-driver之类的ORM对EXPLAIN进行解析，并把结果集的字段修改为中文后，输出为自定义格式
        - q: soar.yaml
        - q: "@sql指纹 sql fingerprint" # pt-fingerprint(percona fingerprint, using regex), TiDB SQL parser(AST)


- type: MySQL-HA
  repo:
    - url: https://github.com/vitessio/vitess
      doc: https://vitess.io/docs/
      des: vitess能解决所有mysql高可用方面的常见问题，比如什么主从复制、读写分离、分库分表、写库单点问题等等。
      qs:
        - q: Vitess 如何处理读写分离？
        - q: How does VTGate, VTTablet works?
        - q: sharding, Vitess 是如何实现数据库的水平扩展的？支持哪些类型的分片策略？
        - q: Vitess 中的 Resharding 过程
        - q: Vitess 如何处理大规模的事务？
        - q: Vitess 提供哪些机制来确保数据库的高可用性？
        - q: Vitess 如何支持多租户架构？
        - q: Vitess 的客户端如何处理连接池和事务？
        - q: 为什么Vitess推荐每个MySQL服务器250GB？
    - url: https://github.com/XiaoMi/Gaea
      des: MySQL HA. Just for ref.
    - url: https://github.com/MyCATApache/Mycat2
      des: 之前用过MyCAT1.6，但是已经EOL了，MyCAT2目前也EOL了。MyCAT2的feat有支持prom监控、XA事务、内置HAProxy
    - url: https://github.com/mariadb-corporation/MaxScale
      des: MaxScale是用来替代MHA（之前用 MHA+Consul）实现HA。由于 GTID 实现方式不同，Maxscale 最新版不支持 mysql 的故障自动转移，只支持读写分离功能。这部分内容是废的，MHA或者Maxscale这些组件实际上主要提供故障转移，但是vitess本身就支持，所以不需要搭配使用。
  des: Atlas, DBProxy, mysql-proxy, mysql-fabric, sharding-JDBC
  qs:
    - q: "***MySQL 中间件有哪些核心需求？***"
      x: |
        - 数据库虚拟化
        - 数据库对业务透明，业务不需要知道数据库的真实 IP、主从、读写、高可用等
        - 支持分库，且数据库的分库对业务透明

        ---

        - 非跨库需求
         - partition key 的简单查询
         - partition key 上的 in 查询
         - 非 partition key 上的简单查询
         - 排序 + 分页
        - 跨库 join
        - 跨库事务
        - 跨库子查询
    - q: MySQL分库分表
      x: 直接让`分库分表中间件`解决分表问题，业务和路由算法完全解耦，更灵活。其实这三点的目的都是类似的，都是为了降低大表问题，降低负载，是吗？只不过实现的方法不同，分库和分区是逻辑上拆分数据，分表则是物理上拆分数据。实际操作时通常是分表+分库。

    - q: "***什么是分区？分区有哪些缺点，为什么大部分互联网公司都不使用分区，而更多的选择分库分表来进行水平拆分呢？请简述一下分区和分表的各自优势和缺点？使用分库分表的先后顺序？***"
      x: |
        *应该先分表，再分库*，因为分表后可以解决单表的压力，但是数据库本身的压力没有下降，我们需要分库，真正隔离来优化服务。

        分区就是，所有数据，逻辑上还在一个表中，但物理上，可以根据一定的规则放在不同的文件中。业务代码无需改动。

        *不使用分区，主要是因为在高并发业务下，有很多问题*，主要是三点：如果 sql 不走分区键，很容易出现全表锁；分区表中使用关联查询，性能极差；使用分库分表，我们可以自己选择业务场景和访问模式，而分区则完全交给 MySQL，无法控制。

    - q: MySQL 有哪几种分表方法？MySQL 有哪几种路由规则？
    - q: 怎么实现 MySQL 分表？时间（按时间分区，大部分只查询最近的订单数据，那么大部分访问都集中在一个分区，比一个表小多了，数据库也可以更好地加缓存，从而提高性能）
    - q: MySQL 有哪些分表方法？
    - q: 分库分表带来的问题？



# [PostgreSQL Ecosystem - OSSRank](https://ossrank.com/cat/368-postgresql-extension)
- type: pgsql
  md: true
  repo:
    - url: https://github.com/postgres/postgres
      key: true
      doc: https://www.postgresql.org/docs/16/index.html
      qs:
        - q: 我有丰富的mysql的使用经验，可以直接平移到pgsql吗？使用时有哪些需要注意的？
        - q: How to optimize?
          x: analyze, explain, auto_explain之类的，类似mysql. AUTOVACUUM
        - q: "***Compare mysql and pgsql. 从CC, replication, index(bptree), transaction, perf, extensibility, ecosystem, operability, usability方面***"
          x:
        - q: HEAP存储引擎，OrioleDB引擎
        - q: heap表的物理结构是怎样的？
          x: pgsql每个数据库的表数据存储在$PGDATA/base目录下的子目录中，不同数据库之间是完全物理隔离的。表数据实际存在的物理文件可以通过查看文件系统目录看到。每个表有一个唯一的物理文件，这个文件以relfilenode命名，存储在对应的数据库目录下。如果对表执行了TRUNCATE操作，会生成一个新的relfilenode，即一个新的文件，但表的oid保持不变。
        - q: heap表文件的page是如何组织的？
          x: heap表文件的单个页面（page）被分为多个heaptuple数据元组。每个page有一个header部分，其中包含了管理元组的字段，如pd_lsn、pd_checksum、pd_flags等。每个heaptuple由HeapTupleData和HeapTupleHeaderData组成，其中HeapTupleHeaderData包含了事务相关的字段，如t_xmin、t_xmax等，用于实现PostgreSQL的事务语义和MVCC（多版本并发控制）。实际的数据存储在data area部分。
        - q: pgsql的WAL是如何与heap表存储引擎协同工作的？
          x: WAL是PostgreSQL中的一种日志机制，用于确保数据的一致性和可靠性。在heap表存储引擎中，当执行插入、更新或删除操作时，相关操作会被记录到WAL日志中。这些日志记录会在事务提交时写入到磁盘上的WAL文件中。在发生故障时，WAL日志可以用来恢复数据，确保数据不会因为系统崩溃而丢失。WAL机制与heap表存储引擎的写入操作紧密相关，确保了数据的持久性和一致性。
        - q: heap表文件的扩展文件有哪些？
        - q: heap表的写入逻辑是怎样的？
          x: heap表的写入操作首先会构造一个HeapTuple对象，然后通过一系列的函数调用，将该元组插入到一个可用的page中。这个过程包括初始化元组头、获取可用的page block-number、冲突检测、将元组信息添加到page中、标记page为dirty、写入WAL以及标记relation-cache中的旧tuple所在的buffer失效。值得注意的是，实际的数据落盘是通过checkpointer进程异步完成的，而不是在写入操作的主链路上直接落盘。
        - q: heap表的读取逻辑是怎样的？
        - q: PostgreSQL是如何处理内核fsync的bug的？
        - q: advisory lock 咨询锁
        - q: Replication
        - q: 不停机备份？ # dump, 文件级备份（PITR(Point-In-Time Recovery)）
        - q: 怎么操作pgsql故障恢复？ # 备份后，清除WAL，转储并重建数据库
        - q: pgsql的FTS有哪些缺点？ # 性能、缺少feat支持（facet分面）
        - q: FTS, textsearch, tsquery, tsvector, @@匹配运算符
        - q: 字组索引 pg_term, pg_bigm,
        - q: sharding # pgsql没有内置分片，可以使用citus实现sharding
        - q: pgsql 的WAL机制是如何保证数据一致性的？
    - url: https://github.com/orioledb/orioledb
      des: Next generation storage engine for pgsql.
    - url: https://github.com/dimitri/pgcopydb
    - url: https://github.com/zalando/patroni
      des: 用来实现pgsql高可用集群的中间件
    - url: https://github.com/EnterpriseDB/repmgr
      des: 同上，也是用来实现pgsql高可用集群的中间件
    - url: https://github.com/Vonng/pigsty
      des: Pretty Useful. 用来构建生产级可用的pgsql服务（类似RDS）。
    - url: https://github.com/CrunchyData/pgmonitor
      des: Used to collect metrics and alerting-resources from crunchy data.
    - url: https://github.com/amutu/zhparser
      des: zhparser = zh parser. pgsql extension for FTS of Chinese. 基于SCWS实现
    - url: https://github.com/Casecommons/pg_search
    - url: https://github.com/dimitri/pgloader
      des: 用来把数据import到supabase时发现的，支持各种sql（比如sqlite、mysql、mssql等）
    - url: https://github.com/kataras/pg
      des: postgres client for golang.
    - url: https://github.com/pg-sharding/spqr
      des: ??? Stateless Postgres Query Router
    - url: https://github.com/citusdata/citus
      des: Distributed PostgreSQL as an extension
    - url: https://github.com/paradedb/paradedb
      des: Postgres for Search and Analytics
    - url: https://github.com/CrunchyData/postgres-operator
      des: pgsql operator, 这种把pgsql放到k8s的operator确实挺鸡肋的
    - url: https://github.com/cloudnative-pg/cloudnative-pg
    - url: https://github.com/jackc/pgx
      des: pgx是一个为Go语言编写的PostgreSQL数据库驱动和工具包。它提供了一个低层次、高性能的接口，并且公开了PostgreSQL特有的功能，如LISTEN/NOTIFY和COPY。此外，它还包括了一个适配器用于标准的database/sql接口。






- type: redis
  md: true
  repo:
    - url: https://github.com/redis/redis
      key: true
      qs:
        - q: redis arch # (event, )
        - q: redis thread model? # 其实redis的线程模型没啥好说的，就是主线程+fork子线程
        - q: redis 内存模型? Malloc(jemalloc), Eviction Strategy, Expiration Strategy
        - q: redis virtual memory, THP and swap
        - q: 我们输入redis命令时，redis怎么handle这些请求(client requests)? # redis use reactor as event-driven
        - q: redis多线程之后，之前的那些阻塞操作（比如keys, bigkeys, HGETALL之类的各种遍历操作以及DEL之类的），还会阻塞吗？为啥？
        - q: redis lazy-free机制
        - q: 有哪些可能导致 Redis OOM的操作？ # monitor, setbit
        - q: RESP(redis serialization protocol)
          x: RESP 就是我们在主从复制和 pipeline 中使用的那个 redis 协议。实际上，所有 redis 命令的执行都是由 RESP 协议执行的（客户端发送命令给 redis 服务器时，redis 就会使用 RESP 协议来处理这些命令）。具体流程就是，序列化命令、解析并处理命令、处理完成后再序列化成 RESP 格式的响应、最后再通过 RESP 协议返回给客户端。
        - q: 2*3+2 (volatile/allkeys * LRU/LFU/random) + no-eviction, volatile-ttl
        - q: Why redis use 'Approximated LRU', other than LRU? 近似LRU和LRU有啥区别?
          x: 采样. 当 Redis 接收到新的写入命令，而内存又不够时，就会触发近似 LRU 算法来强制清理一些 key。具体清理的步骤是，Redis 会对 key 进行采样，通常是取 5 个，然后会把过期的 key 放到我们上面说的“过期池”中，过期池中的 key 是按照空闲时间来排序的，Redis 会优先清理掉空闲时间最长的 key，直到内存小于 maxmemory。redis 通过配置maxmemory-samples，默认为 3，数字越大，cpu 开销越大，越接近“理论 LRU 算法”
        - q: What are the "caching patterns"? How to ensure the consistency of cache and database?
        - q: redis服务调优? How to reduce the memory usage of redis?
        - q: 为什么 redis 建议关闭THP? # THP会导致COW期间复制内存页从 4KB 变成 2MB，导致fork子进程速度变慢、高并发下容易造成内存溢出，所以建议关闭

        # distributed lock
        - q: 怎么用redis实现distributed locks? Compare (etcd, redis, zk, chubby)?
          x: (avoid deadlock, reentrant, exclusive, ) (perf, consistency, retry-mechanism, lose-lock in MSR, expire)
        - q: "Deadlock: What It Is, How to Detect, Handle and Prevent?"
          x: (no mutual exclusion, no hold and wait, removal of no preemption, removal of circular wait)
        - q: "***双写一致性：怎么保证缓存和数据库的数据一致性? (, read/write through, , write-behind)***"
          x: 延迟双删(write-around + cache-aside)、异步重试(write-around + read through)、CDC旁路模式(canal) 先更 db 后删 cache 能在大部分情况保证缓存和数据库的一致性
        - q: CDC 怎么做到高可用呢?
          x: CDC 服务也要做到高可用的，可以定期将消费的 binlog pos 同步到 zk/etcd 等外部存储，多个 CDC 服务竞争任务。如果是 MySQL 切表的话，需要 CDC 服务也参与，还要区分是否开启 GTID, 各种集群实现。一般为了避免这种情况，CDC 服务都是连接 slave 从库
        - q: "***有哪些监控 redis 的指标？***"
      qq:
        - topic: RedisObject
          qs:
            - q: redis中各种datatype分别使用什么ds实现? # (..., bitmap, hyperloglog, pub/sub)
            - q: RedisObject, data structure? # type(datatype), encoding(ds), ptr, (lru, refcount)
            - q: How does type and encoding mapping in RedisObject? (type, notused, encoding, lru, refcount)
            #        - Redis的Hashtable是如何扩容的? hash扩容渐进式rehash过程?
            - q: redis 字符串的 []buf 有啥用？为啥还需要 free字段呢？
            - q: redis的scan命令的实现? # hashmap, rehash, expand/shrink
            - q: stream
            - q: redis, transaction # BASE(not ACID), OCC, (multi, exec, discard, watch/unwatch)
            - q: 那我如果想实现redis的原子操作，是用redis事务，还是用lua脚本呢？

            - q: redis lua中eval 和 evalsha 有什么区别？为什么推荐使用 evalsha？
            - q: redis 的 lua 脚本？用哪些命令管理 lua 脚本？redis 里使用 lua 脚本的流程？怎么在 redis 里调试 lua 脚本？lua 脚本超时时间？超时后怎么处理？
            - q: redis操作lua脚本 # script load/exists/flush/kill. script load加载，拿到返回的 sha1，再script exists判断脚本是否存在，最后evalsha sha1执行脚本
            - q: redis pipeline # (RESP buffer, ) (batch processing, not atomic (not support transaction))
            - q: 我有一个不太明白的问题哈，众所周知redis的transaction是BASE的，也就是弱一致性的。那为啥还要通过引入类似seata或者DTM这种Distributed Transation服务来使用AT和TCC这些弱一致性方案，而不是直接使用redis的transaction呢？既然都是弱一致性的。我们会在一个项目中使用各种数据库，比如postgres, mongo, elasticsearch, influxdb等等各种类型的数据库，分布式事务是怎么保证在这些数据库的数据一致性的呢？按照我的想法，分布式事务难道不应该是数据库服务本身应该提供的吗？比如说我们使用vitess实现mysql高可用，那vitess本身就应该给我们保证分布式事务的数据一致性。不是吗？


        - topic: redis persistence
          qs:
            - q: Compare AOF, RDB and hybrid? # (work, config/usage, pros and cons, related issues)
            - q: RDB (fork process+COW) (save time ops) (bgsave)
            - q: redis RDB的bgsave的 "save N M" 是怎么实现的？
              x: 轮询实现的，有个 serverCron 每100ms执行一次
            - q: 为啥RDB的需要配置这么多条规则呢?
              x: 因为 Redis 每个时段的读写请求肯定不是均衡的，为了平衡性能与数据安全，我们可以自由定制什么情况下触发备份。所以这里就是根据自身 Redis 写入情况来进行合理配置。
            - q: "***AOF 工作原理***" # 命令追加append,
            - q: AOF (append, write, fsync, rewrite compress) (fsync strategy) (bgrewriteaof)
            - q: Hybrid # (header(RDB)+incremental(AOF))
            - q: How does AOF compress logs?
            - q: Why does redis use fork to create child process, other than create a thread to rewrite AOF or RDB?

        - topic: redis MSR
          qs:
            - q: redis MSR具体流程?
              x: SYNC(RDB+RESP buffer), PSYNC = full(SYNC)+partial+RESP buffer. redis2.8之后使用FSYNC+PSYNC结合来实现MSR，
            - q: PSYNC(partial-sync) 具体流程?
              x: (offset, copybuffer, runid). offset 是偏移量。copybuffer 是复制积压缓冲区，每次主节点同步数据推自己的 offset 和 buffer 过来后比对双方数据的 offset，之后决定是否需要同步 buffer 里面的数据。而 runid 是每个 slave 节点启动时发给 master 节点，用于标识之前是否同步过，决定进行全量还是部分复制。
            - q: position-based
            - q: redis psync full-sync
            - q: 命令传播
              x: 命令传播阶段主要有两个点，一个是*同步增量数据*，一个是*主从之间发送心跳*确认双方在线，slave 节点还会去发送自己的 offset 去获取更新命令


        - topic: redis-sentinel
          qs:
            - q: What's redis-sentinel?
              x: HA, collateral tasks(monitor, failover). sentinel 解决高可用问题，master 宕机时故障转移
            - q: How does it works?
              x: gossip(to notification leader is dead)+raft(to elect leader(smaller priority > larger offset > smaller runid))
        - topic: redis-cluster
          qs:
            - q: What's redis-cluster? How does it works? # 集群嘛，解决拓展性问题. meet/ping/pong/fail
            - q: Why does redis-cluster use hash-slots to implement consistent hash? # slot=CRC16(key)/16384
            - q: Hash Slot Resharding and Rebalancing for Redis Cluster.
        - topic: redis-sharding
          qs:
            - q: What's redis-sharding?
            - q: range, hash(id=hash(key)%N)
        - topic: RedLock
          qs:
            - q: "***分布式锁有哪些常见问题?***"
              x: |
                - `时钟漂移问题` 因为 redlock 算法没有对各 redis 实例的时钟校准，所以对上述`第三步`中`各实例返回加锁成功时间`都减去一小段时间，来抵消时钟漂移
                - `失败重试机制` 如果获取锁失败，会随机时间后再获取锁，以免竞争导致每个客户端都无法获取锁
                - `羊群效应 (Hard Effect)` 分布式锁的一种常见问题，所有客户端都尝试对某个临时节点去加锁，当一个锁被占有时，其他对客户端都会监听这个临时节点
            - q: 为啥RedLock比SETNX和Redisson更靠谱?
              x: 因为能够同时解决 忘记释放锁、锁超时释放（业务还没执行完）和redis主从复制时锁丢失（客户端 A 对 master 节点加锁，master 节点主从复制给 slave 节点，此时 master 节点宕机，主从切换，slave 节点成为 master 节点; 此时客户端 B 来尝试加锁时，新 master 节点仍然可以加锁，而客户端 A 认为自己加锁成功，进行解锁操作，但是解锁失败; 多个客户端都可以完成加锁，真正需要解锁却解不了锁;）。说白了就是“未释放或者错误释放”的几种情况。
            - q: RedLock的原理? RedLock是怎么解决“redis主从复制时锁丢失”问题的?
              x: 核心思想是，对redis集群中所有node获取锁，如果超过一半的node在锁的一半有效期内成功加锁，客户端认为获取了锁。如果完成该操作，则全部解锁。（其实就是通过redis集群的方法来避免主从复制时的锁丢失）
      use:
        - url: https://github.com/HDT3213/delayqueue
          des: How to use redis to implement delay-queue? # (zset+lua) 使用 zset，拿时间戳作为 score，消息内容作为 key 调用 zadd 来生产消息，消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。
        - des: 限流，redis 实现限流有哪些方案？
        - des: redis 实现分页
        - des: redis 实现多条件查询
        - des: 怎么使用 redis 实现流量整形
        - des: 怎么把 redis 数据刷回 MySQL
        - des: 如何删除 redis 里的 key？
        - des: MySQL 里有 200W 数据，redis 只存 20W 数据，如何保证 redis 中都是热点数据？
        - des: 如何分析 Redis 里存了什么？ # 使用 RDB 备份，解析生成的 RDB 文件
        - des: 使用redis时，能否列举一些既能用其他数据类型，也能用stream，但是stream更好的使用场景吗？ # 现在看起来Streams像是一个追加模式的，以时间为分数，元素是小型Hash的zset。更省内存，在很多场景下可以代替zset（最常见的就是有ts但是只需要类似“比分”这样简单数据的场景（股票价格、气象数据、MQ的任务分发等、IM场景）） 用stream代替list
      cmd:
        - c: object encoding key
          x: 查看某个 key 具体使用了哪种数据结构
        - c: object refcount key
          x: 查看某个 key 的共享对象的引用次数
        - c: redis-cli --bigkeys
          x: 用来查看所有bigkey
        - c: redis-benchmark
          x: redis 性能测试工具
          u: https://redis.io/docs/management/optimization/benchmarks/
        - c: redis-check-aof
          x: 检查 aof 日志的工具
        - c: redis-check-dump
          x: 检查 rdb 日志的工具
        - c: CONFIG RESETSTAT
          u: https://redis.io/commands/config-resetstat/
        - c: INFO
          u: https://redis.io/commands/info/

        - c: migrate
          x: 实际上是 dump+restore+del 三个命令的组合，但是是原子性命令，支持源 redis 和目标 redis 之间直接迁移，比 dump+restore 好用，可以直接替代
        - c: rename
          x: key重命名会执行 del 删除旧键，如果数据太大，会阻塞 redis
        - c: SETBIT key offset value
          x: SETBIT；“置位”
        - c: GETBIT key offset
          x: GETBIT；“取值”
        - c: BITCOUNT key [start end]
          x: 返回位图中第一个值为 bit 的二进制位的位置；在默认情况下，命令将检测整个位图，但是用户可以通过可选的 start 参数和 end 参数指定要检测的范围
        - c: BITOP operation destKey key [key...]
          x: BITOP 支持 and，or，not，xor 这四种操作；很常用的一条命令
        - c: SLOWLOG GET <?N>
          x: 查看最新的N条慢日志，包括命令本身、执行时间和执行时所在的时间戳


    - url: https://github.com/redis/go-redis
      doc: https://redis.uptrace.dev/guide/
      des: redis client. Better than redigo.
    - url: https://github.com/go-redis/cache
      des: 使用 Redis 作为后端存储，并使用 MessagePack 来序列化缓存的值。可以选择使用 TinyLFU 或其他算法作为本地进程内缓存。
    - url: https://github.com/redis/rueidis
      des: 更轻量的redis，可以把rueidis理解为另一种leveldb或者boltdb之类的，但是更重要的是我们可以把redis无缝替换为rueidis。
    - url: https://github.com/valkey-io/valkey
      des: FOSS redis
    - url: https://github.com/go-redsync/redsync
      des: redis distributed mutex lock

    - url: https://github.com/bsm/redislock
      des: distributed lock implemented using redis
    - url: https://github.com/tair-opensource/RedisShake
      des: redis数据迁移工具，用来在不同的redis实例之间迁移、同步、备份数据。

    - url: https://github.com/RediSearch/RediSearch
      des: Redis Modules, Used to support FTS. 如果没有用ES，又把redis作为数据源的话，可以用RediSearch代替ES。RediSearch还支持secondary index, 比如说如果redis中存了大量文章，就可以把文章的标题和内容作为索引的字段，执行搜索操作时，就可以快速定位到包含关键字的文章，而不需要遍历整个数据集。
    #    - url: https://github.com/redisson/redisson
    - url: https://github.com/CodisLabs/codis
      des: redis HA, 已经EOL了
    - url: https://github.com/twitter/twemproxy
      des: redis proxy, HA, 也EOL了
    - url: https://github.com/spotahome/redis-operator
      des: 用来在k8s上部署redis的CRD，可以用来自动化部署redis集群，并支持redis HA

    ## redis GUI
    - url: https://github.com/ErikDubbelboer/phpRedisAdmin
    - url: https://github.com/RedisInsight/RedisDesktopManager
    - url: https://github.com/gphper/grm





- type: RDB
  repo:
    - url: https://github.com/duckdb/duckdb
      des: |
        有点离谱，更轻量的嵌入式RDB，其官方称之为In-Process RDB
        专注于OLAP，也就是适用于读多写少的场景，而不是像其他RDB一样，同时支持OLAP和OLTP

    - url: https://github.com/enpeizhao/duck_db
    - url: https://github.com/pingcap/tidb
      des: AP数据库，因为tidb使用Raft实现 consistency。当然，TiDB 默认采用悲观事务模式，当然也支持不同级别的事务（RC、RR、SI）。
      qs:
        - q: TiDB 的架构和特性有哪些？
          x: 其架构包括 TiDB Server、PD Server 和存储节点（TiKV 和 TiFlash）
        - q: 为什么要range范围计算？怎么优化？DNF和CNF是怎么转化成范围区间的？
          x: TiDB 在进行表扫描前会对查询条件进行优化，将 Selection 算子的过滤条件化简为区间扫描。这个过程包括将逻辑表达式转化为析取范式（DNF）和合取范式（CNF），然后生成扫描区间。
        - q: TiDB 的乐观事务是如何实现的？
          x: TiDB 的乐观事务基于 Percolator 分布式事务模型，通过两阶段提交（2PC）来实现。在 Prewrite 阶段，事务会获取一个 start_ts 作为开始时间戳，并对要写入的数据进行加锁。在 Commit 阶段，会获取一个 commit_ts 作为提交时间戳，并清理在 Prewrite 阶段留下的锁。乐观事务追求极致性能，在高冲突率的场景中可能会失败。
        - q: TiDB 插入（Insert）语句的处理流程是怎样的？
          x: TiDB 插入数据的流程包括构建执行计划、执行 Insert 计划、处理数据填充、维护索引等步骤。在执行 Insert 计划时，会根据字段类型获取数据并进行填充，然后批量设置自增 ID，并将数据写入存储引擎。如果遇到唯一键冲突，TiDB 会根据配置进行错误处理或事务回滚。
        - q: TiDB 的执行计划执行过程是怎样的？
          x: TiDB 的执行计划执行过程包括生成执行器、执行 SQL 语句、获取 TiKV 数据等步骤。执行器会根据执行计划中的算子类型构建不同的 Executor，然后执行 Open 方法进行数据处理。数据获取过程中，会向 TiKV 发送请求并获取返回的结果。
        - q: TiDB 的执行优化包括哪些内容？
          x: TiDB 的执行优化包括构建执行计划、逻辑计划优化和物理计划优化。逻辑优化基于规则进行，而物理优化则基于代价进行。优化过程中会考虑谓词下推、列裁剪、聚合消除等因素，以提高查询效率。
        - q: TiDB 的 Percolator 分布式事务?
          x: Client、TSO、BigTable
    - url: https://github.com/drawdb-io/drawdb
      doc: https://drawdb.vercel.app/editor
      des: 官方介绍 "database design tool and SQL generator."，实际上就是个用来画ER Diagram的工具。支持导出到5种RDB（mysql, pgsql, sqlite, mariadb, sqlserver），所以归类到RDB下面。感觉没啥用。
  des: 可以看到RDB实际上还是MySQL及其衍生物，比如MariaDB和Percona, 然后就是Oracle和SqlServer


- type: tsdb
  repo:
    - url: https://github.com/influxdata/influxdb
      des: TICK(Telegraf + Influxdb + Chronograf + Kapacitor) 技术栈的核心
      qs:
        - q: influxdb feats?
          x: ts, metrics, event
        - q: influxdb, storage engine?
          x: TSM(LSM), Tree(cache, wal, TSM file, compactor)
        - q: 聊聊TICK技术栈?
          x: |
            - influxdata提供的stack
            - Chronograf 不如grafana或者kibana好用
            - kapacitor可以通过对influxdb中的数据进行分析处理，它提供了丰富的函数可以自定义不同的条件，根据符合的阀值，输出日志、输出警告到slack、POST数据至HTTP endpoint、执行脚本等等各类触发条件。

            Influxdb是TICK最核心的服务，因为它是专门设计用于存储和查询时间序列数据的数据库。InfluxDB 的设计允许它高效地处理大量数据，并且能够快速地查询和分析这些数据，这对于监控系统来说是至关重要的。其他组件如Telegraf、Chronograf和Kapacitor都是围绕着InfluxDB构建的，以提供数据收集、可视化和事件处理的功能

    - url: https://github.com/taosdata/TDengine
      des: 相比于influxdb，TDengine支持强一致性、且性能更好（性能优势很大，官网提供了benchmark），更适合写多读少的场景。想要取代目前influxdb在物联网（嵌入式设备）中的地位。
    - url: https://github.com/VictoriaMetrics/VictoriaMetrics
    - url: https://github.com/cnosdb/cnosdb
      doc: https://docs.cnosdb.com/docs/
    - url: https://github.com/influxdata/kapacitor
      des: 数据处理平台，用于处理时间序列数据，可以执行复杂的事件检测和警报
    - url: https://github.com/influxdata/chronograf
      des: 类似grafana或者kibana，用于提供InfluxDB数据的可视化和查询
    - url: https://github.com/GreptimeTeam/greptimedb
    - url: https://github.com/influxdata/telegraf
      des: 工业互联网 influxDB+telegraf+OneNet+Hightopo 完美适配了工业数据采集的高并发、低数据、简单关系、强时序的使用场景。插件驱动的代理，用于收集、处理、聚合和发送指标到各种输出，如InfluxDB。



- type: kvdb/cache
  md: true
  repo:
    - url: https://github.com/rosedblabs/rosedb
    - url: https://github.com/etcd-io/bbolt
      des: boltdb
    - url: https://github.com/br0xen/boltbrowser
      des: A CLI Browser for BoltDB Files
    - url: https://github.com/lotusdblabs/lotusdb
    - url: https://github.com/memcached/memcached
    - url: https://github.com/dragonflydb/dragonfly
    - url: https://github.com/OpenAtomFoundation/pika
    - url: https://github.com/ideawu/ssdb
    - url: https://github.com/dgraph-io/badger
      des: BadgerDB 是一个快速的嵌入式键值存储引擎，专为 Go 语言设计。它具有高性能、低内存占用和持久性的特点，适用于各种应用场景。
    - url: https://github.com/facebook/rocksdb
      des: RocksDB 是一个高性能的嵌入式键值存储引擎，由 Facebook 开发。它基于 Google 的 LevelDB，但进行了许多优化和改进，提供了更高的性能和可靠性。市面上开源 kv 轮子一大堆，架构上都是 rocksdb 做单机引擎，上层封装 proxy, 对外支持 redis 协议，或者根据具体业务逻辑定制数据类型，有面向表格 table 的，有做成列式存储的。
      qs:
        - q: RocksDB 对 LevelDB 进行了哪些优化?
          x: 无非是批量写入(Pipeline Write)和并发处理(并发写memtable)
        - q: RocksDB 的 Pipeline Write 机制
        - q: RosksDB 中 LSM-Tree 写入流程?
          x: 两步。首先将键值对（KV）追加写入到WAL（Write-Ahead Logging）日志，并强制刷盘以保证数据的持久化。然后将该KV写入到memtable。
    - url: https://github.com/google/leveldb
      des: 相比于其他kvdb，其特性是在存储时，key 值根据用户指定的 comparator 函数进行排序。除此之外，通过WriteBatch可以实现atomic操作（不是transaction也不是lua脚本，更类似pipeline（但是支持atomic）），还默认使用snappy算法对数据进行压缩（compact机制）。leveldb默认异步写（而不是同步写，为了更好的性能）
      qs:
        - q: 怎么用Comparator自定义排序？
    - url: https://github.com/cockroachdb/cockroach
    - url: https://github.com/tikv/tikv
    - url: https://github.com/pingcap/tiflash
      des: 提供行存储引擎 TiKV、列存储引擎 TiFlash 两款存储引擎，TiFlash 通过 Multi-Raft Learner 协议实时从 TiKV 复制数据，确保行存储引擎 TiKV 和列存储引擎 TiFlash 之间的数据强一致。
    - url: https://github.com/EchoVault/EchoVault
    - url: https://github.com/patrickmn/go-cache
      des: FRO. 最简易的kvdb.
    - url: https://github.com/dgraph-io/ristretto
      des: FRO.
  qs:
    - q: "***cache指标***"
      x: QPS和hit-ratio
    - q: cache hit ratio? How to calculate? How to monitor?
    - q: What about cache strategy?
      x: (LRU/LFU/ARC/TTL)
    #  - How to ensure the consistency of database and cache?
    - q: What causes? How to resolve?
    - q: "***缓存雪崩(cache avalanche), 缓存穿透(cache penetration), 缓存击穿(cache breakdown). 怎么处理以上问题?***"
      x: |
        - (large number cache invalidation) (random expire, LFU, )
        - (bloomfilter) 总结一下，击穿和穿透都是某个 key 被高并发请求，表现都是缓存层被穿透，数据库被高并发请求，**区别在于这个 key 在数据库中是否存在，如果 key 存在就是击穿，key 不存在就是穿透**。

        gozero 本身提供的对 cache 的处理就很好

        - 缓存穿透：即使查不到，也自动缓存，1min 过期
        - 缓存击穿：通过 mutex 保证只有一个请求去访问数据库. 或者 singleflight
        - 缓存雪崩：给缓存 key 自动设置随机过期时间，确保不会集中过期

    - q: What's cache warming? What are the specific implementation methods for cache warming? (pipeline)

    # local cache
    - q: What local caching options are there? What are the usage scenarios of local cache? Which one is better to use?






- type: GraphDB
  repo:
    - url: https://github.com/vesoft-inc/nebula
    - url: https://github.com/neo4j/neo4j
    - url: https://github.com/JanusGraph/janusgraph
    - url: https://github.com/authzed/spicedb
    - url: https://github.com/surrealdb/surrealdb
      des: document-graph database??? 怎么理解






- type: ColumnDB
  des: DBMS
  repo:
    - url: https://github.com/ClickHouse/ClickHouse
      des: 通常用在大数据的ETL中作为OLAP使用。具体来说就是日志分析、广告和推荐引擎、金融数据分析、物联网数据分析。相比于RDB，Vertical的优势在于存储效率、查询性能、数据压缩。
    - url: https://github.com/ClickHouse/clickhouse-go
    - url: https://github.com/apache/cassandra
    - url: https://github.com/apache/hbase






- type: DocumentDB
  md: true
  repo:
    - url: https://github.com/mongodb/mongo
      doc: https://docs.mongoing.com/
      cmd:
        - c: show collections
          x: 显示当前数据库中的所有集合
      qs:
        - q: Compare mongo and mysql.
          x: (SE, transaction, scalability, memory usage higher than mysql, aggregate的表达力弱于SQL)
        - q: How does mongo query works?
          x: (BSON+cursor) 执行查询操作(find, aggregate, count, ...)时，MongoDB 会把查询条件转化成 BSON，进行查找。返回数据时用 cursor 分批返回数据。 这个cursor类似redis scan或者mysql分页。
        - q: mongo存在mysql的连解查执吗？能否从存储引擎（包括存储引擎本身的区别，以及选择）、读操作机制（查询机制）、写操作机制、事务支持（ACID）、数据模型、数据持久化等方面，比较一下mysql和mongo
      qq:
        - topic: mongo transaction
          qs:
            - q: How to use transaction in mongo?
            - q: Why to use WiredTiger as default engine in MongoDB? Compare with InnoDB? # (CC, perf, durability)
            - q: Why does mongodb use WiredTiger instead of mmap?
            - q: mongo replication lag, How to resolve? # write-concern
            - q: mongo的WiredTiger为啥用btree，而不是b+tree呢? 哪些场景下WiredTiger使用LSM?


    - url: https://github.com/mongodb/mongo-go-driver
      des: mongo-go-driver
    - url: https://github.com/apache/couchdb
      des: Reduce简化器, Map



- type: 嵌入式RDB
  repo:
    - url: https://github.com/sqlite/sqlite
      des:
      qs:
        - q: sqlite (datatype, transaction, index, FTS)
      cmd:
        - c: sqlite3 data.db '.backup backup.db'
          x: .backup 命令创建一个内容一致的数据库备份副本。如果备份期间有很多写入活动，则副本创建的速度可能会很慢。
        - c: sqlite3 data.db '.dump' > dump
          x: .dump 命令创建一个数据库内容的转储。
    - url: https://github.com/benbjohnson/litestream
      des: 一个将SQLite数据库流式复制到S3兼容的存储系统的解决方案, 也可以用于备份。相当于某种sqlite的MS复制方案，适用于大型应用（但是很好奇为啥大型应用还要用sqlite，哈哈）。底下来列出了一些备选方案，比如直接用sqlite内置备份命令，再加上s3的sync命令来实现。以及LiteFS 或者 VFS 来实现。感觉意思不大。
    - url: https://github.com/LMDB/lmdb
      des: |
        与sqlite类似的嵌入式RDB，但是不如sqlite。

        - 相同数据的情况下, 比sqlite3的数据库大13%
        - key大小限制。lmdb的key被限制在1978个字节以内, 这在一些情况下会非常容易超出限制。
    - url: https://github.com/kriszyp/lmdb-js
      des: |
        Node.js和Deno的LMDB绑定

        Simple, efficient, ultra-fast, scalable data store wrapper for LMDB
    - url: https://github.com/mattn/go-sqlite3
    - url: https://github.com/nalgeon/redka
      des: 基于sqlite实现的redis




- type: VectorDB
  repo:
    - url: https://github.com/facebookresearch/faiss
      des: vector plugin
    - url: https://github.com/milvus-io/milvus
    - url: https://github.com/weaviate/weaviate
    - url: https://github.com/qdrant/qdrant
    - url: https://github.com/farouqzaib/fast-search





---


- type: js
  repo:
    - url: https://github.com/npm/cli
      cmd:
        - c: npm list -g
          x: 查看所有全局包列表
        - c: npm root -g
          x: 查看全局包位置
        - c: npm config set prefix <目标目录>
          x: 修改全局包位置
        - c: npm install -g <pkg>
          x: 全局安装
        - c: npm rm -g <pkg>
          x: 全局卸载，相当于npm uninstall，rm是uninstall的alias，需要注意的是只写pkg名就可以了，不要加version. 比如 npm rm -g create-react-app.
    - url: https://github.com/yarnpkg/berry
      des: yarn
    - url: https://github.com/pnpm/pnpm
      des: pnpm
    - url: https://github.com/dylang/npm-check
      des: |
        可以认为 npm-check = depcheck + npm-check-updates. 可以用来检查并自动更新dependency，也支持检查unused依赖项. Check for outdated, incorrect, and unused dependencies in package.json.
        - url: https://github.com/depcheck/depcheck
          des: = npm-check
        - url: https://github.com/raineorshine/npm-check-updates
          des: 顾名思义，相当于 `npm-check -u`，用来检查pkg版本

    - url: https://github.com/nvm-sh/nvm
      des: Node Version Manager 用来管理node版本
    - url: https://github.com/cheeriojs/cheerio
      des: parse HTML
    - url: https://github.com/tailwindlabs/tailwindcss
      des: CSS in HTML，其实就是类似bootstrap那种CSS框架嘛。对我们这种不会写css的人来说很有用（但是定制性更强，不如bootstrap简单。当然事情都有两面，在前端也日渐复杂的今天，对职业前端开发来说，简单并不是好事。），至于其优缺点，在我看来都很小，所以也就都无所谓了。使用tailwind时一定要用IDE插件，否则就要一直查官方文档，非常头疼。
    - url: https://github.com/shuding/nextra
      des: used to dev website using MDX+Next.js
    - url: https://github.com/PaulieScanlon/mdx-embed
      des: used to embed in MDX, such as media like youtube, tiktok, etc. And code-snippets like CodePen, Gist, Replit, CodeSandbox etc.
    - url: https://github.com/sveltejs/svelte
      des: 基于编译器的前端框架
    - url: https://github.com/sveltejs/kit
      des: svelte的meta-framework
    - url: https://github.com/axios/axios
    - url: https://github.com/trpc/trpc
      des: 可以用来代替axios，但是更typesafe
    - url: https://github.com/vuejs/core
    - url: https://github.com/nuxt/nuxt
      des: 让vue支持SSR
    - url: https://github.com/vercel/next.js
      des: react生态下的几个meta-framework, next.js适合做SSR, umi适合做CSR, 拓展性也更好, 还内置了很多贴地气的功能，比如配置式路由、补丁方案、antd 的接入、微前端、国际化、权限等. next.js和Gatsby都是MPA和SPA的结合使用，比如SSR/SSG 同构方案就是一个典型的体现，首先框架侧会在服务端生成完整的 HTML 内容，并且同时注入客户端所需要的 SPA 脚本。这样浏览器会拿到完整的 HTML 内容，然后执行客户端的脚本事件的绑定(这个过程也叫 hydrate)，后续路由的跳转由 JS 来掌管。
    - url: https://github.com/umijs/umi
      cmd:
        - c: umi dva list model
          x: 列出所有 model
        - c: umi plugin list
          x: 列出所有插件
        - c: umi generate page xxx --typescript --less
          x: 目前只支持生成 page，生成基本页面 (其他文件如 model 都只能手动创建)
        - c: umi generate dvx:model xxx
      des: react meta-framework
    - url: https://github.com/remix-run/remix
      des: 也是react的meta-framework
    - url: https://github.com/jestjs/jest
      des: /js-unittest/. Better than mocha
    - url: https://github.com/webpack/webpack
    - url: https://github.com/vitejs/vite
      des: 打包工具，better than gulp, grunt and webpack. vite 就是个更好用的 webpack，但是解决了 webpack 那些众所周知的问题，比如说打包速度慢、配置复杂之类的。
      qs:
        - q: Compare webpack, vite, babel, gulp, grunt?
    - url: https://github.com/expressjs/express
      des: Express
      qs:
        - q: MERN(MEAN/MEVN) 技术栈有啥优缺点
    - url: https://github.com/element-plus/element-plus
      des: for Vue
    - url: https://github.com/ant-design/ant-design
      des: for react
    - url: https://github.com/chakra-ui/chakra-ui
      des: sucks
    - url: https://github.com/shadcn-ui/ui
      des: 非常漂亮的 UI. ALL of these Table-Implements is based on "@tanstack/react-table", exactly as the "PesterDataTable" components. but shadcn/ui is a scaffold nor a lib, so we can't integrates it with docusaurus.
    - url: https://github.com/facebook/docusaurus
      des: docusaurus is pretty stable and robust. 但是docusaurus的TOC是inline的而不是全局的（这就导致在移动端很难在heading之间），这点就很烦，并且maintainer已经明确说了不太可能换成全局TOC，因为成本很高。
      qs:
        - q: 比较几种SSG (MPA/SPA, perf(RT, compilation(build tool)), UI) # docsify, gitbook, astro
        - q: 切换SSG之前，需要考虑哪些checklist (migration cost) # support "docs mode", plantUML, image zoom, code block?, admonitions syntax, Tabs(items) syntax
        - q: markdown 图片缩放？(markdown 语法中并不支持控制图片显示大小，只能通过 css 来控制)
        - q: 怎么添加 docusaurus 不支持的语言？
        - q: How to custom sidebar? How to sort sidebar manually, also auto-generate docs inside?
        - q: How to set "Docs" as the main page?
        - q: How to hide(or remove) navbar?
        - q: 怎么给docusaurus添加评论插件? 比较几种评论插件，哪个更好用? docusaurus 怎么集成 giscus插件?
          x: Discussions(giscus), Issues(utterances, gitalk), third-party(Disqus), self-hosted(artalk)
        - q: docusaurus本身不支持渲染PlantUML，那么怎么实现呢?
          u: https://github.com/show-docs/remark-kroki
          x: oki 的 docusaurus 插件，支持 PlantUML，需要自己部署 kroki 服务，或者使用官方提供的免费服务
        - q: docusaurus本身不支持“点击展示大图”，怎么实现?
          u: https://github.com/gabrielcsapo/docusaurus-plugin-image-zoom
          x: 用来“点击展示大图”，但是“scroll 之后zoom图片就直接关闭了”，就很蠢。
        - q: docusaurus支持哪些站内搜索? 除了algolia，有哪些本地搜索方法?
          u: https://github.com/easyops-cn/docusaurus-search-local
          x: algolia 需要开源 repo，且 blog 能够直接访问，所以我们直接使用本地搜索。比 cmfcmf/docusaurus-search-local 好用，样式好看，还支持中文搜索，支持快捷键搜索操作。
      cmd:
        - c: docusaurus build --bundle-analyzer


- type: Typescript
  repo:
    - url: https://github.com/microsoft/TypeScript
      qs:
        - q: es
        - q: vue, Lifecycle Hooks
        - q: nuxt.js
        - q: react-hooks
        - q: How to set default parameter in ts?
        - q: Compare SPA and MPA.
          x: (SSR or CSR) (perf(首屏加载), SEO, route, state management)
        - q: How to evaluate Astro? # islands arch, MPA
    - url: https://github.com/TypeStrong/ts-node
      des: 用来在node环境执行ts代码
    - url: https://github.com/sudheerj/ECMAScript-features
      des: ES syntax. ECMA实际上是对所有js Engine(比如v8，而不只是interpreter)的spec，因为所谓的syntax本身就是Engine提供的。
      qs:
        - q: 变量声明和赋值 # var, let, const
        - q: class, extends, super
        - q: arrow functions
        - q: template string
        - q: default, rest arguments
        - q: 数组操作
        - q: 模块化
        - q: 异步编程 (Promise对象和异步操作, async/await异步函数)
        - q: 迭代器和生成器



- type: Data-Visualization
  repo:
    - url: https://github.com/apache/echarts
    - url: https://github.com/d3/d3



---


- type: ghac
  repo:
    - url: https://github.com/actions/runner-images
      des: 所有gh-actions内置的images，之前玩 nektos/act 的时候，想本地执行gh-actions要预装一个50GB的docker image，就是这堆东西，里面主要是各种lang和compilers，还有各种pkg manager，各种utils和cli tools, linters等等。
    - url: https://github.com/mxschmitt/action-tmate
      des: Used to debug gh-actions via SSH, but I haven't used it yet.
    - url: https://github.com/actions/toolkit
      des: Used to develop gh-actions.
    - url: https://github.com/actions-go/toolkit
      des: Developing with TS is a better choice, but we can also develop ghac with docker. This toolkit is divided into inputs, outputs, results, logging, secrets and variables. There is no documentation, so we can directly view the source code, which is very simple to implement and use. we can load these inputs, directly use `os.Getenv()`, so it sucks.
    - url: https://github.com/actions/gh-actions-cache
      des: Used to manage the GitHub Actions caches being used in a GitHub repository. (Just a cli tool, Not a gh-actions)
    # [如何为 Rust 项目配置 GitHub Action cache](https://liujiacai.net/blog/2022/10/29/github-action-cache-for-rust/)
    # [Mark Phelps: Speed Up Your Go Builds With Actions Cache](https://markphelps.me/posts/speed-up-your-go-builds-with-actions-cache/)
    - url: https://github.com/actions/cache
      des: Pretty Useful. restore-key
    - url: https://github.com/oprypin/find-latest-tag
      des: Find the latest tag in a GitHub repository
    - url: https://github.com/diggerhq/digger
      des: Digger允许你在现有的CI（持续集成）流水线中运行IaC。它提供了一种在CI环境中本地运行Terraform的方式，以实现安全性和成本效益。你可以使用Digger在GitHub上的项目中运行Terraform，并通过PR（拉取请求）评论执行Terraform的计划和应用操作。它还支持Open Policy Agent（OPA）用于基于角色的访问控制、PR级别的锁定、漂移检测等功能。你可以通过GitHub Actions与AWS或GCP集成来使用Digger。
    - url: https://github.com/securego/gosec
      des: Go security checker
    - url: https://github.com/containrrr/watchtower
      key: true
      des: Used to automatically fetch container's newest image.
    - url: https://github.com/bonaysoft/uptoc
      des: 用来把文件传到S3, Google Storage, Qiniu, cos, Aliyun OSS的工具。比较常见的使用场景是把前端打包好的dist传到CDN上。
    - url: https://github.com/appleboy/ssh-action
      des: 操作 ssh
    - url: https://github.com/appleboy/scp-action
      des: shell

    - url: https://github.com/stefanzweifel/git-auto-commit-action
      des: 根据预设规则对文件变更进行自动化提交，并附上自定义的提交信息。这在自动化测试（当你更新Markdown文件时，自动提交并推送更新，确保文档与代码保持同步）、CICD（在测试成功后自动将构建产物更新到特定分支）或者文档更新（每次内容变化时，自动构建并更新站点）等场景下非常有用。

    - url: https://github.com/goreleaser/goreleaser
      key: true
      cmd:
        - c: goreleaser check
        - c: goreleaser build
    - url: https://github.com/goreleaser/goreleaser-action
      des: goreleaser-action
    - url: https://github.com/docker/login-action
      des: Used to login DockerHub
    - url: https://github.com/docker/build-push-action
      des: Used to push image to DockerHub. Usually used with login-action.
    - url: https://github.com/aliyun/acr-login
      des: Used to login ACR(Aliyun Container Registries)
    - url: https://github.com/hhyasdf/image-sync-action
      des: 基于 image-syncer 实现，用来同步一些基于Docker Registry的服务（比如ACR, DockerHub, Quay, Harbor） What should be noted that it is not a two-way synchronization, but supports synchronizing an image to multiple docker-registries. The main usage scenario of this tool is to directly synchronize the packaged image to multiple platforms during release. There is no need to write a separate job for each docker-registry as before. Using this, we can directly synchronize to multiple platforms. goreleaser has done similar, but accroding this post , goreleaser only supports dockerhub, gcr and ghcr.

    - url: https://github.com/ad-m/github-push-action
      des: push, push to repo itself, we can also push to another repo

    - url: https://github.com/gaurav-nelson/github-action-markdown-link-check
      des: mlc, 活链检测, 之前花了一个下午的时间试用了各种lc服务，还是这个最好用。
    - url: https://github.com/UmbrellaDocs/linkspector
      des: mlc作者的新作，据说比mlc更好用，基于Puppeteer进行check，有效减少FPR。试用了一下，体验一般，应该像mlc一样，在log中展示check过的文件名以及其中的link数，目前linkspector这种，完全不知道扫描过哪些文件，心里没底。config换成yaml好评。
    - url: https://github.com/raviqqe/muffet
      des: = site sucker. 这个是用来检测自己的网站（尤其是CMS之类的内容站）是否有broken-link，不是lc。试用过几次，很不好用。
    - url: https://github.com/codecov/codecov-action
      des: codecov
    - url: https://github.com/github/codeql-action
      des: codeql
    - url: https://github.com/github/gh-actions-importer
      des: gh-actions-importer 怎么把其他 ci 服务的 wf 转到 ghac？


    - url: https://github.com/dawidd6/action-send-mail
      des: used to send mail

    - url: https://github.com/cloudflare/wrangler-action
      des: contains all wrangler operations like pages, functions, etc. 之前直接使用pages-action部署pages，但是因为pages的

    - url: https://github.com/peter-evans/repository-dispatch
      des: 在 workflow 中触发其他 workflow
    - url: https://github.com/jigglycrumb/action-deploy-workspace-to-repo
      des: 把本地文件夹推送到github repo的指定文件夹，并直接覆盖。我用来把docs的blog目录来覆盖掉blog项目。
  qs:
    - q: ghac 的 workflow 有哪些基础语法？? # on, job, matrix, needs
    - q: trigger # webhook(push, PR, fork, ...), schedule, manually(workflow_dispatch)
    - q: "***有哪些常用的 context？What are the common context?***"  # github, jobs, steps, (env, secrets, vars)
    - q: How to use cache in gh-actions?
    - q: 怎么本地执行 ghac？
    - q: 如果使用gh作为团队的vcs，怎么优化 ghac 成本？
    - q: 怎么在 workflow 中触发其他 workflow
    - q: "***怎么开发 ghac 的 wf？***" # action.yml(with or env)



---

# devops


- type: git
  repo:
    - url: https://github.com/git/git
      key: true
      cmd:
        - c: 'git commit -m "<type>(<scope>): <subject> <footer>" -m "Description <body>"'
          x: 'git commit -m "fix(sms): 修复短信到达率问题 fix #12, fix #13, fix #14" -m "通过xxx修复该bug"'
        - c: git log --graph --date=short
          x: 查看提交记录，相当于glods
        - c: glods --grep <keywords>
          x: 搜索提交记录，非常好用
        - c: git reflog
          x: reflog 是一个本地结构，它记录了 HEAD 和分支引用在过去指向的位置。reflog 信息没法与其他任何人共享，每个人都是自己特有的 reflog。重要的一点是，它不是永久保存的，有一个可配置的过期时间，reflog 中过期的信息会被自动删除。我们在使用reset后，部分代码会丢失，如果这时想找回这些代码，就可以使用reflog
        - c: git remote rm origin && git remote add origin <url>
          x: git 怎么修改远程仓库地址
        - c: git rm -r --cached .
          x: 忽略规则不生效，清空git缓存，撤销已经写到缓存区文件的修改
        - c: git push -f
          x: 强制推送
        - c: git checkout .
          x: 放弃本地所有修改
        - c: git remote -v
          x: 查看git的远程仓库地址
        - c: git diff <filename>
        - c: git diff .
        - c: git diff --cached .
          x: 展示和暂存区的差异，而git diff .展示和工作区的差异
        - c: git reset [--mixed | --soft | --hard] <起始点的父提交>
          x: 三种reset type，默认mixed 回退到某个版本，本地会保留源码，回退 commit 和 index 信息，若要提交重新 commit。soft 回退到某个版本，只回退了 commit 的信息，不会恢复到 index file 一级，若要提交重新 commit。Hard 彻底回退到某个版本，本地的源码也会变为上一个版本的内容。
        - c: git reset HEAD~3
        - c: git reset --merge
          x: 用来撤销合并，也可以与mixed/soft/hard搭配使用
        - c: git rebase -i HEAD~n
          x: 合并前n个commit。需要注意的是，编辑时把pick改为s即可，记得第一个不要修改（需要父commit）
        - c: git stash
        - c: git filter-branch
        - c: git cherry-pick
        - c: git work-together
        - c: git config -f .gitmodules submodule.xxx.ignore dirty
          x: 忽略子模块的脏commit
        - c: git clone url path --recursive
          x: clone包含submodule的repo
        - c: git blame <filename> -L 10,20
          x: 查看10到20行，blame命令 我们往往通过blame查到具体是哪个人修改了某文件到某块代码，找到这个背锅侠。也可以使用 'git blame <filename> -L:<func_name>'
        - c: git grep -n -p <str>
          x: 从当前branch中查找指定字符串，相比于 'git grep -n <str>' 会显示匹配行以及上下几行的内容
        - c: git grep -n -p <str> <commit号/tag号>
          x: 从指定commit中查找指定字符串
        - c: git rev-list --all | xargs git grep <str>
          x: 从所有历史commit中查找指定字符串
        - c: git count-objects -v
          x: 查看git仓库大小
        - c: git filter-branch --force --index-filter 'git rm -rf --cached --ignore-unmatch <filename>' --prune-empty --tag-name-filter cat -- --all
          x: 怎么从所有git记录中查找指定字符串？？？ 需要按照上面输出的大文件，指定文件或者文件夹
        - c: git push origin --force --all && rm -rf .git/refs/original/ && git reflog expire --expire=now --all && git gc --prune=now
          x: 怎么压缩 git 项目？push后，并清除本地缓存。删除之后会有大量输出，显示已经从各自历史log中剔除掉关于这个大文件的信息，之后可以使用gc命令再次压缩。一定要执行“清除缓存”。另外，之后最好从远程重新拉取。
          u: https://juejin.cn/post/6844904046797520909
        - c: git maintenance run --task=gc --task=loose-objects --task=pack-refs && git prune
          x: used to reduce git repo size, equal to 'git gc'
        - c: git push --force --all --tags
          x: gp默认只有main分支，如果使用git push --all就可以推送所有branch，使用git push --all --tags可以顺便推送所有tag
      qs:
        - q: "commit: type, scope, subject, body, footer" # feat, fix, test, docs, chore, style, perf, ci, feat!
        - q: "PR commit: type" # PR, WIP, PTAL, TBR, TL, LGTM, CC
        - q: "branch: type" # feat, dev, release, hotfix, main
        - q: tag, SemVer rules?
        - q: What are the common git operations? # reset/grep/blame/rebase/merge/cherry pick/stash
        - q: How to use "git bisect"? # start, (bad, good), reset
        - q: git add -A 和 git add . 及 git add -u 的区别 # `git add .` 不提交被删除文件，`git add -u` 不提交新文件，`git add -A`会提交全部文件。`git add -A` = `git add .` + `git add -u`
      qq:
        - topic: Git 具体使用
          qs:
            - q: fork 后如何同步源的最新代码？
            - q: auto-sync using git
            - q: 怎么在不重建项目的情况下，清除 git 历史？
            - q: git 怎么修改远程仓库地址？ # git remote rm origin && git remote add origin <url>
            - q: 怎么压缩 git 项目？ # git filter-branch
            - q: gh 开源项目 如何移除历史密钥
            - q: 怎么合并多个 commit? rebase、merge、cherry pick都可以合并多个 commit，有啥区别? Why we'd better use merge? # rebase 操作和 cherry-pick 操作都会修改 commit-id，导致无法追溯问题。所以通常禁止使用，只允许 merge 操作公共分支（merge将两个分支上的所有提交记录合并成一个新的提交记录，并且保留原来的提交记录。这个操作不会修改提交记录的 SHA 值），方便 debug。
            - q: How to create a PR on gh? What should we do if original repo code is modified? How to sync? 怎么给 github 的项目提 pr？提 PR 时需要注意哪些问题？ # 在对应项目的 PR 页面里，最好标明对应的 issue。另外，提交修改之前，需要注意原 repo 是否更新。
            - q: main 分支保护怎么设置？
    #        - topic: submodule
    #          qs:
    #            - 怎么克隆包括 submodule 的项目？
    #            - 如何删除 git 的 submodule？
    - url: https://github.com/kubernetes/git-sync
      des: clones a git repo and keeps it in sync with the upstream
    - url: https://github.com/GitJournal/git-auto-sync
      des: used to sync local changes to remote cron. support installed by homebrew. 这个已经挂了，无法自动提交 "git-auto-sync-daemon is NOT Running!"，并且也不支持自定义commit msg
      cmd:
        - c: git-auto-sync sync
        - c: git-auto-sync daemon add $PWD
        - c: git-auto-sync daemon status
        - c: git-auto-sync daemon ls
    - url: https://github.com/rtyley/bfg-repo-cleaner
      des: bfg, 经过测试，发现 bfg 只能修改 commit 历史，但是无法直接修改当前文件
      cmd:
        - c: bfg --delete-files id_{dsa,rsa}
          x: 删除所有含有 'id_rsa' or 'id_dsa' 的文件
        - c: bfg --strip-blobs-bigger-than 50M
          x: 删除所有超过50MB的blobs文件
        - c: bfg --replace-text <filepath> --no-blob-protection
          x: 替换文件中的敏感信息（不删除文件）

    - url: https://github.com/newren/git-filter-repo
      des: rewrite git repository history. Another filter-branch.
    - url: https://github.com/go-git/go-git
      des: 用 golang 实现的 git 库，通过这个可以直接调用 git 命令，而不是之前用 os/exec 直接调用 git 命令。repo分为Repository, Remote, Submodule, Worktree等几部分。用这个就可以替代之前写过的，比如用PlainOpen()代替IsGitRepository(), 也支持push和pull操作。



- type: devops
  repo:
    - url: https://github.com/bregman-arie/devops-exercises
      des: 非常好用的，可以用来作为devops面试题，也可以平时随便看看
    - url: https://github.com/1Panel-dev/1Panel
      des: 运维面板，类似之前的宝塔什么的
    - url: https://github.com/admpub/nging
    - url: https://github.com/naiba/nezha

    - url: https://github.com/openvswitch/ovs
      des: OpenvSwitch. 引入 OpenvSwitch 之后，可以使得配置简单而灵活，并且可以解耦物理网络和虚拟网络。OpenvSwitch 的原理？在 OpenvSwitch 里有一个流表规则，任何通过这个交换机的包，都会经过这些规则进行处理，从而接收，转发，放弃（流表就是一个个表格，每个表格都是一条规则；规则有优先级，先看高优先级的规则，再看低优先级的）

    - url: https://github.com/chaitin/SafeLine
      des: WAF

    - url: https://github.com/gravitational/teleport
      des: Protect access to all of your infrastructure
    - url: https://github.com/gofireflyio/aiac
      des: 看到有个大佬群里还在聊pgsql的有个sql应该怎么写。想到各种chat2产品，什么chat2db(Outerbase), aiac之类的，之前试用了几个，都很稚嫩，甚至会报错。所以还是要等等看，如果有什么成熟的ALL-IN-ONE产品，到时候可以再看。
    - url: https://github.com/shaowenchen/ops
      doc: https://www.chenshaowen.com/ops/
      des: |
        ??? 某种ansible，但是需要在目标server安装opscli，才能使用。相比ansible有侵入性。

        正如author所说“如果遇到新的运维问题，我会马上编写 Task Yaml 对操作进行固化，方便下一次复用。Ops 的核心操作是脚本执行和文件分发，核心对象是主机、Kubernetes 集群。主机和集群都需要实现 Ops 的两种核心操作，最上层是 Task 编排，沉淀运维场景。”

        相当于一个自用的ansible roles，核心是各种case，比如“在 kubectl pod 中测试指定节点的磁盘 IO 性能”之类的。

    - url: https://github.com/googleapis/release-please
      des: 用来在CI阶段check PR语法是否符合规范（通常PR只跑代码相关的test之类的CI，但是这个工具是用来检查PR commit本身是否符合规范）。类似pre-commit这种git hook检查commit语法。
    - url: https://github.com/coder/coder
      des: 用来搭建团队的云端开发环境，或者堡垒机？


    - url: https://github.com/zorkian/go-datadog-api
      des: Golang client for the Datadog API
    - url: https://github.com/DataDog/datadog-api-client-go
      des: Golang client for the Datadog API
    - url: https://github.com/SonarSource/sonarqube
    - url: https://github.com/reviewdog/reviewdog
    - url: https://github.com/flagify-com/OctoMation
    - url: https://github.com/andygrunwald/go-gerrit
    - url: https://github.com/graphql-go/graphql
      des: GraphQL = Graph + Query Language, 可以搭配各种DB使用，但是通常搭配 Graph 图数据库使用
    - url: https://github.com/jumpserver/jumpserver
      des: Jump Server
    - url: https://github.com/dushixiang/next-terminal
      des: Jump Server

    # [字节跳动自研线上引流回放系统的架构演进 - 掘金](https://juejin.cn/post/6857688805835866126)
    - url: https://github.com/buger/goreplay
      des: traffic-replay. 比 TCPCopy, TcpReplay, 滴滴的sharingan 好用。用在准生产环境中，将线上的流量复制到该环境，测试新功能和服务到承压能力。流量复制的两个目的，*压力测试*以及*验证代码在生产环境下是否符合预期*(降低服务端上线的风险)。
      doc: https://github.com/buger/goreplay/wiki
      qs:
        - q: gor的大概使用流程？（两种，实时复制引流到其他服务器，或者把流量保存到文件中，然后释放到其他机器(适合部分很难同步流量的场景)
          d: https://mp.weixin.qq.com/s?__biz=MzUzNTY5MzU2MA==&mid=2247496167&idx=1&sn=2913f1ebced800443a824a986710b257
        - q: 问一个流量复制工具的问题，如果现在生产环境是v1的请求参数，预发布环境的服务端代码已经是v2的话，请求应该都会报错，这种情况怎么处理呢？
        - q: gor适合没有任何token鉴权操作的请求
        - q: rate limiting 怎么限制每秒请求数？
        - q: 为指定header或者URL的请求设置请求比例？
        - q: gor的请求过滤
        - q: 对生产环境和预发布环境的宿主机侵入性太强，需要分别安装gor并启动gor listener和gor replayer，有什么其他方案？ # istio and linkerd, traffic mirroring


- type: CI
  repo:
    - url: https://github.com/ligurio/awesome-ci
    - url: https://github.com/jenkinsci/jenkins
    - url: https://github.com/argoproj/argo-cd
      des: k8s native CD. ArgoCD会auto pull最新配置并应用到k8s中. 所有 k8s 声明式配置都保存在 Git 中么，并把 Git 作为应用的唯一来源，我们不再需要手动更新应用（例如执行 kubectl apply、helm install ...），只需要通过统一的接口（Git）来更新应用。并且支持快速回滚和集群灾备。基于 GitOps 的持续交付工具，它允许用户声明式地管理 Kubernetes 集群中的应用部署。Argo CD 通过与 Git 仓库同步，确保集群状态与 Git 仓库中定义的状态保持一致。
      qs:
        - q: Compare (blue/green, canary, rolling)
        - q: Argo有哪些核心组件？怎么安装？相关CRD有哪些？(CD, Workflows, Events, Rollouts)
    - url: https://github.com/argoproj/argo-workflows
      des: 基于容器的任务编排工具，它允许用户定义、运行和监控复杂的工作流。Argo Workflows 支持多种类型的工作流，包括顺序、并行、条件和循环等。
    - url: https://github.com/argoproj/argo-events
      des: 事件驱动工具，它提供了一种机制来处理来自外部系统的事件，并触发 Kubernetes 集群内的操作。Argo Events 包括事件源（EventSources）、事件总线（EventBus）、传感器（Sensors）和触发器（Triggers）等组件。
    - url: https://github.com/argoproj/argo-rollouts
      des: 应用渐进式发布工具，它支持金丝雀发布、蓝绿发布等策略，帮助用户安全地更新和回滚 Kubernetes 集群中的应用。
    - url: https://github.com/argoproj/argocd-example-apps
    - url: https://github.com/fluxcd/flagger
    - url: https://github.com/fluxcd/flux2
      des: k8s native CD
    - url: https://github.com/tektoncd/pipeline
      des: tekton 是一个支持 CICD 的 k8s 原生开源框架，通过 Operator 的方式集成到 k8s 集群中. pipeline是tekton的一部分, tekton 是一个支持 CICD 的 k8s 原生开源框架，通过 Operator 的方式集成到 k8s 集群中. Tekton contains pipeline, catalog, triggers, dashboard, cli.
    - url: https://github.com/sdaschner/tekton-argocd-example




- type: ansible
  repo:
    - url: https://github.com/ansible/ansible
      key: true
      cmd:
        - c: ansible all -m ping -u bruce
          x: 检查所有的远程主机，是否以 bruce 用户创建了 ansible 主机可以访问的环境
        - c: ansible all -a "/bin/echo hello"
          x: 在所有的远程主机上，以当前 bash 的同名用户，在远程主机执行“echo bash”
        - c: ansible all -m user -a "name=foo password=<crypted password here>"
          x: 添加用户
        - c: ansible web -m service -a "name=httpd state=started"
          x: 启动服务
        - c: ansible web -m git -a "repo=git://..."
          x: 下载 git 包
        - c: ansible lb -a "/sbin/reboot" -f 10
          x: 并行执行：启动 10 个并行进行执行重启
        - c: ansible all -m setup
          x: 查看远程主机的全部系统信息
        - c: ansible <xxx> --list-host
          x: 查看组中的 host 清单
        - c: ansible-playbook -v playbook/centos.yml --list-hosts
          x: 查看脚本影响到的 hosts
        - c: ansible-playbook --check playbook/centos.yml -i hosts
          x: 预执行，查看 playbook 语法是否正确，以及在目标服务器上是否能够执行成功 (但是并不保证一定能够执行成功)
        - c: ansible-playbook -v playbook/centos.yml -i hosts
          x: 执行并查看输出细节
        - c: ansible-playbook --check playbook/helloworld.yml -i hosts
          x: 执行基础 playbook，确定 playbook 是否 work
        - c: ansible all -m command -a 'echo Hello World on Docker.'
          x: 确保 ssh 能够连接所有目标服务器 (请一定确认 ssh 连接已建立，因为未建立 ssh 连接也会成功)

      des: ansible是一个基于Python的自动化运维工具，它集合了众多运维工具（puppet, cfengine, chef, func, fabric）的优点，实现了批量系统配置，批量程序部署，批量运行命令等功能 ansible基于SSH执行所有功能
      qs:
        - q: What's ansible?
        - q: "***Compare ansible with Puppet, Chef, Fabric?***"
        - q: How does it works? # master-node(ansible), remote-node(ssh, python)
        - q: How to install ansible (using docker)?
        - q: playbook执行失败，怎么继续执行？
        - q: 怎么用ansible批量优化centos7系统？
        - q: inventory and facts? # 被控节点，使用 yaml 文件 + 机器分组(按照服务, 地理位置, 时间阶段分)
        - q: playbook syntax? # play, task, module, host, user, role, handler
        - q: roles syntax? # tasks, files, handlers, templates, meta, vars, default
        - q: What are the common modules in playbook? (handlers? roles?) # shell, file,
        - q: 什么是“handler 机制”？handler的使用场景？ # 类似hook(或者event机制)，某种代码复用。比如说很多tasks中都需要重启某服务，那写一个“重启服务”的handler直接复用即可。
        - q: "@Ansible Tower" # 仪表盘
        - q: "@Ansible Community"
        - q: "***ansible使用shell时，容易引入不幂等的操作，结果不可预期，怎么解决？***"
          x: 多使用 change_when 和 faild_when
        - q: 通常来说，我们都只能通过跳板机来访问目标机器，那ansible怎么通过跳板机来访问目标机器呢？


    - url: https://github.com/semaphoreui/semaphore
      des: Ansible Web UI, 基于golang+vue实现
    - url: https://github.com/ansible-community/ansible-nomad
    - url: https://github.com/ansible/ansible-examples
      des: ansible playbooks, official repo, but EOL.
    - url: https://github.com/Homeless-Xu/Ansible-DevOps
      des: ansible语法介绍
    - url: https://github.com/chusiang/ansible-managed-node.dockerfile
      des: A Docker image of run the OpenSSH daemon and Python for Ansible. 用来在本地玩ansible
    - url: https://github.com/cobbler/cobbler
      des: 相比于ansible，Cobbler已经内置了DNS管理、DHCP之类的服务初始化工具，只需要修改“预定义”的模版，就能“多快好省”地安装和配置这些服务。



- type: OCR
  repo:
    - url: https://github.com/tesseract-ocr/tesseract
    - url: https://github.com/JaidedAI/EasyOCR




- type: IaC-terraform
  repo:
    - url: https://github.com/hashicorp/terraform
      des: terraform providers, GCP, StatusCake, Cronitor. Better than puppet, chef, saltstack, fabric, pulumi, 阿里云 ROS, AWS CloudFormation. pulumi和tf的区别归根到底在于，tf使用HCL，而pulumi则选择ts/python/golang之类的通用编程语言。使用HCL的好处是资源非常集中，无论是查资料还是找现成的各种都效率更高（生态更好）。缺点是HCL语法太简单，导致配置繁琐 (比如大量重复配置)。通用语言的优缺点则相反，生态不好，但是通用语言的表达力更强，没有study curve. 另外，关于“抽象级别”：terraform 提供了一种高度抽象的方式来描述基础设施，它将资源定义为独立的配置块，可以以模块化和可重用的方式组合。pulumi则更灵活，可以更灵活地编写逻辑和控制流程。
      qs:
        - q: How to use terraform and tofu?
        - q: d
          u: https://github.com/infracost/infracost
          d: 与TF搭配使用，用来实时生成云服务的账单，这个可太实用了！！！
    - url: https://github.com/opentofu/opentofu
      doc: https://opentofu.org/docs/cli/
      des: 提供了最佳实践，可以很快生成需要的，可以理解为ansible galaxy，提供了大量已经写好的主流云服务设施的terraform代码，可以直接使用。三分钟就能上手。
      cmd:
        - c: tofu apply -auto-approve
    - url: https://github.com/runatlantis/atlantis
      des: Terraform Pull Request Automation. 通过webhook监听TF的PR事件，来远程运行terraform plan、import、apply命令，并将输出作为评论反馈到PR中。其目的是为了让整个团队的成员更直观地看到代码变更将如何影响基础设施，而无需手动运行Terraform命令（也就是在代码还没push，TF实际执行之前，就看到infra会怎么变更）。
    - url: https://github.com/gruntwork-io/terragrunt
      des: Terragrunt is a thin wrapper for Terraform that provides extra tools for working with multiple Terraform modules.
    - url: https://github.com/antonbabenko/pre-commit-terraform
      des: tf的pre-commit，这个repo还算活跃


#- type: IaC-pulumi
#  repo:
#    - url: https://github.com/pulumi/pulumi
#    - url: https://github.com/pulumi/pulumi-tf-provider-boilerplate
#      des: Boilerplate code for Terraform provider-backed Pulumi packages. pulumi 的 provider 都是基于 tf 包，通过pulumi-tf-provider-boilerplate打包获得 (从而兼容 tf 的所有 provider)
#    - url: https://github.com/pulumi/pulumi-terraform-bridge
#      des: 用来把tf转成pulumi
#    - url: https://github.com/pulumi/pulumictl


- type: VCS
  repo:
    - url: https://github.com/gitlabhq/gitlabhq
      des: gitlab
    - url: https://github.com/harness/gitness
      des: 之前就是 Drone, will support for essential feats like code hosting, pull requests, code reviews and more. 也就是说之后会变成类似gitea或者gogs之类的VCS。如果需要查看Drone，可以切换到该branch查看。
    - url: https://github.com/go-gitea/gitea
      doc: https://docs.gitea.cn/
    - url: https://github.com/gogs/gogs
    - url: https://github.com/theonedev/onedev
      des: ??? 基于java实现的，试用了一下，功能很全（内置支持CICD, kanban, packages, CR, git blame...），但是感觉一般
    - url: https://github.com/renovatebot/renovate
      des: just install renovate apps in gh-repos, it will auto-generate a "Dependency Dashboard" issue. 用来直接fetch最新的dependency，前端用这个比较多，但是这个其实支持几乎所有语言。
    - url: https://github.com/goharbor/harbor
      des: 其他 Image Manager/Docker Registry 还有Portus, Quay之类的，通常这类服务都直接集成在VCS了，所以不单独添加type
  qs:
    - q: 5人小团队用什么VCS更有性价比？比较几种常用VCS平台 gh, ghe, gitea, gogs
      x: (经验复用, 人均费用, cicd, ) 小团队直接白嫖 gh，等 ghac 的时间不够了，就直接自建，ghe毫无意义


- type: serverless
  repo:
    - url: https://github.com/honojs/hono
    - url: https://github.com/openfaas/faas
    - url: https://github.com/serverless/serverless
      qs:
        - q: Compare mainstream serverless providers. (railway, heroku, vercel, fly.io, pikapods, zeabur) (credit card, price(free plan?), server resources, )
        - q: Compare mainstream static hosting providers. (gh-pages, cf-pages, vercel, netlify, heroku, firebase) (fe(be? db?), price, visit)
    - url: https://github.com/cloudflare/workers-sdk
      des: wrangler命令
      cmd:
        - c: npx wrangler pages deploy "build" --project-name="docs" --branch="gh-pages"', "publish to cloudflare pages
    - url: https://github.com/syumai/workers
      des: cf worker 的第一语言是 js，如果想用 golang 的话，需要把 golang 编译成 wasm，用 js 调用. workers就是用来"Go package to run an HTTP server on Cloudflare Workers.", Support R2, KV, Cache API, Cron Triggers, etc.
    - url: https://github.com/Charca/cloudflare-pages-auth
      des: 目前给blog使用的cloudflare functions. 如果是MPA可以锁定指定route，如果是SPA则只能锁定全站。
    - url: https://github.com/cloudflare/workerd
      des: cf workers就是基于workerd实现的
      qs:
        - q: Compare cloudflare workers or page function? (pf is also a kind of worker, but inversion, file-based(worse migration))
    - url: https://github.com/cloudflare/cloudflared
    - url: https://github.com/coollabsio/coolify
      des: 开源serverless服务，类似Heroku, Vercel, Netlify之类的




---

# k8s

- type: k8s
  md: true
  repo:
    - url: https://github.com/kubernetes/kubernetes
      key: true
      doc: https://gist.github.com/naviat/446d1be0a5a03bad1d7113d1abf082c7
      cmd:
        - c: kubectl get <pods|ingress>
          x: 显示一个或者多个资源, [查看 default 命名空间的数据]
        - c: kubectl get no -o wide
        - c: kubectl describe no
        - c: kubectl get no -o yaml
        - c: kubectl get node -selector=[label]
        - c: kubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type=='ExternalIP')].adress}'
        - c: kubectl get po --shaw-labels
        - c: kubectl get po -l app=nginx
        - c: kubectl get pod [pod_name] -o yaml --export
        - c: kubectl get pod [pod_name] -o yaml --export > nameoffline.yaml
        - c: kubectl get pods --filed-selector status.phase=Running
        - c: kubectl get pods --all-namespaces
          x: 查看所有 namespace 的数据
        - c: kubectl get pods --field-selector=status.phase=Running
          x: 查询命名空间下所有在运行的 pod
        - c: kubectl get pod pod-name -o=yaml
          x: 查询资源当下在集群中的属性
        - c: kubectl api-resources --namespaced --verbs=list -o name
        - c: kubectl apply -f <resources.yaml>
          x: 提交资源给集群应用
        - c: kubectl apply -f <resources.yaml> --record
          x: 并记录版本，想用 K8s 中--Deployment 资源的回滚能力的话，还得让 K8s 记住每个版本都提交了什么，这个功能可以通过--record 选项开启
        - c: kubectl describe pod <pod-name>
          x: 查看资源对象的事件信息，比如退出码
        - c: kubectl logs <podname> -n <namespace>
          x: 查看容器日志
        - c: kubectl logs <podname> --previous
          x: 如果恰巧这个Pod 被重启了，查不出来任何东西，可以通过增加 —previous 参数选项，查看之前容器的日志
        - c: kubectl describe
        - c: kubectl create
          x: 从文件或者标准输入创建资源
        - c: kubectl update
          x: 从文件或者标准输入更新资源
        - c: kubectl delete
          x: 通过文件名、标准输入、资源名或者 label selector 删除资源
        - c: kubectl log
          x: 输出 pod 中一个容器的日志
        - c: kubectl rolling-update
        - c: kubectl exec
          x: 在容器内部执行命令
        - c: kubectl port-forward
          x: 将本地端口转发到 pod
        - c: kubectl proxy
          x: 为 k8s API server 启动代理服务器
        - c: kubectl run
          x: 在集群中使用指定镜像启动容器
        - c: kubectl expose
          x: 将 replication controller service 或者 pod 暴露为新的 k8s service
        - c: kubectl label
          x: 更新资源的 label
        - c: kubectl config
          x: 修改 k8s 配置文件
        - c: kubectl config get-contexts
          x: 获取k8s的所有context
        - c: kubectl config use-context <rancher-desktop>
          x: 设置k8s的context
        - c: kubectl cluster-info
          x: 显示集群信息
        - c: kubectl api-versions
          x: 以 '组/版本' 的格式输出服务端支持的 API 版本
        - c: kubectl drain
          x: 用于将节点标记为不可调度并驱逐上面运行的所有 Pod。这在需要维护节点或将其从集群中移除时很有用。当你想要停止一个节点上的所有工作负载，并将其迁移到其他节点时，可以使用 kubectl drain。
        - c: kubectl delete pod <pod-name>
        - c: kubectl get ns
        - c: kubectl get ns -o yaml
        - c: kubectl get <xxx> -o wide
          x: find resources in default namespace
        - c: kubectl get <xxx> -o yaml
        - c: kubectl get <deploy|svc|ds|events|sa|rs|secrets|cm|ing|pv|pvc|sc>
          x: kubectl get svc, po
        - c: kubectl get all
          x: kubectl get all --all-namespaces
        - c: kubectl get ds --all-namespaces
        - c: kubectl describe ds [daemonset_name] -n [namespace_name]
        - c: kubectl get sa default -o yaml > ./sa.yaml
        - c: kubectl replace serviceaccount default -f ./sa.yaml
        - c: kubectl get cm --all-namespaces
        - c: kubectl get cm --all-namespaces -o yaml
        - c: kubectl get ing --all-namespaces
        - c: kubectl taint <node_name> <taint_name>
        - c: kubectl <cordon|uncordon> <node_name>
        - c: kubectl port-forward <image> <port:port>
          x: 用来在apply服务之前验证是否可用，kubectl port-forward svc/http-echo 8080:5678
      qs:
        - q: "*What's k8s? and why we should use k8s(or ms)? when to use k8s? when not?*"
        - q: "***Compare k8s and kernel? and briefly introduce these (CSI, CNI, CRI, )***"

        - q: k8s scheduler
        - q: kube-apiserver:提供 REST API,跟 Kubernetes master 交互
        - q: kube-scheduler:负责 Pod 调度,决定 Pod 运行在哪个 Node 上
        - q: kube-controller-manager:包含系统组件如 ReplicationController、NodeController 等
        - q: kubelet:负责 Pod 与机器的生命周期管理,在每个 Node 上运行
        - q: kube-proxy:负责实现 Service 抽象到 Pod 端口的网络代理能力

        - q: 既然k8s的Overlay方案要用calico呢？既然calico使用BGP，而k8s集群内部应该属于某个AS内部吧，既然如此岂不是应该使用OSPF，而不是BGP呢？
        - q: 生产环境怎么部署k8s? ECS直接部署还是阿里云k8s? ACK和ASK有啥区别? # https://ruby-china.org/topics/41673 非常使用的帖子，总结：

        - q: k8s OPA是啥？相比于内置的PSP/RBAC等方案
        - q: kube-proxy, mode (iptables, ipvs, userspace), compare
        - q: pod, state
        - q: pod healthcheck (liveness probe, readiness probe, startup probe)
        - q: pod scheduler
        - q: list-watch机制和informer模块
        - q: k8s spec
        - q: What components in k8s master and slave? Briefly describe the feats of each component? # (apiserver, scheduler, controller-manager), kubelet, kube-proxy
        - q: (Pod, Deployment, Service, Ingress, ConfigMap, Secret, StatefulSet, DaemonSet)
        - q: Service (ClusterIP, NodePort, LoadBalancer)
        - q: RoundRobin, SessionAffinity
        - q: What's GitOps? # GitOps = IaC + Git + CI/CD. 基于IaC版本化CICD. Devops as Code (DaC)
        - q: How to do blue/green and canary deployments with Argo Rollouts?
        - q: AdmissionControl
        - q: PodSecurityPolicy, OPA
        - q: Brief describe the process of worker node joining the cluster
        - q: How to use EFK to collect k8s logs?
        - q: Which two methods does scheduler use to bind pods to worker nodes?
        - q: the process of k8s-scheduler? (predicates, priorities)
        - q: What's CRD? How to write Operator? (Operator = CRD + Operator)
        # q:      - How does ArgoCD implement Canary Deployment Strategy and
        - q: Why does the k8s overlay solution use calico? Why does calico use BGP instead of OSPF?
        - q: 如何实现支持多集群的 Kubernetes Operator?


        # [60 道重要的 Kubernetes 面试题](https://mp.weixin.qq.com/s?__biz=Mzg5Mjc3MjIyMA==&mid=2247544382&idx=1&sn=ed3cccd3bb4ab0ceb0491ed553f29232&source=41#wechat_redirect)
        - q: 简述 etcd 及其特点
        - q: 简述 etcd 适应的场景
        - q: 简述 Kubernetes 和 Docker 的关系
        - q: 简述 Minikube、Kubectl、Kubelet 分别是什么
        - q: 简述 Kubernetes 常见的部署方式
        - q: 简述 Kubernetes 如何实现集群管理
        - q: 简述 Kubernetes 的优势、适应场景及其特点
        - q: 简述 Kubernetes 的缺点或当前的不足之处
        - q: 简述 Kubernetes 相关基础概念
        - q: 简述 Kubernetes 集群相关组件
        - q: 简述 Kubernetes RC 的机制
        - q: 简述 Kubernetes Replica Set 和 Replication Controller 之间有什么区别
        - q: 简述 kube-proxy 的作用
        - q: 简述 kube-proxy iptables 的原理
        - q: 简述 kube-proxy ipvs 的原理
        - q: 简述 kube-proxy ipvs 和 iptables 的异同
        - q: 简述 Kubernetes 中什么是静态 Pod
        - q: 简述 Kubernetes 中 Pod 可能位于的状态
        - q: 简述 Kubernetes 创建一个 Pod 的主要流程
        - q: 简述 Kubernetes 中 Pod 的重启策略
        - q: 简述 Kubernetes 中 Pod 的健康检查方式
        - q: 简述 Kubernetes Pod 的 LivenessProbe 探针的常见方式
        - q: 简述 Kubernetes Pod 的常见调度方式
        - q: 简述 Kubernetes 初始化容器（init container）
        - q: 简述 Kubernetes deployment 升级过程
        - q: 简述 Kubernetes deployment 升级策略
        - q: 简述 Kubernetes DaemonSet 类型的资源特性
        - q: 简述 Kubernetes 自动扩容机制
        - q: 简述 Kubernetes Service 类型
        - q: 简述 Kubernetes Service 分发后端的策略
        - q: 简述 Kubernetes Headless Service
        - q: 简述 Kubernetes 外部如何访问集群内的服务
        - q: 简述 Kubernetes ingress
        - q: 简述 Kubernetes 镜像的下载策略
        - q: 简述 Kubernetes 的负载均衡器
        - q: 简述 Kubernetes 各模块如何与 API Server 通信
        - q: 简述 Kubernetes Scheduler 作用及实现原理
        - q: 简述 Kubernetes Scheduler 使用哪两种算法将 Pod 绑定到 worker 节点
        - q: 简述 Kubernetes kubelet 的作用
        - q: 简述 Kubernetes kubelet 监控 Worker 节点资源是使用什么组件来实现的
        - q: 简述 Kubernetes 如何保证集群的安全性
        - q: 简述 Kubernetes 准入机制
        - q: 简述 Kubernetes RBAC 及其特点（优势）
        - q: 简述 Kubernetes Secret 作用
        - q: 简述 Kubernetes Secret 有哪些使用方式
        - q: 简述 Kubernetes PodSecurityPolicy 机制
        - q: 简述 Kubernetes PodSecurityPolicy 机制能实现哪些安全策略
        - q: 简述 Kubernetes 网络模型
        - q: 简述 Kubernetes CNI 模型
        - q: 简述 Kubernetes 网络策略
        - q: 简述 Kubernetes 网络策略原理
        - q: 简述 Kubernetes 中 flannel 的作用
        - q: 简述 Kubernetes Calico 网络组件实现原理
        - q: 简述 Kubernetes 共享存储的作用
        - q: 简述 Kubernetes 数据持久化的方式有哪些
        - q: 简述 Kubernetes PV 和 PVC
        - q: 简述 Kubernetes PV 生命周期内的阶段
        - q: 简述 Kubernetes 所支持的存储供应模式
        - q: 简述 Kubernetes CSI 模型
        - q: 简述 Kubernetes Worker 节点加入集群的过程
        - q: 简述 Kubernetes Pod 如何实现对节点的资源控制
        - q: 简述 Kubernetes Requests 和 Limits 如何影响 Pod 的调度
        - q: 简述 Kubernetes Metric Service
        - q: 简述 Kubernetes 中，如何使用 EFK 实现日志的统一管理
        - q: 简述 Kubernetes 如何进行优雅的节点关机维护
        - q: 简述 Kubernetes 集群联邦
        - q: 简述 Helm 及其优势
        - q: 简述etcd 及其特点？
        - q: 简述etcd 适应的场景？
        - q: 简述什么是 Kubernetes?
        - q: 简述Kubernetes 和Docker 的关系？
        - q: 简述Kubernetes 中什么是Minikube、Kubectl、Kubelet?
        - q: 简述Kubernetes 常见的部署方式？
        - q: 简述Kubernetes 如何实现集群管理？
        - q: 简述Kubernetes 的优势、适应场景及其特点？
        - q: 简述Kubernetes 的缺点或当前的不足之处？
        - q: 简述Kubernetes 相关基础概念？
        - q: 简述Kubernetes 集群相关组件？
        - q: 简述Kubernetes RC 的机制？
        - q: 简述Kubernetes Replica set 和 Replication Controller 之间有什么区别？
        - q: 简述kube-proxy 作用？
        - q: 简述kube-proxy iptables 原理？
        - q: 筒述 kube-proxy ipvs 原理？
        - q: 简述kube-proxy ipvs 和 iptables 的异同？
        - q: 简述Kubernetes 中什么是静态 Pod?
        - q: 筒述 Kubernetes 中 Pod 可能位子的状恋？.....
        - q: 筒述 Kubernetes 創建一个 Pod 的主要流程？
        - q: 简述Kubernetes 中Pod 的重启策略？
        - q: 筒述 Kubernetes Pod 的 LivenessProbe 探針的常兄方式？..
        - q: 简述Kubernetes Pod 的常见调度方式？
        - q: 简述Kubernetes 初始化容器 (init container) ?
        - q: 简述Kubernetes deployment 升级过程？
        - q: 筒述 Kubernetes deployment 升級策路?....
        - q: 筒述Kubernetes Daemonset 类型的餐源特性？
        - q: 简述Kubernetes 自动扩容机制？
        - q: 筒述 Kubernetes Service 类型?.........
        - q: 简述Kubernetes Service 分发后端的策略？
        - q: 简述Kubernetes 外部如何访问集群内的服务？
        - q: 简述Kubernetes 镜像的下载策略？
        - q: 简述Kubernetes 的负载均衡器？.
        - q: 简述Kubernetes 各模块如何与 API Server通信？
        - q: 简述Kubernetes Scheduler 作用及实现原理？.…
        - q: 简述 Kubernetes Scheduler 使用哪两种算法将 Pod 绑定到 worker 节点？
        - q: 简述 Kubernetes kubelet 的作用？
        - q: 简述 Kubernetes kubelet 监控 worker 节点资源是使用什么组件来实现的？
        - q: 简述Kubernetes 如何保证集群的安全性？
        - q: 简述Kubernetes 准入机制？….
        - q: 简述Kubernetes RBAC 及其特点（优势）？.….
        - q: 简述Kubernetes Secret 作用？.....
        - q: 简述Kubernetes Secret 有哪些使用方式？
        - q: 简述Kubernetes PodsecurityPolicy 机制？ ..
        - q: 简述Kubernetes CNI模型？
        - q: 简述Kubernetes 网络策略？
        - q: 简述Kubernetes 网络策略原理？.
        - q: 简述Kubernetes 中flannel的作用？.….
        - q: 简述Kubernetes Calico 网络组件实现原理？
        - q: 简述Kubernetes 共享存储的作用？
        - q: 简述Kubernetes 数据持久化的方式有哪些？.
        - q: 简述Kubernetes Pv和PVC?
        - q: 简述Kubernetes pv 生命周期内的阶段？
        - q: 简述Kubernetes 所支持的存储供应模式？
        - q: 简述Kubernetes CSl模型？
        - q: 简述Kubernetes Worker 节点加入集群的过程？
        - q: 简述Kubernetes Pod 如何实现对节点的资源控制？
        - q: 简述Kubernetes Requests 和 Limits 如何影响 Pod 的调度？.
        - q: 简述Kubernetes 中，如何使用 EFK 实现日志的统一管理？……..
        - q: 简述Kubernetes 如何进行优雅的节点关机维护？
        - q: 简述Kubernetes 集群联邦？
        - q: 简述Helm 及其优势？
        - q: 什么是 Headless Service?
        - q: 简述你知道的几种CNI 网络插件，并详述其工作原理。K-常用的 CNI网络插件 (calico && flannel)，简述一下它们的工作原理和区别。
        - q: 简述kube-proxy 的三种工作模式和原理。
        - q: 每个Pod 中有一个特殊的 Pause 容器，能否去除，简达原因。
        - q: 简述pod 中readness 和 liveness 的区别和各自应用场景。
        - q: Pod 启动失败如何解决以及常见的原因有哪些…
        - q: kubelet 与kubeproxy 作用。kubeproxy 的三种代理模式和各自的原理以
        - q: Kubernetes 如何简化容器化部署？
        - q: Kubernetes 体系结构有哪些不同的组成部分？
        - q: 您能否简要介绍一下 Kubernetes 中主节点的工作？
        - q: kube-apiserver 和kube-scheduler 的作用是什么？
        - q: 使用 Kubernetes 时可以采取的最佳安全措施是什么？
        - q: 非 nodeport 和 lb 的 svc 怎么暴露给外部集群？
        - q: k8s 内部都有哪些证书，是一样的吗？
        - q: k8s master 都有哪些组件，可以随意部署吗？
        - q: 监听 pod 状态变化是怎么实现的？
        - q: pod 内容器是相互隔离的吗？
        - q: k8s 里调度的关键步骤？
        - q: k8s pod 切换策略
        - q: "Kubectl Port Forward: What is Port Forwarding and How Does it Work?"
    - url: https://github.com/easzlab/kubeasz
      des: 使用Ansible脚本安装K8S集群
    - url: https://github.com/falcosecurity/falco
      des: Cloud Native Runtime Security 用来实时监控容器、Kubernetes、主机和云服务中的潜在威胁，依托 Linux 内核模块和 eBPF 技术实现高效检测。同时，这款开源项目还与 50 多个第三方系统成功集成，提供 JSON 格式的警报通知，方便用户进行存储、分析和触发操作。
    - url: https://github.com/kubernetes-sigs/metrics-server
      des: Scalable and efficient source of container resource metrics for Kubernetes built-in autoscaling pipelines.
    - url: https://github.com/numaproj/numaflow
      des: ???
    - url: https://github.com/wuYin/k8s-in-action
      des: 可以作为k8s syntax手册使用，需要时直接查。其实只需要知道每个key大概是啥意思，会修改就行了。
    - url: https://github.com/kubewharf/godel-scheduler
      des: godel-scheduler 则是为 Kubernetes 提供了一个自定义的调度器实现。它可以根据自定义的策略和规则，智能地将容器化的应用程序和任务分配到集群中的节点上，以实现高效的资源利用和负载均衡。godel-scheduler 提供了丰富的配置选项和扩展能力，可以根据具体需求进行定制化配置和扩展。
    - url: https://github.com/kubesphere/ks-installer
    - url: https://github.com/kubesphere/kubekey
    - url: https://github.com/openyurtio/openyurt
      des: 用来管理多云环境的k8s集群。比如有些Pod和节点运行在Amazon云,有些运行在Google云,还有些运行在企业自建的Kubernetes环境中。这些子集群通过OpenYurt实现联邦,共同组成一个完整的“联邦集群”。OpenYurt的工作原理是在标准Kubernetes集群上增加一个名为Yurt Controller的控制平面组件。Yurt Controller负责管理子集群、操作Pod和资源之间的分配,同时提供安全和加密通信基础设施,让这些分布式子集群可以协同工作。用户对OpenYurt联邦集群的操作都将被映射并同步到各个子集群中。
    - url: https://github.com/karmada-io/karmada
      des: 跨云和跨集群的k8s编排平台

    - url: https://github.com/alibaba/kt-connect
      des: |
        已经EOL了，轻量级的面向k8s用户的开发测试环境治理辅助工具。其核心是通过建立本地到集群以及集群到本地的双向通道，从而提升在持续交付生命周期中开发环节的效率问题以及开发测试环境的复用问题。

        kt-connet支持一下功能：
        - 转发集群流量到本地
        - Service Mesh支持
        - 基于SSH的轻量级VPN网络：KT使用shhuttle作为网络连接实现，实现轻量级的SSH VPN网络
        - 作为kubectl插件，集成到Kubectl：也可以直接将ktctl集成到kubectl中

    - url: https://github.com/neargle/my-re0-k8s-security
      des: k8s 攻防

    - url: https://github.com/kubernetes/kops
      des: 可以理解为k8s环境下的terraform。kops支持在多种基础架构上快速安全地部署高可用性的Kubernetes集群,比如AWS、GCE、Azure、VMware等公有云,也支持Hybrid和Multi-Cloud环境。体验上和原生Kubeadm相比更友好高效,同时也提供了很多友好的管理功能来运维生产级K8s集群。需要注意的是，相比于rancher等集成了安装和管理的工具，kops只提供安装功能，不支持管理k8s集群。
    - url: https://github.com/kubernetes-sigs/kwok
      des: kwok可以在几秒钟内设置一个由数千个节点组成的集群。该工具包会模拟这些节点的行为，使其表现得像真实的节点一样，因此它的资源消耗非常低，你可以在笔记本电脑上轻松地进行测试和操作。KWOK 的主要使用场景是帮助开发人员和系统管理员在本地环境中进行大规模集群的测试和调试。它可以用于测试应用程序在大型 Kubernetes 集群中的行为，评估集群的性能和稳定性，以及进行容错和扩展性测试。此外，KWOK 还可以用于演示、培训和学习目的，让用户可以快速搭建和操作一个大规模的 Kubernetes 集群。总体而言，KWOK 是一个用于模拟大规模 Kubernetes 集群的工具包，可以在本地环境中进行快速而低资源消耗的测试和操作。
    - url: https://github.com/ccfos/nightingale
      des: nightingale相当于带运维面板的kibana，就是说在web端配置各种prom参数。还可以接入VictoriaMetrics、Thanos、Mimir、M3DB之类的各种tsdb。也可以接入Categraf、Telegraf、Grafana-agent、Datadog-agent、各种 Exporter 作为采集器。“你可以在 WebUI 上管理和配置告警策略，也可以对分布在多个 Region 的指标、日志、链路追踪数据进行统一的可视化和分析”。感觉也没啥用。
    - url: https://github.com/kubernetes-sigs/cluster-api
      des: k8s-cluster 提供的API，让我们用来通过API来进行一些自定义操作。
    - url: https://github.com/deepflowio/deepflow
      des: 用eBPF进行monitor的工具
    - url: https://github.com/actions/actions-runner-controller
      des: k8s controller for GitHub Actions self-hosted runners
    - url: https://github.com/nginxinc/kubernetes-ingress
      des: use nginx to replace k8s default ingress
    - url: https://github.com/elastic/cloud-on-k8s
      des: ECK(Elastic Cloud on Kubernetes), 相比于直接用k8s部署es和kibana，ECK提供了大量feats，比如封装了，以及扩缩容、备份恢复等生命周期管理功能。通过Operator模式监控整个Elastic集群状态,可以实现自愈能力（比如单个Pod失效后自行重启或者扩充新的Pod）。总结来说，就是大大简化在K8s上使用Elastic的难度，同时提供更高级和便捷的生命周期管理功能。
    - url: https://github.com/rook/rook
      des: 用k8s的CRD来实现存储的自动自动化编排。用rook可以轻松地在 k8s 集群上创建和管理各种类型的存储资源，如块存储、文件存储和对象存储。它支持多种存储后端，包括 Ceph、EdgeFS、Minio 等，并提供了一致的接口和工具来管理这些存储资源。不仅提供了存储编排功能，还包括了一些高级功能，如数据保护、快照、复制、调整大小等。
    - url: https://github.com/cilium/hubble
      des: Hubble 利用 eBPF 技术来实时监控和分析 Kubernetes 网络流量、服务通信和安全事件，以提供全面的可观察性和安全性。它可以帮助您了解和调试应用程序之间的网络流量、服务依赖关系，并提供强大的安全分析和审计功能。
    - url: https://github.com/kubeshark/kubeshark
      des: wireshark in k8s, 可以实时捕获和分析Kubernetes控制平面和数据平面中的所有网络流量,包括Pod、节点和集群之间的流量。它可以查看Kubernetes API请求和响应的细节,例如HTTP/gRPC方法、请求和响应主体等信息。与其他类似工具相比,Kubeshark的一个优点是可以不影响原生Kubernetes性能就可以收集流量。它通过内嵌式控制平面和数据平面代理来捕获流量,无需严重修改Kubernetes组件或仰赖外部插件。
    - url: https://github.com/ddosify/ddosify
      des: 更易用的prom，内建了一些基本metrics，不需要额外配置（所以理所当然是push监控）。当然，也可以通过插件自定义metrics。相比于prom，Ddosify监控简单易用,但定制程度相对低些。Prom采用pull模式,Ddosify采用push模式。
    - url: https://github.com/labring/sealos
      des: sealos的“应用部署”可以可视化写k8s deployment文件
    - url: https://github.com/kumahq/kuma
    - url: https://github.com/hashicorp/vault
      des: Secrets Management. k8s提供ConfigMap和secret来存储数据，但是ConfigMap是明文，secret则适用于存放密文。但是证书的签发、续签、重签都很麻烦，并且直接存放在secret中仍然安全性不足（这也是为啥有vault这样的工具）。
    - url: https://github.com/hashicorp/vault-secrets-operator
      des:
    - url: https://github.com/external-secrets/external-secrets
      des: Secrets Management. Used to replace k8s built-in secrets. 相比于内置secrets，使用外置secrets管理的好处是，使用内置secrets必须在k8s-cluster内创建和更新，不够灵活。并且不支持权限控制，所有pod和服务都能访问。但是应该说，外置和内置secrets各有使用场景。
    - url: https://github.com/hashicorp/nomad
      des: Nomad = Consul + Vault. 可以把Nomad理解为某种单节点的非常轻量的类似k8s这样的服务编排工具，但是并没有实现K8s所有的特性,比如对Pod和服务的完整生命周期管理等。Nomad 内置了Consul和Vault的客户端库,这使它可以直接利用Consul提供的服务发现和Vault提供的加密存储能力,但Nomad本身的主要目的是工作负载的编排与部署。
    - url: https://github.com/TwiN/gatus
      des: 某种uptime类似产品，而非prom的替代品。pull模式的healthcheck，不提供各种metrics，只提供HTTP, TCP, DNS之类状态的alert。
    - url: https://github.com/louislam/uptime-kuma
      des: UI更好看的uptime, 功能类似（也是监控HTTP/TCP/DNS这些），但是给每个服务提供了dashboard来查看详细数据。额外内置了所有主流平台的notification。
    - url: https://github.com/k0sproject/k0s
      des: more lightweight than k3s, 直接集成了cri，而不是cri-o或者containerd这样的独立模块。也没有ingress或者traefik这样的gateway，直接内置这些服务了。
    - url: https://github.com/ahmetb/kubectx
      des: switch between contexts (clusters) on kubectl faster.

    - url: https://github.com/txn2/kubefwd
    - url: https://github.com/GoogleContainerTools/kaniko
      des: 用来构建容器镜像的工具
    - url: https://github.com/steveteuber/kubectl-graph
      des: 最近接手了一个规模比较大的集群，光是整理集群中的资源就使人头昏眼花，虽然我自认 kubectl 使用的已经十分熟练，但是上千个 Kubernetes Resource 看下来还是不堪重负。在不能为集群安装任何其他工具的情况下，可以改造的就只有我自己的 Client 端，也就是 kubectl 了。本文就介绍一个有趣的 kubectl 插件：kubectl-graph。
    - url: https://github.com/rabbitmq/cluster-operator
      des: 最近接到一个在 K8s 中部署一个 RabbitMQ 集群的任务，既然是部署在 K8s 集群中，首选的当然是 RabbitMQ Operator 了。不过在浏览官方文档时，意外的官方也有开发一个 kubectl-rabbitmq 的插件来帮助部署和运维 RabbitMQ Operator，在试用后发现体验意外的不错。那么本文我们就使用 kubectl-rabbitmq 来部署一个 RabbitMQ 集群吧！
    - url: https://github.com/sunny0826/kubecm
      des: 该项目脱胎于 mergeKubeConfig 项目，最早写该项目的目的是在一堆杂乱无章的 kubeconfig 中自由的切换。随着需要操作的 Kubernetes 集群越来越多，在不同的集群之间切换也越来越麻烦，而操作 Kubernetes 集群的本质不过是通过 kubeconfig 访问 Kubernetes 集群的 API Server，以操作 Kubernetes 的各种资源，而 kubeconfig 不过是一个 YAML 文件，用来保存访问集群的密钥，最早的 mergeKubeConfig 不过是一个操作 YAML 文件的 Python 脚本。而随着 Go 学习的深入，也就动了重写这个项目的念头，就这样 kubecm 诞生了。
    - url: https://github.com/traefik/traefik-helm-chart
      des: traefik-helm-chart 是一个 Traefik 反向代理的 Helm Chart。Helm 是 Kubernetes 的包管理工具，而 Helm Chart 则是一种描述 Kubernetes 应用部署的文件。Traefik 是一个功能强大的开源反向代理和负载均衡器，它能够在 Kubernetes 中自动发现并动态配置路由规则，提供高可用性和可伸缩性的服务访问。使用 Traefik Helm Chart 可以方便地在 Kubernetes 集群中部署和管理 Traefik 反向代理。
    - url: https://github.com/kedacore/keda
      des: keda = K8s-based Event Driven Autoscaling. 用来替换k8s内置HPA，来实现更好的autoscaling的服务。因为HPA只能根据自身负载情况来进行扩缩容决策（而不是服务整体负载情况），这就很容易导致在一个多级微服务调用的业务场景里，压力逐级传递，不仅扩容很慢（被动扩容），而且很容易导致一个服务被“冲垮”后形成多米诺骨牌效应，所有服务都挂掉。
    - url: https://github.com/cert-manager/cert-manager
    - url: https://github.com/dotdc/grafana-dashboards-kubernetes
      des: 基于k8s的grafana dashboard







- type: k8s-operator
  repo:
    - url: https://github.com/kubernetes-sigs/kubebuilder
      des: k8s 是一个高度自动化的系统，k8s 内置了服务发现，负载均衡，HPA 等功能；但是需求总是永无止境的，当我们有未被 k8s 内置工具满足的需求时，可以使用`Operator`和`Custom Webstack`来实现；比较常见的需求如，部署一个数据库，节点自动化运维，日志采集组件配置等等。kubebuilder 就是用来实现k8s controller的（controller是一个控制循环,它会监视指定类型的对象(如 Deployment 或 StatefulSet 等),并在对象有变化时采取相应的动作），使用 KubeBuilder, 用户可以更快速方便地开发各种类型的控制器,如管理 DaemonSet、 StatefulSet、自定义资源等。控制器也可以集成各种外部系统。虽然不是 Kubernetes 核心组件,但 KubeBuilder 是开发 Kubernetes 原生应用的重要工具。它大大降低了开发控制器的难度,有利于扩展 Kubernetes 功能和定制化开发。
      qs:
        - q: operator, kubebuilder? GV(Api Group&Version), GVK(Group Version Kind), GVR(Group Version Webstack)
          x: GV 是相关 API 功能的集合，每个 group 拥有一个或多个 Versions. 每个 GV 都包含 N 个 api 类型 (也就是 kinds)，不同 Version 的 kinds 可能不同. Resource 是 Kind 的对象标识，一般来说 kind 和 resource 是 1:1 的，但是有时候存在 1:N 的关系，不过对于 operator 来说都是 1:1 的关系
    - url: https://github.com/kubernetes/sample-controller
      des: 用来学怎么写k8s的operator
    - url: https://github.com/crossplane/crossplane
      des: 面向多云环境的资源管理框架,可以轻松开发支持多云的控制器。
    - url: https://github.com/projectcontour/contour
      des: 以数据平面为导向的控理器,主要用于Ingress等负载均衡场景。
    - url: https://github.com/ko-build/ko
      des: 由Spotify开源,也采用代码生成方式,但使用TypeScript开发控制器。
    - url: https://github.com/kubernetes/client-go
      des: Go client for Kubernetes. 自己实现k8s Controller时用到。Controller 的逻辑其实是很简单的：监听 CRD 实例（以及关联的资源）的 CRUD 事件，然后执行相应的业务逻辑。






- type: k8s-security
  repo:
    - url: https://github.com/open-policy-agent/opa
      des: OPA 用来解决云原生应用的访问控制/授权和策略
    - url: https://github.com/open-policy-agent/gatekeeper
      des: 除了 PSP, RBAC, SecurityContext 等内置方案之外，在 k8s 还可以通过策略来实现一些额外的管理、安全方面的限制，比如 Gatekeeper 这个基于 OPA 的方案。
    - url: https://github.com/kubernetes-sigs/security-profiles-operator
      des: SPO(Security Profiles Operator) k8s的sec方面最难搞的就是SecurityContext 里面的 SELinux、Seccomp 和 AppArmor 三大块了。Security Profiles Operator 项目为此而来，希望能够降低在 Kubernetes 集群中使用这些安全技术的难度。在项目网页上转了转，发现他所说的简化，除了定义几个 CRD 封装这样的 Operator 传统技能之外；还有一个使用 CRD 在节点间传输 Security Profile 的能力；最后也是最重要的，提供了很方便的录制功能，这倒是真的戳中了痛点——手写 Profile 固然酷炫，录制生成才是生产力啊。
    - url: https://github.com/kyverno/kyverno
  qs:
    - q: Compare gatekeeper and kyverno.
      d: https://blog.fleeto.us/post/k8s-policy-comparison/


- type: Kernel-Trace
  des: eBPF
  repo:
    - url: https://github.com/bpftrace/bpftrace
      des: bpftrace
    - url: https://github.com/cilium/ebpf
      des: eBPF 可以通过热加载的方式动态地获取，修改内核中的关键数据和执行逻辑，避免内核模块的方式可能会引入宕机风险，并具备堪比原生代码的执行效率
    - url: https://github.com/iovisor/bcc
      des: BCC = BPF Compiler Collection. 用来分析操作系统性能和获取操作系统信息，我们可以使用 BCC 来分析系统性能，内核分析工具 eBPF 就是基于 BCC 开发的
    - url: https://github.com/microsoft/retina
      des: eBPF distributed networking observability tool for Kubernetes
    - url: https://github.com/facebook/bpfilter
      des: BPF-based packet filtering
    - url: https://github.com/Netflix/bpftop
      des: bpftop provides a dynamic real-time view of running eBPF programs. It displays the average runtime, events per second, and estimated total CPU % for each program. 用来增强 eBPF 程序优化和监控的命令行实用程序。bpftop 可以提供 eBPF 程序实时运行的快照，显示程序执行的平均持续时间、每秒处理的事件数以及每个程序的总 CPU 使用率的近似值等指标。有了这个工具，Netflix 就可以充分利用 eBPF 的功能。
  qs:
    - q: Systemtap中内核trace事件的实现
    - q: 怎么用systemtap分析进程对CPU的占用
    - q: Comparing SystemTap and bpftrace.
    - q: 怎么使用 BCC 工具？
      x: execsnoop(系统进程), opensnoop(fd), biotop(磁盘 I/O 操作), xfsslower(分析导致系统变慢的操作)
    - q: eBPF 的应用场景和最佳实践？
    - q: linux trace工具 (BCC, eBPF, systemtap, bpftrace) overhead, easy-use, extensibility, sec
    - q: 请解释eBPF的工作原理及其在Linux内核中的主要用途。
    - q: eBPF在Linux内核中的作用是什么？
    - q: 描述BCC（BPF Compiler Collection）的主要功能。
    - q: 如何使用BCC工具进行系统性能分析？
    - q: eBPF程序是如何被加载到内核中的？
    - q: 什么是eBPF的校验器，它是如何工作的？
    - q: eBPF程序的性能优势是什么？
    - q: 描述eBPF map的数据结构及其用途。
    - q: 如何使用BCC工具来追踪系统调用？
    - q: eBPF在网络安全方面的应用有哪些？
    - q: 请解释XDP（Express Data Path）在eBPF中的作用。
    - q: 如何使用BCC进行网络包过滤和监控？
    - q: 描述BCC中的kprobes和tracepoints的作用。
    - q: eBPF程序是如何与用户空间进行通信的？
    - q: 请举例说明eBPF在云原生环境中的应用。
    - q: 如何使用BCC工具来优化系统性能？
    - q: 描述eBPF程序的生命周期，包括加载、执行和卸载。
    - q: eBPF在系统监控和调试中的作用是什么？
    - q: 如何使用BCC工具来分析和优化数据库性能？
    - q: 请解释eBPF辅助函数的作用及其重要性。
    - q: 请解释eBPF的工作原理及其在Linux内核中的主要用途。
    - q: 如何使用BCC工具集进行系统性能分析和监控？
    - q: eBPF程序的校验过程包括哪些关键步骤，为什么这一过程对于系统安全至关重要？
    - q: 描述eBPF map数据结构，并举例说明其在实际应用中的作用。
    - q: 在使用BCC进行网络分析时，如何利用kprobes和tracepoints来追踪系统调用和性能事件？
    - q: 请解释XDP（Express Data Path）技术，并讨论其在高性能网络处理中的优势。
    - q: 讨论eBPF在云原生环境中的作用，特别是在Kubernetes网络插件中的应用。
    - q: 如何使用BCC工具来诊断和解决系统中的性能瓶颈问题？
    - q: 描述eBPF程序的生命周期，包括其加载、执行和卸载的过程。
    - q: 请举例说明如何使用BCC工具集来监控和分析文件系统的行为。



- type: Container-Network
  repo:
    - url: https://github.com/flannel-io/flannel
      des: 使用 Flannel 解决什么问题？flannel 使用 UDP 实现 overlay 网络的方案，解决了 docker 的跨宿主机的连通性问题。
      qs:
        - q: 使用 Flannel 解决什么问题？
    - url: https://github.com/projectcalico/calico
      des: calico 的核心在于不走 overlay 网络（直接使用物理机作为路由器），不引入另外的网络性能损耗（没有虚拟化开销），而是将转发全部用三层网络的路由转发来实现，只不过具体的实现和上面的过程稍有区别
      qs:
        - q: calico 的架构 (路由配置组件 felix, 路由广播组件 BGP speaker)
        - q: calico ipip 模式
          x: 解决跨网段的问题，也就是通过打隧道的方式，从隧道端点来看，将本来不是邻居的两台机器，变成相邻的机器
        - q: 大规模场景下的 BGP Route Reflector
        - q: "*calico 是什么？calico 的架构？calico 网络模型的设计思路？calico 网络的转发细节？*"
  qs:
    - q: 几种常见Overlay网络
      a: |
        Overlay 模式：笔者在 VXLAN 篇已经介绍过 Overlay 网络通信的原理，这是一种虚拟的上层逻辑网络，其优点是不受底层网络限制，只要是三层网络互通，就能完成跨数据中心的网络互联，但弊端是数据封包、解包有一定的计算压力和网络延迟消耗。在一个网络受限的环境中（譬如不允许二层通信，只允许三层转发），那么就意味着只能使用 Overlay 模式网络插件。常见的 Overlay 模式网络插件有 Cilium（VXLAN 模式）、老牌的 Calico（IPIP 模式）以及 Flannel（VXLAN）等。

        三层路由，主要是借助 BGP/hostgw 等三层路由协议完成路由传递。这种方案优势是传输率较高，不需要封包、解包，缺点是 BGP 等协议在很多数据中心并不支持，且设置也很麻烦。常见的路由方案网络插件有 Calico（BGP 模式）、Cilium（BGP 模式）。

        underlay 模式 基于 macvlan、ipvlan 等，这种模式所配置的容器网络同主机网络在同一个 LAN 里面，可以具有和主机一样的网络能力，并且没有其它诸如 bridge 等方式带来的 bridge 处理和地址翻译的负担，这种方式能最大限度的利用硬件的能力，往往有着最优先的性能表现，但也由于它直接依赖硬件和底层网络环境限制，必须根据软硬件情况部署，没有 overlay 那样开箱即用的灵活性。

        此外，对于容器编排系统来说，网络并非孤立的功能模块，还要能提供各类的网络访问策略能力支持，譬如 Kubernetes 的 Network Policy 这种用于描述 Pod 之间访问这类 ACL 策略以及加密通信，这些也明显不属于 CNI 范畴，因此并不是每个 CNI 插件都会支持这些额外的功能。如果你有这方面的需求，那么第一个就要排除 Flannel 了，如果按功能的丰富度而言，受到广泛关注的无疑是 Calico 和 Cilium。

        从结果上看，综合吞出量、延迟表现或者资源占用的表现 Cilium 无疑非常出色。最后，且刨除网络受限环境的影响，假设所有的 CNI 插件我们都可以选择，笔者给到以下建议：如果只是一个小型节点集群，且不关心安全性，那么建议使用最轻最稳定的 Flannel；如果是一个标准化的集群，且看中 CNI 之外的功能（譬如可观测、Network Policy、加密通信），笔者建议就选择势头正劲的 Cilium。


- type: k8s-cluster-management
  repo:
    - url: https://github.com/lima-vm/lima
      des: KVM
    - url: https://github.com/abiosoft/colima
      des: colima的proxy太折磨了，现在会自动detect proxy，所以就不需要手动配置proxy了，但是能够detect到，不意味着能成功使用，所以启动之后最好再docker pull alpine看看docker能否成功fetch image
      cmd:
        - c: colima restart
        - c: colima start && colima start --kubernetes
        - c: colima status
        - c: colima start --runtime containerd
        - c: colima template
          x: Setting the default config
        - c: colima list
        - c: colima start --edit
        - c: colima stop
        - c: colima start --cpu 4 --memory 6 --disk 100 --vm-type=qemu --mount-type=sshfs --dns=1.1.1.1
        - c: colima start --mount $HOME/project:/project:w
          x: Mounting Volumes
        - c: colima delete
          x: delete colima and all settings
    - url: https://github.com/kubernetes/minikube
      des: 内置了k8s dashboard，非常棒，可以完美替换掉colima+k8s dashboard，并且解决了很多colima的小毛病。
      cmd:
        - c: minikube dashboard
          x: 启动 Minikube 的 Kubernetes dashboard
        - c: minikube start --driver=docker --container-runtime=docker
          x: 使用 Docker 作为虚拟化程序和容器运行时启动 Minikube
        - c: eval $(minikube docker-env)
          x: 设置环境变量，使得 Docker 能够构建和运行 Minikube 中的镜像
        - c: minikube addons list
          x: 列出所有可用的 Minikube 插件（addons）

    - url: https://github.com/orbstack/orbstack
      des: OrbStack 和 colima + minikube
    - url: https://github.com/k3s-io/k3s
      des: By removing dispensable feats (legacy, alpha, non-default, in-tree plugins) and using lightweight components (e.g. sqlite3 instead of etcd3) they achieved a significant downsizing. This results in a single binary with a size of around 60 MB.
    - url: https://github.com/kubernetes-sigs/kind
      des: As the name suggests it moves the cluster into Docker containers. This leads to a significantly faster startup speed compared to spawning VM.
    - url: https://github.com/kubernetes/kubeadm
    - url: https://github.com/portainer/portainer
    - url: https://github.com/derailed/k9s
      des: Used to manage k8s cluster. A TUI tool. 如果是中小集群的话，用k9s也是个好选择. k9s的快捷操作确实比用web管理要爽. k9s还支持插件机制，我们可以用插件来添加自定义命令。但是还是喜欢点开即看的UI，不习惯这种还要再输入命令，才能看到的，所以就没怎么用了。如果Goland支持（像database的query一样）直接把terminal默认放到editor区使用就更好了。否则查看类似k9s这种大量信息的cli工具就不太方便。
      cmd:
        - c: k9s version
        - c: k9s info
          x: To get info about K9s runtime (logs, configs, etc..)
        - c: k9s help
          x: List all available CLI options
        - c: k9s -n mycoolns
          x: To run K9s in a given namespace
        - c: k9s --context coolCtx
          x: Start K9s in an existing KubeConfig context
        - c: k9s --readonly
          x: Start K9s in readonly mode - with all cluster modification commands disabled
    - url: https://github.com/rancher/rancher
      des: rancher是用来管理k8s cluster的，如果只是用来作为开发环境使用，可能不是个好主意。
    - url: https://github.com/kubesphere/kubesphere
      des: KubeSphere、Rancher 都有商业公司运作，为了增加黏性，都会具有一定入侵性。KubeSphere 要求子集群安装最小化的 KubeSphere，Racher 要求安装 Agent。KubeSphere 针对的是开发全场景，Racher 针对的是集群运维管理。
  qs:
    - q: Compare minikube, kubeadm, rancher, kind and k3s? (scalability)


- type: Docker
  md: true
  repo:
    - url: https://github.com/qemu/qemu
      des: |
        KVM
        PVE / Proxmox VE (Proxmox Virtual Environment)

        PVE首先是一个daemon，然后提供了一个web（而不是GUI）用来操作，PVE 结合了 KVM 完全虚拟化和轻量级 Linux 容器 (LXC)
    - url: https://github.com/yifengyou/learn-kvm
    - url: https://github.com/kholia/OSX-KVM
    - url: https://github.com/input-leap/input-leap

    - url: https://github.com/moby/moby
      doc: https://docs.docker.com/reference/
      cmd:
        - c: docker image run
        - c: docker stats --no-stream <container>
          x: 查看 docker 容器的内存占用，只返回当前状态
        - c: docker stats --format 'table {{.Name}}\t{{.CPUPerc}}\t{{.MemUsage}}' <container>
          x: 查看 docker 容器的内存占用，格式化输出
        - c: docker inspect --format='{{.Name}} - {{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' $(docker ps -aq)
          x: 查看所有docker容器的ip
        - c: docker inspect --format='{{.LogPath}}' <container-name>
          x: 清理某个容器的运行日志
        - c: docker inspect <container-id> --format='{{.State.ExitCode}}'
          x: 查看某个容器的退出码。退出码必须在 0-255 之间，0 表示正常退出。外界将程序中断退出，状态码在 129-255。程序自身异常退出，状态码一般在 1-128。
        - c: docker ps --format 'table {{.Names}}\t{{.Image}}\t{{.Ports}}\t{{.ID}}\t{{.Status}}'
          x: 格式化查看 docker ps
        - c: docker network prune
          x: 清理所有没用的容器网络
        - c: docker volume ls/inspect/rm/prune
          x: prune, 删除所有现在没有使用的数据卷(类似image的prune)
        - c: docker search <formulae>
          x: 从官方仓库搜索image
        - c: docker pull
          x: 拉到本地
        - c: docker system df
          x: 查看images, containers, volumes所占用的空间
        - c: docker commit
          x: 提交镜像
        - c: docker history <nginx:latest>
          x: 查看本地镜像的历史提交记录
        - c: docker diff <container name/id>
        - c: docker exec -it <container name/id> /bin/bash
          x: 进入容器使用exec，而不是attch，因为attch退出后会导致容器停止
        - c: docker export/import
          x: 导出/导入 容器
        - c: docker image rm $(docker image ls -q <image name>)
          x: 删除镜像名中含有<image name>的镜像
        - c: docker image prune -a
          x: 清除所有没有使用的镜像(不仅是dangling images)
        - c: docker image prune
          x: 删除所有dangling images(就是没有tag的镜像，比如说二阶段提交后遗弃的一阶段镜像)
        - c: docker image prune -a -f && docker container prune -f && docker rmi $(docker images | grep "^<none>" | awk "{print $3}")
          x: 删除悬空镜像、不用的容器、批量删除tag为none的镜像
        - c: docker inspect --format '{{ .State.Pid }}' <CONTAINER ID or NAME>
          x: 获取某个容器的PID信息
        - c: docker inspect --format '{{ .NetworkSettings.IPAddress }}' <CONTAINER ID or NAME>
          x: 获取某个容器的IP地址
        - c: docker container prune
          x: Remove all stopped containers. 清理所有stopped的容器
        - c: docker system prune
          x: Remove unused data. 清理所有的stopped的容器、所有dangling状态的image、无用网络
        - c: docker rm -fv <containerID>
          x: 停止删除容器，并删除volume
        - c: docker container stop/rm $(docker ps -aq)
          x: 停止/清除 所有容器
        - c: docker manifest inspect --verbose <image>
          x: 查看manifest (RepoTags, Config, Layers)信息，如果需要更简要的输出，就去掉--verbose
        - c: docker image inspect <image>
          x: 比如 docker image inspect <debian>
        - c: docker exec -it $(docker ps -ql) sh
          x: 查看docker iptables rules
        - c: docker info | grep Storage
      qs:
        - q: "***How does docker works? docker arch? (docker arch, runc)***"
          x: 弱隔离，容器的本质是进程 runc(namespace, cgroup, overlay2, CNM(libnetwork), LSM(Linux Security Modules))
        - q: docker解决了什么痛点? docker容器怎么确保isolation?
        - q: cgroup的发展历史?
          x: 在 2006 年，Google 的工程师（ Rohit Seth 和 Paul Menage 为主要发起人） 发起了这个项目，起初项目名称并不是cgroups，而被称为进程容器（process containers）。在 2007 年cgroups代码计划合入Linux 内核，但是当时在 Linux 内核中，容器（container）这个词被广泛使用，并且拥有不同的含义。为了避免命名混乱和歧义，进程容器被重名为cgroups，并在 2008 年成功合入 Linux 2.6.24 版本中。cgroups目前已经成为 systemd、Docker、Linux Containers（LXC） 等技术的基础。
        - q: cgroup是怎么通过subsystem, cgroup, hierarchy实现资源限制的?
        - q: cgroup是怎么限制进程的CPU使用时间，以及内存的？
          x: cpu是通过cfs_quota来进行限制的, memory是通过limit_in_bytes进行来限制该进程的内存使用的
        - q: "***What happens when docker images build?***"
        - q: 容器怎么对应用进行打包？有哪几种方法？
        - q: 如何正确获取容器的 CPU 利用率？
        - q: Docker容器里进程的 pid 是如何申请出来的？
        - q: How does 'docker squash' works?
          x: (smaller image) when squashing, Docker will take all the filesystem layers produced by a build and collapse them into a single new layer.
        - q: 如何查看 docker 容器的内存占用？
        - q: 如何获取 docker 容器的 CPU 利用率？
        - q: docker events.
      qq:
        - topic: docker network
          qs:
            - q: docker 的network mode有哪几种？ # host, container, bridge, overlay
            - q: docker是怎么用iptables来实现容器之间通信的（network traffic的控制和transfer）？
            - q: docker iptables的DOCKER-USER和DOCKER-ISOLATION-STAGE是怎么搭配工作的？rules？具体流程？
            - q: 能不能把容器网络的iptables, docker0, veth, VXLAN, flannel, calico, tun/tap & veth-pair这些东西给我串讲一下？用上面把kernel类比成公司的例子，找到这些概念各自的类比，并说明他们之间的关系
              x: Docker 在安装的时候会创建一个 docke0 的虚拟网桥，然后当运行容器时，在宿主机上创建虚拟网卡 veth pair 设备，veth pair 设备是成对出现的，从而组成一个数据通道，数据从一个设备进入，就会从另一个设备出来。将veth pair 设备的一端放在新创建的容器中，命名为 eth0；另一端放在宿主机的 docker0 中，以 veth 为前缀的名字命名
            - q: Docker主导的CNM和k8s主导的CNI这两种容器网络的spec有啥区别? 或者说，能否比较一下docker和k8s的network？ (比如说从spec, network mode, 插件生态等方面比较)
            - q: Docker容器网络是如何实现跨主机通信的？
            - q: Docker网络支持哪些类型的网络驱动？
              x: Docker网络支持多种类型的网络驱动，包括原生网络驱动（如bridge、host、overlay、macvlan、none）和远程网络驱动（如contiv、weave、calico、kuryr等）
            - q: Docker网络如何进行IP地址管理？
              x: Docker网络使用容器网络模型（CNM）进行IP地址管理，提供原生IPAM驱动程序和远程IPAM驱动程序的接口。用户可以通过UCP、CLI或Docker API手动配置容器IP地址和网络子网。
            - q: docker的IPAM driver是啥？怎么用？
            - q: docker0, How docker0 is related to eth0?
            - q: docker容器怎么capture packet

        - topic: docker fs
          qs:
            - q: docker的storage engine为啥从AUFS到Devicemapper，最终选择OverlayFS(overlay2)
              x: |
                这三种fs分别对应Debian/Ubuntu, RHEL(CentOS) 和 overlay2. 可以把DeviceMapper理解类似“虚拟内存之于物理内存映射”的东西，*是用来把物理storage映射为虚拟storage的机制。
            - q: overlay2 如何读取文件？
              x: |
                其实就是经典的“从近到远”，先容器层后镜像层。CPU读取数据同样如此（先CPU本地的L1-L3，然后再读内存）。
            - q: overlay2 怎么修改文件?
              x: |
                *overlay2使用COW来修改文件，主要是为了节省存储空间*。需要注意的是，overlay2并不会真正删除文件，而是放到一个无法访问的null path，直到执行prune操作时才删除
            - q: overlay2 link, lower, diff.
              x: |
                *link是该layer的短id，lower是该layer的所有父layer的短id，diff是修改* # link 和 lower 文件与镜像层的功能一致，**link 文件内容为该容器层的短 ID，lower 文件为该层的所有父层镜像的短 ID 。diff 目录为容器的读写层，容器内修改的文件都会在 diff 中出现，merged 目录为分层文件联合挂载后的结果，也是容器内的工作目录。**
            - q: overlay2
              x: |
                overlay2 和 AUFS 类似，它将所有目录称之为层（layer），overlay2 的目录是镜像和容器分层的基础，而把这些层统一展现到同一的目录下的过程称为联合挂载（union mount）。overlay2 把目录的下一层叫作lowerdir，上一层叫作upperdir，联合挂载后的结果叫作merged。
        - topic: Dockerfile
          qs:
            - q: Dockerfile, best practices?
              x: |
                - build(size, layer, build speed(build cache), multi-stage, .dockerignore, single line RUN, not-latest tag)
                - security(hardware resource) 默认容器中的 root 用户映射到主机上的非 root 用户，不使用 --privileged 进行提权就ok了
                (default(BuildKit, auth control)
            - q: How to write Dockerfile? spec?
              x: FROM, EXPOSE, USER, ADD/COPY, ONBUILD, WORKDIR, ENV, ARG, , CMD/ENTRYPOINT, RUN, LABEL, VOLUME, HEALTHCHECK
            - q: Compare COPY, MV and ADD?
              x: COPY(copy and move is faster) > ADD(download, unzip), MV(rename, delete)
            - q: Dockerfile unified, 拆开的multi-stage build写法?
            - q: "***dockerfile 中 ONBUILD 的用法?***"
              x: |
                我的 dockerfile 加上这个指令，别人可以更方便地自定义 dockerfile。
                在 Dockerfile 中的用途是创建一个构建触发器，这个触发器会在后续基于当前镜像的任何 Dockerfile 构建过程中被自动执行。它的主要目的是让镜像创建者定义一些默认的操作步骤，使得使用这个镜像作为基础镜像的其他 Dockerfile 能够自动继承这些设置。
                以下是一些使用 ONBUILD 指令的场景：

                - 传递构建上下文：如果你知道基于你的镜像的其他 Dockerfile 需要某些特定的文件，你可以使用 ONBUILD ADD 或 ONBUILD COPY 指令来自动添加这些文件。
                - 自动安装依赖：如果你的应用程序需要某些依赖，而这些依赖在构建过程中需要安装，可以使用 ONBUILD RUN 来自动执行安装命令。
                - 设置环境变量：如果你的应用程序需要特定的环境变量，可以使用 ONBUILD ENV 来设置这些环境变量。
                - 配置启动命令：如果你的应用程序需要特定的启动命令，可以使用 ONBUILD CMD 或 ONBUILD ENTRYPOINT 来设置默认的启动命令。
                - 清理构建上下文：有时你可能需要在构建过程中删除一些不必要的文件以减小镜像大小，可以使用 ONBUILD 指令来执行清理操作。


        - topic: docker compose
          qs:
            - q: docker-compose.yml有哪些常用key? (common, network, volume, healthcheck, others) # (container_name, image, build, command, volume, environment, expose, ports, depends_on)
            - q: docker-compose restart strategies?
            - q: network (interval, driver, ipam/subnet)
            - q: How to capture traffic(packets) from docker container?
            - q: Compare network model between docker and k8s? # (spec, network mode, plugins ecosystem)
            - q: image, manifest.json # (RepoTags, Config, Layers)
            - q: How to correctly obtain the CPU utilization of a container?
            - q: How to use extends to override compose file(multi compose)?
            - q: volume, mount ns, inode (new inode, after delete file)
    - url: https://github.com/moby/buildkit
      des: |
        Docker的默认构建引擎, concurrent, cache-efficient, and Dockerfile-agnostic builder toolkit. BuildKit 除了作为 Docker 的构建引擎外，也可以被独立使用，或者被其他工具集成，比如 Tekton，Dagger 等。
        BuildKit 有很多优秀的特性，比如：可以在多阶段构建中检测并跳过执行未使用的构建阶段；并发构建独立的构建阶段，这可以显著提升构建的效率；避免与其他API（中间镜像和容器）产生副作用。
        使用多阶段构建，构建的镜像中只包含了目标文件夹 dist，但仍然存在一些问题，当 package.json 文件变动时，RUN npm i && rm -rf ~/.npm 这一层会重新执行，变更多次后，生成了大量的中间层镜像。
        为解决这个问题，进一步的我们可以设想一个类似 数据卷 的功能，在镜像构建时把 node_modules 文件夹挂载上去，在构建完成后，这个 node_modules 文件夹会自动卸载，实际的镜像中并不包含 node_modules 这个文件夹，这样我们就省去了每次获取依赖的时间，大大增加了镜像构建效率，同时也避免了生成了大量的中间层镜像。
      qs:
        - q: How to use BuildKit in Dockerfile? # mount cache/file/tmpfs/bind
        - q: How does BuildKit works?
    - url: https://github.com/moby/libnetwork
      des: CNM spec的实现，相当于docker根目录下的libnetwork单独做成项目了。抽象出sandbox, endpoint, network三种对象。
    - url: https://github.com/docker/buildx
      des: buildx 使用 buildkit 进行构建，支持许多新的功能。Buildx 可以认为是 BuildKit 的前端，主要是为了能提供 BuildKit 的一些能力。 在 Docker v23.0.0 中，docker build 实际已经成为了 docker buildx build 的别名。docker buildx 同样具备了非常丰富的特性，其中一个有趣的特性在于 它支持设置不同的构建驱动，包括使用 docker-container ， Kubernetes 和 remote。
    - url: https://github.com/containers/podman
      des: 某种Docker
    - url: https://github.com/cri-o/cri-o
      des: k8s CRI
    - url: https://github.com/opencontainers/runc
      des: runc = run container
    - url: https://github.com/google/gvisor
      des: ??? gvisor不是CRI，而是用来和CRI搭配使用。为运行在它之上的应用程序提供一个隔离的环境，从而减少了系统内核暴露于容器的攻击面。gVisor捕获应用程序的系统调用并且在用户空间中执行它们，这提供了比传统容器更强的安全性。实际上gvisor是在container和宿主机之间提供了一个隔离层，来提高容器的安全性。
    - url: https://github.com/docker/compose
      cmd:
        - c: docker-compose logs -tf --tail 10
        - c: docker-compose up --detach --build <container-name>
          x: 在docker-compose中重新启动单个容器
        - c: docker-compose down && docker-compose up --build -d
        - c: docker compose up -d --build
          k: true
          x: 启动服务，重新编译镜像，最有用的命令
        - c: docker compose build
          x: 进行所需的服务镜像构建
        - c: docker compose config
          x: 查看docker-compose配置文件
        - c: docker compose down
          x: 停掉服务，删除容器，不删除镜像 docker stop container && docker rm container
        - c: docker compose events
          x: 接受服务之间的互动事件，如进行健康检查等
        - c: docker compose exec
          x: 进入容器，或者对某个容器执行命令
        - c: docker compose images
          x: 列出所有镜像
        - c: docker compose top
          x: 显示各个容器内运行的进程
    - url: https://github.com/compose-spec/compose-spec
      des: Compose Spec is also implemented by Docker Compose, Kompose, Nerdctl, Okteto Stacks, Docker Cloud Integrations, Podman Compose.
    - url: https://github.com/composerize/composerize
      des: 把 Dockerfile 转为 dc
    - url: https://github.com/laradock/laradock
      des: 这个repo本身是为了搭建php开发环境，但是实际上
    - url: https://github.com/docker/awesome-compose
    - url: https://github.com/kubernetes/kompose
      des: kompose, 把 docker-compose 转换为 k8s
  qs:
    - q: Docker、containerd、CRI、CRI-O、OCI、runc 这些概念都是啥关系?
      x: Docker 是一个完整的容器化平台，包括容器格式、运行时和生态系统；containerd 是 Docker 的一个组件，用于管理容器；CRI 定义了 Kubernetes 与容器运行时之间的接口；CRI-O 是符合 CRI 规范的轻量级容器运行时；OCI 定义了容器镜像格式和运行时规范；runc 实现了 OCI 容器运行时规范，是其他容器平台的默认容器运行时。 换句话说，这里只有两类概念，containerd和CRI-O都是CRI，属于"high-level container runtime"，支持更多高级功能，而runc之类的则属于 "low-level container runtime", 只关注如 namespace、cgroups、镜像拆包等基础功能。

    - q: Compare CRI.
      d: https://www.zhangjiee.com/blog/2021/container-runtime.html
      x: docker-shim就是k8s将docker适配到CRI的一种实现。后来docker把containerd独立出来了，k8s就可以直接与containerd通信了，所以containerd提供了CRI-containerd作为CRI实现。再之后到了v1.1，containerd原生支持CRI实现，那么CRI-containerd就没用了，直接踢掉，调用链路进一步变短。所以现在来说，CRI的两个主要实现就是containerd和cri-o




- type: Docker-Linter
  repo:
    - url: https://github.com/hadolint/hadolint
    - url: https://github.com/aquasecurity/trivy
      des: docker 的镜像安全检测工具，查找 docker 容器、k8s 中是否有错误配置、密钥、SBOM 以及漏洞。（desktop 内置了，但是这个看起来更直观）, better than quay/clair and anchore/grype
    - url: https://github.com/wagoodman/dive
    - url: https://github.com/slimtoolkit/slim
      des: 优化和缩小 docker 镜像大小. 其实没啥用，并且不好用
    - url: https://github.com/wagoodman/dive
      des: image layer. 镜像分析工具，查看各层信息
    - url: https://github.com/bcicen/ctop
      des: top in containers




- type: Tracing
  md: true
  repo:
    - url: https://github.com/jaegertracing/jaeger
    - url: https://github.com/elastic/apm-server
      des: APM就是tracing，所以这个没啥用，目前主流tracing是jaeger。apm-server也支持OpenTelemetry标准
    - url: https://github.com/openzipkin/zipkin
      des: built-with java
    - url: https://github.com/uptrace/uptrace-go
      des: ???
    - url: https://github.com/open-telemetry/opentelemetry-go
      des: ???
    - url: https://github.com/open-telemetry/opentelemetry-collector-contrib
      des: 可扩展的数据收集器，用于收集、转换和导出遥测数据。Contrib存储库包含了由OpenTelemetry社区贡献的各种插件、扩展和工具，用于增强和扩展OpenTelemetry Collector的功能。
  qs:
    - q: Compare skywalking, zipkin, jaeger, open-falcon # otel, OpenTracing, OpenCensus
    - q: (traceId, spanId) 分布式链路跟踪中的traceid和spanid代表什么？
      x: trace 是请求在分布式系统中的整个链路视图，span 则代表整个链路中不同服务内部的视图，span 组合在一起就是整个 trace 的视图。




# [17 个方面，综合对比 Kafka、RabbitMQ、RocketMQ、ActiveMQ 四个分布式消息队列](https://mp.weixin.qq.com/s?__biz=MzkyNTI5NTQ1NQ==&mid=2247500561&idx=1&sn=931cf980b218db76225c8d12899adf09&source=41#wechat_redirect)
- type: MQ
  md: true
  repo:
    - url: https://github.com/apache/kafka
      key: true
      doc: https://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ==&amp;mid=2650719847&amp;idx=1&amp;sn=5cbc20ae39756e39552a9a056c133a80
      qs:
        - q: kafka arch? 为啥kafka设计为“轻server重client”的架构?
          x: |
            在将消息发送给 Broker 之前，需要先在 Client 端完成大量的工作，例如：消息的分区路由、校验和的计算、压缩消息等。这样便很好地分摊 Broker 的计算压力。
        - q: basic components? (producer, consumer(/group), broker, topic, partition, offset, record, replica)
          x: |
            可以把 kafka 想像成高速路，而京广高速可以想像成一个 topic(主题路由)，京广高速上有很多车道进行分流，每个车道上的车都通往相同目的地 (同一个 topic)，这里的车道就是 partition(分区路由)
        - q: kafka 的吞吐率为什么那么高
          x: |
            (写入数据时顺序写入+MMAP) (读取数据时零拷贝 + 批量压缩) msg ordering, mmap, zero copy, batch compress
        - q: "***有哪些常见的 kafka 的坑？(背压、消息有序、重复消费、不丢消息)***"
        - q: kafka broker 网络通信模型? kafka对reactor的实现?
          x: |
            通俗点记忆就是 1 + N + M. Acceptor + Processor + KafkaRequestHandler

            1：表示 1 个 Acceptor 线程，负责监听新的连接，然后将新连接交给 Processor 线程处理。
            N：表示 N 个 Processor 线程，每个 Processor 都有自己的 selector，负责从 socket 中读写数据。
            M：表示 M 个 KafkaRequestHandler 业务处理线程，它通过调用 KafkaApis 进行业务处理，然后生成 response，再交由给 Processor 线程。

            对于 IO 有所研究的同学，应该清楚：Reactor 模式正是采用了很经典的 IO 多路复用技术，它可以复用一个线程去处理大量的 Socket 连接，从而保证高性能。Netty 和 Redis 为什么能做到十万甚至百万并发？它们其实都采用了 Reactor 网络通信模型。
        - q: kafka 多个 partition 怎么对应多个 consumer group 的 consumer # rebalance 机制
        - q: kafka 可靠性 日志如何保存 副本机制 ack
        - q: kafka 里怎么保证 exactly once？
        - q: kafka 的 producer端、broker端、consumer端分别 怎么保证信息不丢失？
        - q: kafka 怎么保证消息有序？
          d: https://medium.com/latentview-data-services/how-to-use-apache-kafka-to-guarantee-message-ordering-ac2d00da6c22

        - q: kafka 怎么解决背压问题?
          x: |
            消息积压问题可能由多种原因引起，如消息体过大、路由规则不合理、批量操作等。优化方法包括：减少消息体大小，只包含必要的关键信息；调整路由规则，使消息更均匀地分布在不同的partition上；对于批量操作，提前通知下游系统并做好压测；监控消息积压情况，并及时调整消费者的数量或处理策略。
        - q: AR(Assigned Replicas 所有副本)=ISR (In-Sync Replicas 副本同步队列)+OSR(Out-Sync Replicas)
          x: |
            ISR 是由 leader 维护，follower 从 leader 同步数据有一些延迟，超过相应的阈值会把 follower 剔除出 ISR, 存入 OSR（Out-of-Sync Replicas）列表，新加入的 follower 也会先存放在 OSR 中。AR=ISR+OSR
        - q: LEO, HW, LSO, LW
        - q: Network Model (TPC+reactor)
        - q: bottleneck of kafka? How to resolve?
          x: |
            disk io(msg ordering, mem-pool, page cache, zero copy(sendfile)), network io(batch compress msg and batch send, serialize msg using pb, reactor
        - q: Kafka的存储系统是如何设计的？
          x: |
            Kafka的存储系统设计是为了满足高并发、高可用和高性能的需求。它主要处理实时产生的海量数据流，需要高效地存储和检索数据。Kafka的存储系统基于顺序追加写日志的方式，并通过稀疏索引来快速定位消息。它的存储架构包括主题（Topic）、分区（Partition）、副本（Replica）、分段（Segment）和索引（Index）。每个分区的日志被分为多个日志分段，每个分段包含日志文件和索引文件，以便高效地进行消息的查找、维护和清理。
        - q: Kafka为什么选择基于日志存储而不是关系型数据库的B+树索引结构？
          x: |
            Kafka选择基于日志存储的原因是其设计目标是为了处理高并发写入的场景，而关系型数据库的B+树索引结构在大量写操作时会因为索引维护而降低效率。B+树索引结构还需要额外的空间来存储索引，并可能出现数据页分裂等问题，这些都不适合Kafka的高并发系统需求。相反，日志存储可以通过顺序追加写的方式来提高写入速度，并且可以通过稀疏索引来高效地查询数据。
        - q: Kafka的日志格式有哪些版本，它们之间有什么区别？
          x: |
            Kafka的日志格式有三个主要版本：V0、V1和V2。V0版本包含消息的Offset和大小，而V1版本在此基础上增加了时间戳字段。V2版本是对日志格式的大幅度重构，它使用可变长度类型来提高空间使用率，增加了消息总长度字段，使用增量形式保存时间戳和位移，并将一些字段统一抽取到RecordBatch中，以提高批量发送消息时的效率和减少磁盘空间的使用。
        - q: Kafka提供了哪些日志清理机制？
          x: |
            日志删除（Log Retention）和日志压缩（Log Compaction）。日志删除策略根据保留策略直接删除不符合条件的日志分段，而日志压缩策略则是针对每个消息的key进行整合，只保留最后一个版本的value。这两种策略可以通过Kafka Broker端的参数log.cleanup.policy来设置。
        - q: Kafka如何利用操作系统的PageCache来提高性能？
          x: |
            Kafka通过使用操作系统的PageCache来减少对磁盘I/O操作。PageCache是操作系统用来缓存文件内容的内存区域，当进程需要读取或写入文件时，操作系统会优先检查PageCache，如果所需数据在PageCache中，则直接进行操作，避免了磁盘I/O。此外，Kafka还使用了零拷贝（Zero-Copy）技术来进一步提升性能，减少数据在内核空间和用户空间之间的复制次数。
        - q: Kafka消费者：监听模式VS主动拉取，哪种更适合你？


    - url: https://github.com/etf1/kafka-message-scheduler
      des: 用来实现kafka的延迟队列
    - url: https://github.com/IBM/sarama
      des: kafka client in golang
    - url: https://github.com/conduktor/kafka-stack-docker-compose
      des: docker compose files to create a fully working kafka stack
    - url: https://github.com/strimzi/strimzi-kafka-operator
      des: Strimzi 提供了一种 k8s 原生的方式，通过一组扩展了 k8s API 的 Operator 与 Kafka 进行交互，来简化在 k8s 上配置、部署和运维 Kafka
    # [RocketMQ 可观测性之 Metrics](https://blog.lv5.moe/p/rocketmq-observability-metrics)
    # [RocketMQ 消息堆积算法详解与优化](https://blog.lv5.moe/p/explanation-and-optimization-of-apache-rocketmq-lag)
    # [RocketMQ 多级存储设计与实现](https://blog.lv5.moe/p/introduce-tiered-storage-for-rocketmq#%E9%A2%84%E8%AF%BB%E7%BC%93%E5%AD%98)
    - url: https://github.com/apache/rocketmq
    - url: https://github.com/beanstalkd/beanstalkd
      des: lightweight work queue
    - url: https://github.com/reugn/go-streams
      des: 可以理解为简易版kafka，或者redis stream的golang实现。需要注意的是go-streams与这些只是功能上类似，但是实际上完全不同，kafka就不说了，redis stream也需要安装redis，乃至NATS、NSQ这些都需要安装服务，但是go-streams是个pkg，可以直接在golang中使用。其他MQ的使用场景如日志、传感器数据、网络流量之类的，go-streams也能胜任。还内置了各种filter，来对数据进行过滤、转换、合并、拆分等操作（可以理解为数据聚合操作）。
    - url: https://github.com/hibiken/asynq
      des: |
        Distributed Task Queue, 跟go-streams的区别在于，go-streams更侧重于处理数据流和流式计算，而asynq则更侧重于任务队列和处理异步任务（以及一些基本功能如优先级任务队列、Retry, Task Timeout）。
        asynqmon 是适配的Web UI

    - url: https://github.com/rabbitmq/rabbitmq-server
      qs:
        - q: RabbitMQ是主流MQ中唯一原生支持延迟任务的，那RabbitMQ是怎么实现的? TTL, DLX, DLQ分别是啥?
          x: |
            通过结合使用 TTL 和 DLX，你可以创建一个延迟队列。具体步骤如下：

            - 设置一个队列的 TTL，使其小于你希望消息延迟的时间。
            - 创建一个 DLX，并定义一个路由规则，将过期的消息路由到一个特定的 DLQ。
            - 在 DLQ 中处理延迟消息，或者再次将它们发送到另一个队列以实现所需的延迟效果。



    - url: https://github.com/streadway/amqp
      des: 操作 rabbitMQ 服务
    - url: https://github.com/rabbitmq/rabbitmq-delayed-message-exchange
      des: rabbitMQ插件实现延迟队列
    - url: https://github.com/nats-io/nats.go
      des: NATS
    - url: https://github.com/nats-io/nats-server
      doc: https://docs.nats.io/
      qs:
        - q: nats三种模式 (pubsub, queue), request reply
        - q: "@request reply"
        - q: nats的JetStream是啥? 能否用JetStream实现nats的延迟任务? 怎么实现?
          x: NATS之前有个streaming的拓展(nats-streaming-server)，EOL之后使用JetStream代替，实现持久化。

    - url: https://github.com/cz-theng/nats-source
      des: nats源码解读。暂时不看。
    - url: https://github.com/nsqio/nsq
    - url: https://github.com/celery/celery
      des: Distributed Task Queue in Python
    - url: https://github.com/zeromicro/go-queue
      des: Kafka, Beanstalkd Pub/Sub framework.
    - url: https://github.com/sahib/timeq
      des: 有点意思，可以看看。file-based priority queue.
  qs:
    - q: "***Compare kafka, NATS and NSQ?***"
      x: |
        arch, perf(throughput, latency), scalability, durability(fault tolerance, failover), msg delivery semantics, msg ordering, network model, storage model, feats(retry, delay queue) and use cases
        - 开发语言
        - 支持协议
        - 消息存储
        - 消息事务
        - 负载均衡
        - 集群方式
        - 管理界面
        - 可用性
        - 消息重复
        - 吞吐量 TPS
        - 订阅方式和消息分发
        - 顺序消息
        - 消息回溯
        - 消息重试
        - 并发度

    - q: MQ能够解决哪些问题？*有哪些核心需求（或者说特点）？*
      x: 通常认为MQ的作用是“削峰填谷、消息分发、异步通信、架构解耦”，按照我的理解，最核心的是“解耦和异步处理”，用来在高并发场景下平滑短时间内大量的服务请求，不使用消息队列的系统，根据木桶效应，性能取决于系统中性能最慢的组件，但是消息队列可以将组件解耦，各组件异步执行。如果没有 MQ，只能在服务里耦合限流服务，那么不管是上游限流，还是下游限流，都会引入业务的复杂性。所以，我们可以把限流通过 MQ 解决，也起到了解耦的作用。

    - q: MQ有哪些相关基础概念（比如说调度算法、消息模式）？
    - q: 消息队列的消息模式是啥意思？kafka、NATS、NSQ这些都有什么消息模式？
      x: 四种，P2P, Pub/Sub, Request-Reply, Broadcast. 本质来说被多少consumer接收和消费（比如说P2P就是只有1个consumer，而Pub/Sub和Broadcast则都有n个consumer接收，但是二者的区别是Broadcast只能被1个consumer消费掉。之于Request-Reply则不限制consumer数量）。
    - q: MQ有哪些常见的坑？通常怎么解决?
      x: (顺序问题、背压（消息积压/队列阻塞）、主键冲突、数据库主从延迟、重复消费、丢消息) (duplicate msg, slow consumers)
    - q: Compare (AMPQ, MQTT, STOMP, XMPP, DDS, CoAP)?
      x: Transport(lw? perf? reliable?), use cases(low-bandwidth? IoT? real-time? advanced feats?)




- type: DFS
  md: true
  repo:
    - url: https://github.com/juicedata/juicefs
      des: |
        基于 redis 和 S3 实现的 DFS
        它主要解决了三个问题：
        - 完全兼容 POSIX、HDFS
        - 支持通过 fuse、csi 挂载到服务器或 k8s pod 中，也可使用 S3 client、WebDAV client、Hadoop client 访问
        - 托管文件元数据，解决元数据访问的性能问题

        JuiceFS 上储存的文件会被拆分成为一个个 4MB 的 Block 储存在对象储存中，这意味着不再能直接从 OSS 读取文件，必须依赖 JuiceFS server 的转换
    - url: https://github.com/happyfish100/fastdfs
    - url: https://github.com/ceph/ceph
  qs:
    - q: What's distributed filesystem? core requirements? (GFS, ceph, juice, HDFS)
      x: consistency guarantee, fault recovery mechanism, concurrency control





- type: gateway
  md: true
  repo:
    - url: https://github.com/caddyserver/caddy
      doc: https://authp.github.io/docs/intro
      des: Automatic SSL
      cmd:
        - c: caddy run --config Caddyfile
          x: 指定文件 caddy run
        - c: caddy start
          x: 把服务进程化
        - c: caddy stop
          x: 停止服务
        - c: caddy reload
          x: 修改配置之后，不需要重启，重载服务
        - c: caddy validate
          x: 测试配置文件是否正确
        - c: caddy reverse-proxy
          x: 快速且可适用生产的反向代理
        - c: caddy adapt
          x: 将配置文件转换成 json
        - c: caddy environ
          x: 打印环境变量
        - c: caddy file-server
          x: 启动可付诸生产的文件服务器
        - c: caddy file-server --root <~/mysite> --domain <localhost>
          x: 用 caddy 直接部署 web 服务，不需要 Caddyfile 或者 nginx.conf 那样的配置文件
        - c: caddy hash-password
          x: 用 base64 加密密码
        - c: caddy list-modules
          x: 列出已安装的模块
    - url: https://github.com/traefik/traefik
    - url: https://github.com/nginx/nginx
      qs:
        - q: 为啥 nginx 支持高并发?
          x: (memory-pool, event-driven, process model, thread model, network model)
        - q: How does nginx works?
          x: (master->conf, control worker(restart when exception)), (worker->handle request using reactor, accept_mutex)
        - q: How to optimize nginx config?
          d: https://blog.lv5.moe/p/nginx-ssl-tls-configuration-optimization#tls13-early-data0-rtt
          x: process, TCP, IO, OCSP stapling, Strict SNI,
        - q: multi-process(master-worker) + reactor(worker process), thread-pool, network model(epoll(ET))
        - q: dynamic modules
        - q: nginx security? (SELinux, iptables, delete useless nginx modules, async-about)

        #  - 如何解决容器中nginx worker process自动设置的问题?
        #     worker_processes, /sys/devices/system/cpu/online, lxcfs
    - url: https://github.com/cloudflare/pingora
      des: 与依靠lua或者openresty的主流gateway（比如nginx, nginx-ingress, apisix, kong等）不同，pingora直接写rust代码来构建module（相比之下，没有额外的学习成本）。
    - url: https://github.com/openresty/openresty
    - url: https://github.com/Kong/kong
      des: 基于 OpenResty 实现的，Nginx需要搭配OpenResty才更适合在微服务架构常用的灵活场景下使用，也就是把lua直接嵌入nginx，来动态拓展nginx的功能。而kong则可以看作是把OpenResty的功能插件化了，提供了60多种插件。
    - url: https://github.com/pantsel/konga
      des: kong的管理程序
    - url: https://github.com/linkerd/linkerd2
      des: service-mesh的请求多路转发、链路追踪. v1 is implemented based on scala, v2 is refactored with golang.
    - url: https://github.com/apache/apisix
    - url: https://github.com/apache/apisix-ingress-controller
    - url: https://github.com/easegress-io/easegress
      des: 相比于其他gateway更侧重业务网关，但是也支持LB、熔断降级、二层代理、Auth之类的。相比Ingress或者Istio更易用。
    - url: https://github.com/kubernetes/ingress-nginx
      des: gateway
    - url: https://github.com/istio/istio
      qs:
        - q: Mixer (Attribute, Adapter, Handler, Instance, Template)
        - q: Istio Arch?
          x: Data plane(由网格内的 Proxy 代理和应用组成), Control plane(用于控制和管理数据平面中的 sidecar 代理)
        - q: Sidecar 代理是如何实现自动注入的？
          x: 由k8s Admission Controller实现，当为应用部署的命名空间打上特定的标签，Istio 会自动在新建的 Pod 中注入 Sidecar 容器。
        - q: Pilot 服务是如何进行服务发现的？
          x: Pilot 服务通过监听 k8s API Server来缓存 Istio 服务模型，并在服务模型更新时触发相关事件回调处理函数的执行。
        - q: Pilot 配置规则 ConfigController 是如何工作的？
          x: ConfigController 用于管理各种配置数据，包括用户创建的流量管理规则和策略。它通过监听 Kubernetes API Server 中的配置规则资源，维护所有资源的缓存，并触发事件处理回调函数。
        - q: Pilot 的 Discovery Server 是如何执行 xDS 异步分发的？
          x: Discovery Server 接收来自 Envoy 端的 xDS 请求，从 Config Controller 和 Service Controller 中获取配置和服务信息，生成响应消息发送给 Envoy，并监听配置变化消息，将变化内容通过 xDS 接口推送到 Envoy。
        - q: Pilot-agent 的作用及其源码分析？
          x: Pilot-agent 负责启动 Envoy 代理，并提供健康检查、监视证书变化、Envoy 守护功能、通知 Envoy 优雅退出等功能。它通过生成 Envoy 的 Bootstrap 配置文件，监控证书变化，并在必要时重启 Envoy 来实现证书的热加载。
    - url: https://github.com/envoyproxy/envoy
    - url: https://github.com/hashicorp/consul
    - url: https://github.com/fabiolb/fabio
      des: Consul Load-Balancing made simple
    - url: https://github.com/hashicorp/consul-template
      des: Template rendering, notifier, and supervisor for Consul and Vault data.
    - url: https://github.com/haproxy/haproxy
      des: LB
    - url: https://github.com/cilium/cilium
      des: cilium 通过 eBPF 提供了高性能与高可观测的 k8s 集群网络， 另外 cilium 还提供了比 kube-proxy 更高效的实现，可以完全替代 kube-proxy
    - url: https://github.com/cilium/cilium-cli
    - url: https://github.com/kubernetes-sigs/gateway-api
      des: Gateway API 是南北向负载均衡和流量路由到 Kubernetes 集群的新标准，也是下一代 Ingress 的规范。可以说 Gateway API 代表了 Kubernetes 集群中流量管理的未来。用来解决之前Ingress API的各种问题。
  qs:
    - q: "***Compare (istio, cilium, kuma, consul, envoy, Traefik, Nginx, Caddy, Kong, Linkerd.)***"
    - q: 服务网关里的流量网关和业务网关分别是啥?
      x: |
        gateway = 路由转发+过滤器  这块的“路由转发”就是“流量网关”，“过滤器”就是“业务gateway”。可以理解为整个整个集群的前置中间件，把权限校验、限流、监控、API 日志收集等功能写到过滤器里。流量网关通常只专注于全局的 Api 管理策略，比如全局流量监控、日志记录、全局限流、黑白名单控制、接入请求到业务系统的负载均衡等，有点类似防火墙。Kong 就是典型的流量网关。业务网关就是权限控制、日志输出、数据加密、熔断限流等每个微服务应用都需要的通用服务。
    - q: 比较istio和linkerd的CPU benchmark，怎么设计具体测试流程？
      d: https://mp.weixin.qq.com/s/bry4g11lacH1eyuh5uVcHw

    - q: sidecar (sidecarless(cilium), ambient(istio))
    - q: Why does ms need gateway?
    - q: reactor(multi-thread)

    - q: What's service mesh? keypoint of service mesh? How to implement?



    # LVS
    - q: What about LB? What are the methods to implement LB for each layer of network layers? Why is the current mainstream LB solution is transport layer + application layer? # (forward to real qs through virtual qs) (MAC/IP(VIP)/)
    - q: What are the LB algo? # (static & dynamic) (RR, WRR, url-hash, ip-hash)
    - q: What's haproxy? Compare with nginx? (just like iptables and ipvs) What LB algo does haproxy have?
    - q: What's LVS? (DR, NAT, tunnel, fullnat) *How does LVS works?* # netfilter, just like iptables
    - q: Compare LVS, nginx, MetalLB and kube-proxy?




- type: Service-Registry
  md: true
  repo:
    - url: https://github.com/apache/zookeeper
      des: 虽然一些新的分布式协调系统如 etcd 和 consul 的性能和功能更好，但是 zk 作为 java 生态中的一环，使用还是非常广泛的，但是在比较新的项目里，很少使用 zk，如果还不了解的话，简单了解一下基础概念和使用就可以了，不需要深入了解使用
      qs:
        - q: 聊聊zk的zab协议、node存储模型、watcher机制
        - q: zk 如何保证 ap？etcd 如何保证 cp？如果想要在 zk 上实现 cp 应该如何处理？
        - q: zk的顺序一致性是啥?
          d: https://lotabout.me/2019/QQA-What-is-Sequential-Consistency/
    - url: https://github.com/etcd-io/etcd
      des: etcd = Eternal Consistency Distributed
      qs:
        - q: "***etcd arch?***"
          x: etcd server(WAL(Entry + snapshot)) + raft + storage(treeIndex + boltdb)
        - q: etcd feats?
          x: ectd 支持动态扩容缩容, MVCC, 可靠的事件监控，并且基于 MVCC 实现指定版本重放 (zk 的 watcher 没有 MVCC), 租约机制将 connection 和 session 分离
        - q: etcd API (Put()/Delete(), Get(), Watch(), Transactions(), Leases(Grant/Revoke/KeepAlive))
        - q: etcd 如何实现的 watch. How to watch keys?  mvcc & streaming watch (bptree, mmap)
          d: https://mp.weixin.qq.com/s?__biz=MzAxMTA4Njc0OQ==&mid=2651451271&idx=3&sn=43bcb53845660775f73f03fa359865a6
        - q: mini-transactions机制
        - q: etcd 如何实现配置下发和服务发现？etcd 怎么选主？
        - q: (lease)
        - q: "***How to optimize etcd?***"
          d: https://mp.weixin.qq.com/s?__biz=MzAxMTA4Njc0OQ==&mid=2651441737&idx=2&sn=84d797acc722fdc23c67678aa2d875be
          x: |
            拆解一下很简单，就是实现和使用两方面（也就是服务端和客户端），使用方面没啥意思（比如不要创建大量lease以及不要频繁修改kv）。实现方面无非是raft和botldb，raft没有什么优化点，所以就集中在boltdb上（具体如下）。
            raft 层：raft 是 etcd 节点之间同步数据的基本机制，它的性能受限于网络 IO、节点之间的 rtt 等，WAL 受到磁盘 IO 写入延迟
            存储层：负责持久化存储底层 kv, 它的性能受限于磁盘 IO，例如：fdatasync 延迟、内存 treeIndex 索引层锁的 block、boltdb Tx 锁的 block 以及 boltdb 本身的性能

        - q: Proxy 模式 (etcd 作为一个反向代理把客户的请求转发给可用的 etcd 集群)
        - q: Linearizable Read，snapshot 机制，WAL 的存储与回放
    - url: https://github.com/alibaba/nacos
  qs:
    - q: Compare (etcd, consul, rpcx, zk, nacos, eureka, vault) 这些组件都能实现服务发现、pubsub(消息发布与订阅)、负载均衡、分布式通知与协调、分布式锁、分布式队列、集群监控与 Leader 竞选，所以也应该从这些aspects进行比较



# [分布式事务XA、AT、TCC、SAGA - benym](https://benym.cn/archives/325/)
- type: DT(Transaction)
  md: true
  repo:
    - url: https://github.com/dtm-labs/dtm
      des: DTM 提供了多种分布式事务解决方案. 支持 saga, tcc, xa, 2-phase message.
    - url: https://github.com/apache/incubator-seata
      des: seata
  qs:
    - q: "***Compare XA (2PC, 3PC), AT, TCC, SAGA  (一致性、隔离性、代码侵入性、性能、使用场景)***"
      x: |
        总结一下，XA和AT都是non-invasive的（而TCC和SAGA都是invasive的，通常不考虑）。AT和XA则正好互补，XA强一致性但是性能一般，AT则性能更好但是弱一致性。

         - TCC (Try-Confirm/Cancel): 最终一致的分阶段事务模式，有业务侵入，适用于一致性要求较高的短事务
         - SAGA: 长事务模式，有业务侵入，一致性要求较低的长事务
         - XA (eXtended Arch): 强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入，适用于并发要求不高的场景
         - 事务消息：不需要回滚的事务
         - AT (Application-Level Transaction): 最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式

    - q: XA的2PC和3PC有啥区别?
      x: |
        狭义上的XA实际上就是2PC（因为3PC很难实现），3PC相比2PC就是多了一个PreCommit和“超时回滚机制”。但是还是上面说的，3PC很难实现，所以如果我们使用2PC，就需要面对其缺点，也就是单点故障、阻塞问题、数据不一致问题。拿朋友AA制聚餐举例，餐厅服务员就是协调者，而朋友就是参与者，那么两个阶段就是“投票”和“决定是否完成”，那么3PC就是多了一个服务员向每个参与者询问支付状态（也就是PreCommit），然后决定继续收钱还是取消支付。所以我妈说“3PC是对有人逃单的兜底”

    - q: 分布式事务中的异常处理有哪些关键点？
      x: |
        分布式事务中的异常处理需要关注空回滚、幂等和悬挂等问题。空回滚是指在没有执行Try操作的情况下执行Cancel操作。幂等是指分布式事务的每个分支都需要保证即使出现重复请求，也能正确处理。悬挂是指Cancel操作在Try操作之前执行的情况。为了处理这些异常，业务方需要通过唯一键查询操作是否已完成，或者实现相应的幂等控制和防悬挂逻辑。



- type: prometheus
  md: true
  repo:
    - url: https://github.com/prometheus/prometheus
      doc: https://prometheus.io/docs/prometheus # https://prometheus.io/docs/instrumenting/exporters/
      qs:
        - q: "***prom arch? How to implement?***"
          x: |
            (storage, ) storage (local(tsdb, block+WAL), remote(adapter))
            采集层(exporter 的 pull 机制, 通过 Push Gateway 的 push 机制), 数据处理层(Retrieval 负责定时去暴露监控指标的目标上抓取数据，Storage 负责将数据写入磁盘，promQL 暴露查询数据的 http server 能力), 数据查询层
        - q: metrics? # gauge > counter > histogram > summary(类似histogram, 唯一的区别是histogram 是服务端计算的，而 summary 是客户端计算的，一个是计算好了再推上去，一个是直接推上去再计算)
        - q: "***How to optimize prom?***" # Remote-Write
        - q: "***基于prom监控系统技术栈的选型? Why?***"
          x: PAG(Prom+Alertmanager+Grafana)+CN(cAdvisor+Node Exporter)
        - q: common used exporters? # node, jmx, cadvisor, blackbox
        - q: 除了系统、性能指标外，业务指标怎么统计？
        - q: PromQL
        - q: 配置告警规则 alert.rules
        - q: 使用 Alertmanager 发送告警通知
        - q: 怎么用prom监控阿里云RDS
        - q: 想实现prom cluster，有哪些方案？ #
        - q: 怎么监控 prom 服务本身？ # 当然是两个prom服务互相做交叉监控。另外，定义一条永远会触发的`兜底告警`，单独分组，不断通知，如果某天这条通知停了，就说明报警链路出问题了。 use alertmanager HA mode with multiple instances to cross-monitor
        - q: 尽早干掉维度(Cardinality)过高的指标
        - q: Rate 类函数 + Recording Rule 的坑
        - q: Alertmanager 的 group_interval 会影响 resolved 通知
        - q: 如果我们的业务是每个微服务分别使用各自的redis实例，那这种情况下prometheus怎么监控呢？聚合监控还是？具体怎么搞？这种设计不会导致大量数据冗余吗？并且数据一致性也可能存在很大问题。正常来说不是多个微服务 共享redis吗？
    - url: https://github.com/thanos-io/thanos
      des: 用来拓展prom功能，如全局查询、用OSS作为数据的长期存储方案、基于replication的HA、Downsampling（自动减少历史数据的粒度，以优化存储空间和加速长期数据的查询。）、“压缩和去重”以及多租户。针对以上功能，sidecar, querier, store, compactor, ruler
    - url: https://github.com/prymitive/karma
      des: prom karma, Alert dashboard for Prometheus Alertmanager
    - url: https://github.com/prometheus/node_exporter
    - url: https://github.com/prometheus/jmx_exporter
    - url: https://github.com/prometheus/blackbox_exporter
    - url: https://github.com/prometheus/alertmanager
      qs:
        - q: alertmanager 告警收敛 (group, Inhibition, Silences)
    - url: https://github.com/google/cadvisor
      des: 对于容器化环境中的资源管理和性能监控非常有用，用于收集、聚合、处理和导出运行中容器的资源使用情况和性能特征信息。cAdvisor 是一个daemon，它可以帮助你理解你的容器在运行时对资源的需求和使用情况。cadvisor 使用 linux 的 cgroup 获取容器的性能指标，在 k8s 中集成在 kubelet 中作为默认启动项，官方标配(如果使用 k8s 的话，不需要再引入该服务)
    - url: https://github.com/prometheus/mysqld_exporter
    - url: https://github.com/prometheus/snmp_exporter
    - url: https://github.com/oliver006/redis_exporter
      des: Prometheus Exporter for Redis Metrics. Supports Redis 2.x, 3.x, 4.x, 5.x, 6.x, and 7.x
      qs:
        - q: 怎么用prom监控和analyze redis的big-keys, hot-keys?
        - q: redis metrics
    - url: https://github.com/mvisonneau/gitlab-ci-pipelines-exporter
      des: gitlab-ci-pipelines-exporter 确实不错

    - url: https://github.com/feiyu563/PrometheusAlert
      des: 运维告警中心消息转发系统，支持prom, zabbix, Graylog, Grafana, 钉钉,微信,华为云短信,腾讯云短信,腾讯云电话,阿里云短信,阿里云电话等
    - url: https://github.com/yunlzheng/prometheus-book
      des: prom用法，教程
    - url: https://github.com/Qihoo360/doraemon
      des: 用来管理 prometheus 报警信息的工具，相当于alertmanager，但是已经EOL了
    - url: https://github.com/samber/awesome-prometheus-alerts
      des: alert rules集合，需要使用时可以直接在里面查找
    - url: https://github.com/prometheus/common
    - url: https://github.com/prometheus-community/postgres_exporter
    - url: https://github.com/techiescamp/kubernetes-prometheus
    - url: https://github.com/grafana/mimir
      des: grafana提供的prom HA工具（实际上也是个tsdb）
    - url: https://github.com/zabbix/zabbix
    - url: https://github.com/line/promgen
      des: prom的配置文件生成器，可以帮助用户自动生成 Prometheus 所需的配置文件，简化了手动编辑配置文件的过程。并且可以通过 Promgen 设置警报规则以及定义在触发警报时的通知方式。
    - url: https://github.com/prometheus-community/helm-charts
      des: helm for PAG stack.
    - url: https://github.com/statsd/statsd
    - url: https://github.com/prometheus/statsd_exporter
  qs:
    - q: Compare (prometheus, zabbix, DataDog) (pull, push)
      x: push 适合需要real-time的场景，但是相应的就是需要维护大量agent。pull模式则相反，通常内置了服务发现，不需要维护agent，所以更适合伸缩性强（也就是不稳定）的场景。但是相应的会有一定的timeout。所以并不能说pull比push更强，只是使用场景不同。





- type: Elasticsearch
  md: true
  repo:
    - url: https://github.com/elastic/elasticsearch
      qs:
        - q: 聚合函数aggs (metrics(avg/max/min/sum/stats), bucket(terms, histogram, range, geo_distance, 类似sql的groupby))
        - q: 怎么用EFK收集k8s日志?
        - q: 为啥应该用ES?
        - q: ES基本概念?
          x: fields, documents, mapping, mapping types, index, shards, replicas, analyzers, instances and nodes, cluster
        - q: "***How to optimize ES? (write, read, common)***"
          u: https://mp.weixin.qq.com/s?__biz=MzA4MTc4NTUxNQ==&mid=2650525213&idx=1&sn=86b60576fcbea1801094017eedb989a7
          x: |
            写操作优化 (translog flush 异步化(目的是降低 iops,writeblock), 增加 index refresh 间隔(除了降低 I/O，更重要的是降低 segment merge 频率), merge)

            读操作优化 (指定路由, rollover 冷热分离, 使用 BoolQuery 替代 TermQuery, 将大查询拆成分段查询)

            通用优化 (线程池优化, 物理冷热分离, 多磁盘分散 IO, 减少单条记录的大小)
        - q: "*How does ES works? How do each node work during ES search?*"
        - q: CHANGELOG
        - q: ES常用plugins?
        - q: What are the common problems when using ES? (common MQ problems)
        - q: How to sync data from mysql, mongo to es?
        - q: How does each node work during ES search? # (Node collaboration, search request, data node performs search, results are merged, and returned to the client)
        - q: ELK process? Why need MQ, instead of directly storing data from logstash into ES?
        - q: 怎么整合es和pgsql，也就是把es作为pgsql的SE，怎么实现？怎么保证数据一致性？
          x: 用es的listener实现数据同步

    - url: https://github.com/elastic/go-elasticsearch
      des: olivere/elastic 废弃之后，使用这个官方pkg
      qs:
        - q: 存储新数据时，应该在已有的 Index 上新建一个 type，还是新建一个 Index？
        - q: 怎么把 gin 日志插入到 ES？
        - q: 组合查询？范围查询？多条件排序？
        - q: 怎么使用 bulk？
        - q: 怎么精确查询？term 和 terms 怎么用？
        - q: 高亮搜索？mapping 设置 IK 插件？
        - q: 怎么把 mysql 数据导入 ES？
        - q: ES 有哪些聚合函数？怎么使用？
        - q: 结合 GraphQL 使用？
    - url: https://github.com/elastic/apm-agent-go
      des: Go agent for Elastic APM
    - url: https://github.com/blugelabs/bluge
      doc: https://youerning.top/post/gobluge/
      des: 就是优化后的bleve，类似ES，但是适用于轻量应用。可以直接作为 lib 使用的类似 es 的全文搜索引擎
    - url: https://github.com/meilisearch/meilisearch
    - url: https://github.com/typesense/typesense
    - url: https://github.com/medcl/elasticsearch-analysis-ik
      des: |
        ik分词. Tokenizer and Analyzer plugin for ES.

        - 安装 ik 插件，注意 ik 版本一定要和 es 版本对应.
        - 想要使用 ik 插件，需要创建 mapping 时设置。mapping 类似于在数据库中定义表结构，表里有什么字段，以及字段是什么类型。最好手动创建mapping，不要动态映射 (可能会映射错误)
    - url: https://github.com/elastic/curator
      des: ??? 用来帮ES管理索引的插件，比如删除旧的索引、优化索引、快照和还原等。它还支持定义和执行数据保留策略，以自动删除或归档过时的数据。Curator 的目标是帮助用户轻松管理 Elasticsearch 集群中的索引，保持集群的性能和存储效率。
    - url: https://github.com/zincsearch/zincsearch
      des: A lightweight alternative to elasticsearch that requires minimal resources, written in Go.
    - url: https://github.com/sea-team/gofound
      des: 全文检索引擎, Similar with ES, 但是仅供学习和参考代码
    - url: https://github.com/johnlui/DIYSearchEngine
      des: FRO 可以看看
    - url: https://github.com/uken/fluent-plugin-elasticsearch
    - url: https://github.com/CocaineCong/tangseng
      des: gin+grpc+etcd实现的搜索引擎


- type: EFK/ELK
  repo:
    - url: https://github.com/blacktop/docker-elastic-stack
      des: ELK打包的Dockerfile，之前用过，用来安装ELK服务
    - url: https://github.com/deviantony/docker-elk
      des: 比较好用的 ELK 的 dc，自带 apm-server/curator/enterprise-search/filebeat/logspout/metricbeat



- type: Log-Collector
  repo:
    - url: https://github.com/elastic/beats
      des: Beats contains Filebeat, Packetbeat, Metricbeat, Auditbeat, Heartbeat.
    - url: https://github.com/fluent/fluentd
      des: Filebeat 和 Fluentd 都是用于收集日志的工具，但 Filebeat 更轻量级，专注于收集本地文件的日志数据并转发给 Elasticsearch 或 Logstash。Fluentd 则提供了更丰富的数据收集和处理功能，支持复杂的日志路由和插件系统，适合构建复杂的日志处理管道。
    - url: https://github.com/elastic/logstash
      des: logstash相比其他日志收集工具在性能和内存占用都太差了。使用 grok(ruby) 实现日志过滤。
    - url: https://github.com/grafana/loki
      des: 日志收集工具 loki天然支持grafana，就不需要在grafana和kibana之间纠结了。可以直接替代EFK（作为更lightweight的日志系统，如果不需要ES那么复杂的搜索功能的话），也可以替代filebeat。
      qs:
        - q: When to use?
        - q: How to use? loki.yml
        - q: agent, promtail (daemonset), How to config? (server, client, position, scrape)
        - q: scrape策略 (其实就是用来过滤日志的，loki用regex过滤，通常配置3个job，journal, system, biz001)
        - q: loki和ES的FTS有啥区别？ (Inverted index, 和类似prom基于tag的index，成本更低)
        - q: 写操作 Distributor和Ingester两个组件
        - q: 扩展性 用cassandra/bigtable/dynamodb作为索引存储，其他components都是无状态的
        - q: 如何用Loki来分析Kubernetes事件？
    - url: https://github.com/kevwan/go-stash
    - url: https://github.com/elastic/kibana
    - url: https://github.com/grafana/grafana
    - url: https://github.com/loggie-io/loggie
      des: A lightweight, cloud-native data transfer agent and aggregator
  qs:
    - q: "***Compare (filebeat, fluent, loki, logstash, go-stash).***"




- type: helm
  repo:
    - url: https://github.com/helm/helm
      doc: https://helm.sh/docs/
      cmd:
        - c: helm completion
        - c: helm create
        - c: helm dependency
        - c: helm env
        - c: helm install <bitnami/mysql>
          x: 安装指定服务
        - c: helm uninstall
        - c: helm lint
        - c: helm ls
          x: helm list 的 alias
        - c: helm package
          x: 把Chart目录打包为Chart归档文件
        - c: helm pull
        - c: helm push
        - c: helm registry
        - c: helm show [chart|crds|readme|values|all] <bitnami/mysql>
          x: 获取Chart相关信息
        - c: helm get [hooks|manifest|notes|values|all]
          x: 获取Release相关信息
        - c: helm status
          x: 用来追踪release状态 helm status happy-panda
        - c: helm template
        - c: helm upgrade
        - c: helm verify
        - c: helm search
          x: helm search repo bitnami
        - c: helm repo list
        - c: helm repo add <name> <url>
          x: 添加chart仓库
        - c: helm repo update
          x: 确保我们拿到最新的charts列表
        - c: helm history
          x: 查看某个Release的版本记录
        - c: helm rollback
          x: 把某个Release回滚到某个版本
        - c: helm plugin [install|uninstall|update] <pkg>
          x: helm plugin update dashboard
        - c: helm plugin list
        - c: helm completion [bash|fish|powershell|zsh]
          x: 为指定的shell生成自动补全脚本
        - c: helm registry [login|logout]
          x: 登录或登出注册表
        - c: helm diff upgrade my-release stable/postgresql --values values.yaml
          x: databus23/helm-diff, used to show a diff explaining what a helm upgrade would change
      qs:
        - q: Repository, Chart, Release # 从repo下载chart，然后把chart部署为release（到k8s集群中）
    - url: https://github.com/helmfile/helmfile
      des: helm 是 k8s 的包管理工具，而 helmfile 用来部署多个 chart，不同部署环境的区分以及 chart 的版本控制
      cmd:
        - c: helmfile apply
        - c: helmfile build
        - c: helmfile list
    - url: https://github.com/komodorio/helm-dashboard
      des: A Better UI for Helm
    - url: https://github.com/helm/chart-releaser
      des: Hosting Helm Charts via GitHub Pages and Releases







- type: grpc
  repo:
    - url: https://github.com/grpc/grpc
      des: grpc 使用了基于PB的serialization protocol. 基于HTTP/2 标准协议开发，自带 stream、多路复用等特性.
      qs:
        - q: gRPC 支持哪些类型的调用interceptor？ (unary, stream(server, client, bidi))
        - q: gRPC 如何处理元数据传输？ # gRPC 支持元数据传输，类似于 HTTP 中的 header。客户端可以写入元数据，服务端可以通过 metadata.FromIncomingContext 接收元数据
        - q: gRPC 如何实现负载均衡？ # gRPC 支持客户端负载均衡和服务端负载均衡。客户端负载均衡在 rpc 调用中应用广泛，而服务端负载均衡在云原生环境下更推荐使用，可选方案包括 envoy 和 istio
    - url: https://github.com/nyan233/littlerpc
      des: How to implement a RPC?
    - url: https://github.com/protocolbuffers/protobuf
      des: |
        pb的编解码速度和内存占用都优于JSON，但是不能明文使用（对开发者的友好程度）。***PB使用Varint和Zigzag来对各种数据进行压缩。并且把压缩后的数据用TLV结构来存储。***

        具体来说，Protocol Buffer 序列化采用 Varint、Zigzag 方法，压缩 int 型整数和带符号的整数。对浮点型数字不做压缩(这里可以进一步的压缩，Protocol Buffer 还有提升空间)。编码 .proto 文件，会对 option 和 repeated 字段进行检查，若 optional 或 repeated 字段没有被设置字段值，那么该字段在序列化时的数据中是完全不存在的，即不进行序列化（少编码一个字段）。

        上面这两点做到了压缩数据，序列化工作量减少。
        序列化的过程都是二进制的位移，速度非常快。数据都以 tag - length - value (或者 tag -
        value)的形式存在二进制数据流中。采用了 TLV 结构存储数据以后，也摆脱了 JSON 中的 {、}、;
        、这些分隔符，没有这些分隔符也算是再一次减少了一部分数据。这一点做到了序列化速度非常快。
    - url: https://github.com/tinylib/msgp
      des: |
        msgp = msgpack for go, 可以理解为某种protobuf，也是二进制格式。
        msgp是MessagePack在Go语言的实现，它允许开发者在Go程序中使用MessagePack格式进行数据序列化和反序列化。
        虽然protobuf和msgp都用于数据序列化，但它们在序列化格式、使用场景、以及生成代码的方式上有所不同。选择哪一种取决于具体的项目需求，比如对性能的要求、是否需要跨语言支持、以及是否需要预定义数据结构等因素。
    - url: https://github.com/bufbuild/buf
      des: buf旨在改变当前以 REST/JSON 为中心的 API 开发范式，通过基于模式的范例定义 API 来提供比 REST/JSON 更多优势。buf提供了linter/formatter, breaking change checker, generator来辅助pb的使用。
    - url: https://github.com/grpc/grpc-go
    - url: https://github.com/fullstorydev/grpcurl
      cmd:
        - c: grpcurl -d
    - url: https://github.com/grpc-ecosystem/grpc-gateway
      des: grpc-gateway是用来搭配grpc使用的，grpc-gateway读取gRPC接口定义,自动生成反向代理,用于将HTTP请求转换为gRPC调用,将响应从gRPC转换为HTTP响应。这样开发人员就可以使用现有gRPC服务,通过HTTP/JSON的方式进行访问。总结来说，就是基于gRPC接口定义为其提供JSON化解决方案。




# [不确定K8S YAML文件是否符合最佳实践？这6个工具可以帮你！_软件工程_Rancher_InfoQ精选文章](https://www.infoq.cn/article/dzc6evcihvvzfmuxf62n)
- type: k8s-linter
  repo:
    - url: https://github.com/stackrox/kube-linter
    - url: https://github.com/yannh/kubeconform
    - url: https://github.com/zegl/kube-score
    - url: https://github.com/instrumenta/kubeval
      des: 也是某种linter，用来验证k8s配置是否符合k8s版本
    - url: https://github.com/cloud66-oss/copper
    - url: https://github.com/yonahd/kor
    - url: https://github.com/FairwindsOps/polaris
    - url: https://github.com/open-policy-agent/conftest



- type: Circuit-Breaker
  md: true
  repo:
    - url: https://github.com/Netflix/Hystrix
      qs:
        - q: hystrix (ticket) (bulkhead, swimlane)
        - q: hystrix 的设计理念？
        - q: hystrix 的线程池隔离和信号量隔离，有哪些区别？
        - q: hystrix 核心结构 # 统计控制器 MetricCollector, 流量控制器 poolMetrics
        - q: hystrix 的流量控制流程 # 通过 ticket 来控制
    - url: https://github.com/resilience4j/resilience4j
    - url: https://github.com/alibaba/Sentinel
      des: sentinel 是以流量为切入点，从限流、流量整形、熔断降级、系统负载保护、热点防护等多个维度来保证微服务的稳定性
    - url: https://github.com/eapache/go-resiliency
    - url: https://github.com/sony/gobreaker
      des: circuit breaker in golang
  qs:
    - q: What role do it play? # healthcheck
    - q: 为什么需要断路器？有哪些熔断器？
    - q: Compare hystrix, resilience4j, sentinel. 从隔离策略、熔断降级策略、实时指标实现、可拓展性、限流、流量整形、系统负载保护、控制台等方面







- type: minio
  repo:
    - url: https://github.com/minio/minio
    - url: https://github.com/minio/minio-go


- type: Perf-Testing
  repo:
    - url: https://github.com/rakyll/hey
      des: a better wrk. 比如 wrk 发送 post 请求要写 lua 脚本，hey 就不需要
    - url: https://github.com/myzhan/boomer
      des: locust 支持多机压测（也就是多 worker）时，作为worker使用。locust 的 worker 节点使用 python 实现，因为 GIL 的问题，无法使用处理器的多核特性，榨出真实性能。所以我们需要用 boomer 去实现 worker 节点。
    - url: https://github.com/locustio/locust
      des: locust + boomer 搭配使用. locust 支持多机压测（也就是多 worker），master 节点负责数据的收集和消息的广播等操作，而 worker 节点负责执行压测任务。
    - url: https://github.com/apache/jmeter
      qs:
        - q: Why should not we use JMeter?
        - q: jmeter 怎么调节压力？ # ”阶梯加压“和”持续负载“, CSV 可变参数压测

        - q: jmeter 有哪些组成部分？
          x: 测试计划、线程组(线程数, 准备时长, 循环次数)、配置原件、监听器(TPS 监听器, HPS 监听器, RT 监听器)
        - q: 使用 jmeter 的步骤？ # 新建线程组, 选择 sampler, 设置代理服务器, 添加结果树聚合报告, 调试脚本, 场景设计和运行, 结果分析
        - q: 负载测试如何保证业务连贯性
        - q: 怎么管理jmeter的jmx
      des: |
        stress-test工具最好还是类似JMeter这样带GUI的，在易用性和可视化方面具有明显的优势
    - url: https://github.com/six-ddc/plow
      des: 带UI的HTTP压测工具，还不错。基于fasthttp实现。也支持用body flag直接加载request文件，而不是写在命令行，以供复用。
    - url: https://github.com/wg/wrk
      des: wrk
    - url: https://github.com/tag1consulting/goose
    - url: https://github.com/JoeDog/siege
    - url: https://github.com/tsenart/vegeta
      des: vegeta也支持“基于场景的压测”，但是。内置了丰富的report，可以生成纯文本/json/histogram/hdrplot/plot图表。vegeta可以通过pdsh来实现分布式压测功能。注意，手动将rate设置成0，否则默认用50的qps进行压测。
    - url: https://github.com/baidu/dperf
      des: Based on DPDK, dperf can generate huge traffic with a single server.
  qs:
    - q: What are the Perf Testing Metrics?
    - q: How to estimate the RPS of a service?
    - q: "***Can you give me some conclusions on horizontally comparing various metrics, such as prom, linux and applications like redis, nginx, etc?***"
    - q: Compare Test Reporting Tools, Which is better? (AllureReport)
    - q: Perf Testing, Load Testing, Stress Testing
    - q: "*Sign of perf bottleneck?* (memory, io, cpu, network)"


- type: UI-Test/E2E
  repo:
    - url: https://github.com/appium/appium
    - url: https://github.com/AirtestProject/Airtest







---

# wishlist

- type: Slides-as-Code
  des: SaC
  repo:
    - url: https://github.com/pomber/code-surfer
      des: MDX-to-slides, 之前玩过几乎所有的md-to-slides方案（比如mdx-deck, marp, nodeppt, hacker-slides），但是都有各自的问题，比如说nodeppt就存在渲染有问题，分割线用<slide>标签，语法有点严格，无法导出 PPT 格式。
    - url: https://github.com/slidevjs/slidev
      des: 演讲者录制、演讲者模型、绘图批注等。slidev和marp差不多，生态也都不错，但是我更喜欢slidev
  qs:
    - q: PPT 工具的核心需求 # 远程演示、翻页笔、源文件可保存、写 PPT 方便



# [Diagram as Code - Ranking | OSS Insight](https://ossinsight.io/collections/diagram-as-code/)
- type: Diagram-as-Code
  des: DaC
  repo:
    - url: https://github.com/excalidraw/excalidraw
    - url: https://github.com/terrastruct/d2
      des: 语法和 theme 更现代，已经支持很多插件，等官方支持 docusaurus 插件，就用这个替换掉 PlantUML
    - url: https://github.com/markmap/markmap
    - url: https://github.com/yuzutech/kroki
      des: 给docusaurus配置PlantUML时找到的，非常好用。事实上，kroki支持几乎所有的思维导图工具。Kroki provides a unified API for all the diagram libs, such as PlantUML/Mermaid/D2/GraphViz...etc. IMO, it's a External services, or just like a middleware, no matter what language uses, no matter what diagram you need, you don't need to install any libs in your projects, just call Kroki API, finally you'll get respective diagram images URL.



- type: GUI
  repo:
    - url: https://github.com/wailsapp/wails
    - url: https://github.com/fyne-io/fyne

    - url: https://github.com/chromiumembedded/cef
      des: Qt, GTK, CEF, MAUI(c#), flutter-desktop, TAURI, electron
    - url: https://github.com/tauri-apps/tauri
    - url: https://github.com/webui-dev/zig-webui
      des: 基于browser实现GUI，不是独立APP，而是嵌入在browser内的。既然如此，肯定会有疑问“如果嵌入browser的话，直接做成web不就行了吗？为啥还要用GUI组件？明明各种web端的UI库比GUI多太多了”，实际上，可以把zig-webui理解为“如果electron能复用browser就太好了”的一种实现，相当于复用browser作为client


- type: Homebrew
  repo:
    - url: https://github.com/Homebrew/brew
      key: true
      des: Homebrew/brew用来实现brew命令行，Homebrew/homebrew-core用来管理各种formulae
      cmd:
        - c: git -C "$(brew --repo)" remote get-url origin
          x: 查看homebrew的源
        - c: brew --prefix
          x: 用来查看bin path和cask path
        - c: brew config/cleanup/outdated/doctor/commands
          x: 一些brew全局命令
        - c: brew update -vvv
          x: 更新homebrew
        - c: brew install/uninstall
        - c: brew upgrade
          x: 用来升级brew的formula（不支持cask）
        - c: brew list --<cask|formula>
          x: brew remove
        - c: brew services list/run/start/stop/restart/cleanup
        - c: brew tap
          x: 查看所有已经tapped的repo
        - c: brew tap/untap <user/repo>
          x: 添加/移除 新tap
        - c: brew tap --repair
        - c: brew info <service>
          x: brew info --github <service>
        - c: brew pin/unpin <service@version>
          x: 锁定/解锁 不想更新的包
        - c: brew link/unlink <service>
        - c: brew deps/uses <pkg> --tree --installed
          x: 查看 pkg 的上游包（依赖包）/ 下游包（被依赖包）
        - c: brew leaves
          x: 列出不被任何包依赖的包
        - c: brew update-reset
          x: To undo all changes you have made to any of Homebrew’s repositories, It will revert to the upstream state on all Homebrew’s repositories.
        - c: brew autoremove
          x: Uninstall formulae that were only installed as a dependency of another formula and are now no longer needed
        - c: brew bundle dump --describe --force --file='./Brewfile'
          x: backup brew formulae and cask
        - c: brew bundle
          x: 根据Brewfile恢复homebrew中的软件
        - c: brew bundle install --file='./Brewfile'
        - c: brew cu -facy
          k: true
        - c: brew graph --installed | fdp -Tpng -ograph.png
      qs:
        - q: 怎么备份、导出和导入brew的formulae和cask?
          u: https://github.com/Homebrew/homebrew-bundle
        - q: brew upgrade只能升级formulae，不支持cask。那怎么才能upgrade cask呢?
          u: https://github.com/buo/homebrew-cask-upgrade
        - q: brew graph提供的依赖关系不是可视化的，怎么可视化查看homebrew的formulae之间的依赖关系?
          u: https://github.com/martido/homebrew-graph
          x: 通过Graphviz直接可视化查看graph，非常直观



---


# rust


- type: rust
  repo:
    - url: https://github.com/rust-lang/rust
      qs:
        - q: trait
        - q: macro
        - q: error handle, unwrap or expect?
        - q: Tokio
        - q: rocket
    - url: https://github.com/jdx/mise
      des: Used to parse cli in rust. Similar with alecthomas/kong in golang.
    - url: https://github.com/tokio-rs/tokio
      des: = nettty, gnet, twisted.
    - url: https://github.com/loco-rs/loco
      des: 类似ruby的RoR、PHP的laravel、python的Django，内置了一些功能模块和generator（比如CURD）
    - url: https://github.com/rust-lang/rust-clippy
      des: 相当于 rust 的 linter




- type: Big-Data
  des: and sci
  repo:
    - url: https://github.com/numpy/numpy
      qs:
        - q: np.array()
        - q: ndim 查看数据维度
        - q: "*numpy 有哪些常用方法？*"  # 基本运算 sum、mean（median、average、mode）、shape 和 reshape、排序 sort、标准差 arr.std(ddof=1)
        - q: 向量是啥？numpy 怎么定义向量（ndarray）？行向量和列向量？ *向量可以理解为一维矩阵，矩阵可以理解为多维向量*。因为定义行向量很麻烦，所以通常定义列向量，直接模（值相等），或者转成行向量。
        - q: 矩阵是什么？numpy 怎么定义矩阵？矩阵有啥用？用 matrix 或者 array 定义即可，矩阵可以用来横向对比二维数据（一个常用场景，就是结合多维度，计算某个人的劳动回报；对比不同营销策略的效果）
        - q: 向量的内积和外积？
        - q: 逆矩阵是什么？逆矩阵有啥用？矩阵只有乘法，没有除法，所以需要用逆矩阵来实现除法。*逆矩阵可以用来实现文本加密和解密（想想怎么搞？）*。
        - q: 练习：怎么用矩阵对图片颜色进行反转？把图片进行按比例截取？把图片对角线截取？把图片变成圆角图片？怎么上下翻转、左右翻转图片？
    - url: https://github.com/scipy/scipy
      qs:
        - q: 为啥要用 scipy，而不用 numpy 计算距离？
        - q: 怎么对数据进行多维数据排序（比如根据商品的销量、点击量、评论数和收藏数）？很简单，构造一个最强物品的数据，然后`distance.euclidean(v1, v2)`（欧氏距离）计算每个商品和这个商品之间的距离。
        - q: 余弦距离`distance.cdist(p1, p2, metrics="consine")`
        - q: 编辑距离是啥？怎么计算？至少需要多少次处理才能把一个字符串变成另一个字符串，用`jellyfish拓展包`或者`python-Levenshtein`计算即可。
        - q: 曼哈顿距离是啥？*用来处理不能直接用`欧氏距离`计算两点之间距离的场景*
        - q: 杰卡德距离是啥（Jaccard）？用来比较有限样本集之间的相似性和差异性。jaccard 系数越大，样本相似值就越高。使用场景就是用户偏好和猜你喜欢嘛。用 scipy 的`distance.jaccard()`。
        - q: 方差和协方差 `np.var(A, ddof=1)`和`np.cov(A)`
        - q: 马氏距离是啥？ *用来处理`欧氏距离`忽视了样本中某特性的场景* （比如说相同距离，骑摩托和跑步耗费时间不同，但是用欧式距离忽视其交通工具，马氏距离则考虑其特性）
        - q: 什么是“修正的余弦相似性”？和余弦距离有啥区别？
        - q: 什么是“相关系数”（皮尔森相关系数）？
    - url: https://github.com/antlabs/strsim
    - url: https://github.com/pandas-dev/pandas
      qs:
        - q: pandas 查询功能怎么用？怎么过滤数据？分组函数？
        - q: 有哪些格式化日期的方法？
        - q: 排序方法？ # sort_index(ascending=False)
        - q: 定位函数？怎么取自定义的行数和列数？iloc
    - url: https://github.com/automl/auto-sklearn
      qs:
        - q: sklearn 包含了很多基本 ML 算法，比如回归（包括线性回归、逻辑回归、曲线回归等），贝叶斯、kNN、决策树、SVM。
        - q: numpy 的 shape() 和 reshape()
        - q: 怎么计算用户偏好？  # “修正的余弦相似性”用户相似性 User-Based 商品相似性 Item-Based
        - q: 不同服务的选择不同，一般来说应该选择数量相对较小的、变动不频繁的作为 base（比如电商网站应该根据 Item-Based，新闻网站应该根据 User-Based）
        - q: 怎么计算“余弦相似度”？  # sklearn.metrics.pairwise.cosine_similarity
    - url: https://github.com/MaartenGr/BERTopic
      des: TF-IDF, 使用 tf-idf（词频 - 逆文档）方法进行统计，tf-idf 的思路是什么？如果某个词频很高，但是在其他文档很少出现，就认为这些词适合用来做区分。使用`tf-idf + jieba分词 + sklearn`来实现文本分类。
    - url: https://github.com/apache/spark
      des: stream process engine. 支持批处理和流处理，以及机器学习和图形处理。Spark 使用弹性分布式数据集（RDD）的概念，可以在内存中高效地处理大规模数据。它提供了丰富的 API 和工具，包括 Spark SQL、Spark Streaming、MLlib 和 GraphX 等，可用于数据处理、数据分析、机器学习和图形计算等场景。常见的使用场景包括数据仪表盘、实时日志分析、推荐系统和批量数据处理等。
    - url: https://github.com/apache/flink
      des: stream process engine. 专注于实时数据处理和分析。Flink 支持事件时间处理和窗口操作，可以处理无界流和有界流数据。它提供了强大的状态管理和容错机制，可以保证数据处理的一致性和可靠性。Flink 还支持复杂的事件处理模式和流式 SQL 查询。常见的使用场景包括实时数据管道、实时数据分析、复杂事件处理和流式 ETL 等。
    - url: https://github.com/flowable/flowable-engine
      des: BPM
    - url: https://github.com/camunda/camunda-bpm-platform
      des: BPM
    - url: https://github.com/alibaba/DataX
      des: DataX, Talend, kettle
    - url: https://github.com/Talend/ui
      des: Talend UI
    - url: https://github.com/DataV-Team/DataV
      des: 搭配DataX使用的数据可视化工具
    - url: https://github.com/matplotlib/matplotlib
      des: python 可视化库，就是用来画各种图的，什么折线图、曲线图、柱状图、散点图
    - url: https://github.com/mwaskom/seaborn
      des: python可视化pkg
    - url: https://github.com/plotly/dash
      des: Dash 则是一个用于构建交互式 Web 应用的 Python 框架
    - url: https://github.com/plotly/plotly.py
    - url: https://github.com/plotly/plotly.js
      des: Plotly 提供了丰富多样的交互式绘图功能


- type: lua
  repo:
    - url: https://github.com/lua/lua
      qs:
        - q: lua, feats? #
        - q: Why lua is faster than others?
    - url: https://github.com/luarocks/luarocks
      des: lua package manager
    - url: https://github.com/LuaJIT/LuaJIT
    - url: https://github.com/luau-lang/luau


# cpp

- type: cpp
  repo:
    - url: https://github.com/bminor/glibc
      des: glibc
      qs:
        - q: Compare cpp and c?
        - q: cpp, memory (arena, heap, chunk, memory)
        - q: cpp20, changelog?
        - q: cpp, STL
        - q: cpp, virtual function, pure virtual function
    - url: https://github.com/llvm/llvm-project
      des: llvm
    - url: https://github.com/gcc-mirror/gcc
      des: gcc
    - url: https://github.com/FFmpeg/FFmpeg
      cmd:
        - c: ffmpeg -i concat:'<1.wav|...>' -c copy <output.wav>
          x: 合并多个音频文件，保持音频格式一致即可。例如 ffmpeg -i concat:"1.wav|2.wav|3.wav|4.wav" -c copy output.wav
        - c: ffmpeg -i <input.mp4> -vn -acodec copy <output.aac>
          x: 视频转换为音频，-vn 表示不处理视频流，-acodec copy 表示直接拷贝音频流，不做编解码
    - url: https://github.com/danmar/cppcheck
      des: cpp static analyze tool.
    - url: https://github.com/gperftools/gperftools
      des: = pprof for golang.


- type: zig
  repo:
    - url: https://github.com/ziglang/zig
      qs:
        - q: "@comptime"
          d: https://kristoff.it/blog/what-is-zig-comptime/



---

- type: PDF
  repo:
    - url: https://github.com/pdfcpu/pdfcpu
      des: 用于创建新的 PDF 文档、编辑现有文档、合并 PDF 文件、拆分 PDF 文件、加密和解密 PDF 文件，以及执行其他多种 PDF 相关的操作。
    - url: https://github.com/bblanchon/pdfium-binaries
      des: 也是pdf操作库和渲染库，类似pdfcpu吧，但是pdfium更侧重于渲染，而非操作。




- type: Icon
  repo:
    - url: https://github.com/iconify/iconify
      doc: https://icon-sets.iconify.design/
      des: icon
    - url: https://github.com/simple-icons/simple-icons
      des: simpleicons类似Iconify，都是icon库，也可以通过npm引入


- type: xxx
  repo:
    - url: https://github.com/apache/airflow
      des: DAG
    - url: https://github.com/Genymobile/scrcpy
      des: 用命令行控制Android设备 scrcpy = screen copy. Scrcpy uses adb to communicate with the device, and adb can connect to a device over TCP/IP. The device must be connected on the same network as the computer. 基于ADB来连接设备。也有类似 FreeControl 这样基于scrcpy实现的带GUI的项目。
    - url: https://github.com/tsl0922/ttyd
      des: 用来在网页打开Terminal(通过ws)，类似阿里云ECS控制台支持的“Workbench 远程连接”功能。
    - url: https://github.com/Unitech/pm2
      des: Daemon Process Manager(Process Monitor). Much better than supervisor or forever.
    - url: https://github.com/aria2/aria2
      des: 之前折腾aria2浪费了很多时间，aria2+alist直接离线下载资源（alist本身提供了alist-aria2的image）。事实证明，aria2 无法替代迅雷，毕竟迅雷又不限速，但是aria2速度很慢，还会出现各种小问题。
    # [requireCool/stealth.min.js: Automatically generate the newest stealth.min.js.](https://github.com/requireCool/stealth.min.js)
    - url: https://github.com/getkin/kin-openapi
      des: 直接用swagger代替postman。他这个也支持“像 springboot-swagger 一样，配置成只在开发环境开启 swagger，生产环境默认关闭。”，但是不知道实际用起来怎么样。如果好用的话，就不需要 postman 了。
    - url: https://github.com/actionsflow/actionsflow
      des: 基于gh-actions实现的IFTTT/Zapier，生态还行，但是我基本用不到。曾经IFTTT上长期使用的只有根据天气预报，提前推送下雨带伞的提醒。以及到达公司周围1km内，推送打卡提醒，并且自动打开DingTalk。但是后来就都不用了。
    - url: https://github.com/instill-ai/vdp
      des: ChatGPT pipeline工具，用来编排各种GPT服务，来直接按照预期直接输出
    - url: https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI
      des: RVC, 基于VITS的简单易用的变声框架
    - url: https://github.com/apache/opendal
      des: 继 BeyondStorage/go-storage 失败之后，xuanwo吸取了之前的教训，用rust实现的服务。与BeyondStorage的功能类似，“帮助用户从各种存储服务中以统一的方式便捷高效访问数据”。也可以简单地理解为给各种S3之类的Object Storage、各种kvdb、各种ftp之类的传输协议等存储服务提供统一的抽象层。可以简单理解为“在S3之上，但是类似S3之于Object Storage这样的抽象层”
    - url: https://github.com/pingcap/tiflow
      doc: https://mytechshares.com/2022/04/06/do-you-known-cdc/
      des: tiflow = DM + TiCDC. CDC (Change Data Capture)服务（或者说是 SSOT (Single Source OF Ture)），可以同步数据到 MySQL, Puslar, TiDB, Kafka 以及做增量备份。就是用来在异构数据库之间传数据的。
    - url: https://github.com/go-mysql-org/go-mysql
      des: PingCap的大佬唐刘实现的，他称之为 MySQL Toolset with Go. 支持replication, canal(CDC), client, server, failover 这些功能。还是非常实用的。
    - url: https://github.com/debezium/debezium
      des: 数据源支持 MySQL, MongoDB, PostgreSQL, SQL Server, Oracle, Db2, Cassandra, 通过 kafka connect 获得增量数据写到 kafka, 供后续业务订阅与消费
    - url: https://github.com/GerritCodeReview/gerrit
      des: CodeReview



- type: web
  repo:
    - url: https://github.com/hr3lxphr6j/bililive-go
      des: 这个东西是各种平台视频切片或者录制组需要的工具，看起来还不错。用builder模式把所有的直播间创建和配置所有live对象。核心就是lives.go。单体应用，但是也加了prom+grafana的metrics监控，因为这个不是用来监控服务的，而是用prom来监控直播间的。
    - url: https://github.com/iyear/pure-live-core
      des: 感觉类似bililive-go?
    - url: https://github.com/getfider/fider
      des: 用户反馈收集平台。使用paddle实现订阅付费。
    #- url: https://github.com/gethomepage/homepage
    #  des: homepage, integrates over 100 services(as widgets), and support list these in dashboard. Support common services like Plex, Calibre-web, Emby, FreshRSS, Home Assistant, Adguard, qBittorrent, NextCloud, and so on. It's just a super-webstack actually.
    - url: https://github.com/rocboss/paopao-ce
      des: pretty fast, a "twitter like" community built on gin+zinc+vue+ts. FRO.



- type: Cli-Tools
  repo:
    - url: https://github.com/rclone/rclone
      key: true
      des: rsync for cloud storage - Google Drive, S3, Dropbox, Backblaze B2, One Drive, Swift, Hubic, Wasabi, Google Cloud Storage, Yandex Files
      cmd:
        - c: rclone config file
        - c: "rclone tree <r2>:"
          x: 需要说明的是，这里的 r2 是 config文件中的 Table 配置文件如下
        - c: rclone copy <local-path> r2:<bucket>/<r2-path> --progress --dry-run
        - c: rclone copy docs r2:hhacking/docs --progress
          x: 上传到目标文件夹。⚠️ 上传文件前，一定要打开代理，否则会 timeout。
        - c: rclone check <local-path> r2:<bucket>/<r2-path> --dry-run --size-only --one-way
          x: rclone check docs r2:hhacking/docs --size-only --one-way 上传完成后 check 文件是否全部上传
        - c: rclone sync r2:<bucket> <local-path>
          x: 用来下载远程，需要注意的是因为sync命令的本质是mapping，所以会删掉该文件夹下其他文件，一定要注意。另外，上面的r2指的是rclone.conf中的group key
    - url: https://github.com/WayneD/rsync
      des: used to sync. 也可以用来备份和restore文件

    - url: https://github.com/restic/restic
      des: used to backup
    - url: https://github.com/ngosang/restic-exporter
      des: restic exporter for prom

    - url: https://github.com/trzsz/trzsz-go
      des: lrzsz

    - url: https://github.com/cli/cli
      key: true
      des: GitHub’s official command line tool
      cmd:
        - c: gh cache list
        - c: gh workflow list
          x: "Get workflow-id, nor workflow-name. NOTICE: As long as add test branch, you can trigger by workflow_dispatch event"
        - c: gh workflow run <workflow-id> --ref <branch-name>
          x: Trigger by test branch. eg. gh workflow run 75843747 --ref test

    - url: https://github.com/gruntwork-io/fetch
      key: true
      des: 非常好用的工具，用来直接拉取github的指定folder

    - url: https://github.com/quantumsheep/sshs
      des: 提供了一个TUI来连接指定ssh host（可以更快捷地整理多个 vps 密钥和登录命令），实际上还是需要自己把 vps 信息在 `~/.ssh/config` 维护。作为替换方案，我们也可以直接把 vps 登录命令做成 alfred 的 snip。

    - url: https://github.com/ssllabs/ssllabs-scan
      des: ssllabs提供的cli工具，用来评估和分析网站和服务器的 SSL/TLS 配置和安全性。比如说检测安全漏洞（弱密码套件、不安全的协议版本、证书问题等），自动化测试等操作。

    - url: https://github.com/xyproto/png2svg
      des: 经过我的反复使用和验证，总结一下，png转svg很困难，如果是黑白图片，一些在线工具都能处理地还行，但是如果是彩色图片，则几乎无法处理。尝试使用png2svg在本地处理彩色图片，算是能处理，但是输出的svg文件会非常大(>10M)，并且效果也不算太好。所以还是算了。

    - url: https://github.com/iawia002/lux
      des: 比youtube-dl或者you-get之类的python实现的下载速度要好很多，但是明显不如downie（相同资源，youtube-dl之类的速度大概100k左右，lux在1.5M左右，downie在5M左右）。这几个麻烦的地方在于只能下载，如果需要“后处理”为音频之类的，还需要 ffmpeg。还不如直接用 downie。


    # [Comparison table - chezmoi](https://www.chezmoi.io/comparison-table/)
    # 尽量免配置：尽量使用自带备份服务的工具，可以大大降低备份服务的复杂度（比如我常用工具里 alfred、chrome 和 goland 都可以自动备份配置，剩下几个都是无状态免配置的，所以不需要针对某个工具备份其配置文件）
    # 尽量精简 APP：使用“超级 APP”，而非功能单一的 APP，多想想怎么替代这些简单 APP？
    # 尽量使用 homebrew 安装所有 APP 和命令行工具
    - url: https://github.com/twpayne/chezmoi
      des: 备份服务嘛，我需要备份的只有Brewfile和zshrc，mackup, dotbot之类的这些备份工具都玩过，感觉没啥用。

    - url: https://github.com/tldr-pages/tldr
      des: 这类工具比较多。比其他几个好，但是也远不如tldr活跃，tldr的更新是hourly的，denisidoro/navi和cheat/cheat则是weekly~monthly水平的。目前用tldr作为tldr-alfred的数据源（日常使用的基本上都有，默认自动更新，不需要手动维护）。这类工具作为Docs-Opener，也至少比Dash或者DevDocs好用太多了。

    - url: https://github.com/schollz/croc
      des: 同wifi下传文件，类似airdrop



- type: LLM
  repo:
    - url: https://github.com/huggingface/transformers
    - url: https://github.com/huggingface/diffusers
    - url: https://github.com/lm-sys/FastChat
    - url: https://github.com/langchain-ai/opengpts
    - url: https://github.com/liguodongiot/llm-action
      des: LLM相关文档和项目实战
    - url: https://github.com/tensorchord/Awesome-LLMOps
      des: LLMOps
    - url: https://github.com/netease-youdao/QAnything
      des: 这个就是我一直想要的“基于LLM的本地知识问答库”
    - url: https://github.com/plandex-ai/plandex
      des: 用来编排GPT任务的workflow工具。它利用AI编码引擎来处理复杂的任务，并提供了一种在终端中管理上下文、执行任务和获取结果的方式。
    - url: https://github.com/infiniflow/infinity
      des: AI 原生数据库
    - url: https://github.com/infiniflow/ragflow
      des: ???
    - url: https://github.com/meta-llama/llama3
      des: llama3
    - url: https://github.com/abi/screenshot-to-code
      des: 相当于某种更牛逼的low-code? 只需要截图就能直接获取vue/react代码
    - url: https://github.com/truefoundry/cognita
      des: 用于构建模块化、开源 RAG（Retrieval-Augmented Generation）应用程序的框架，适用于生产环境。使用 Langchain/LlamaIndex 作为底层技术，提供了代码组织结构，使每个 RAG 组件都是模块化、API 驱动和易于扩展的。它还支持增量索引，并提供了无代码 UI 支持。可以利用 Cognita 来组织和管理 RAG 代码库，通过本地设置或 UI 组件进行测试，并部署到生产环境中。




- type: shell
  repo:
    - url: https://github.com/alebcay/awesome-shell
      des: 感觉没啥用
    - url: https://github.com/mvdan/sh
      des: shfmt，也可以用于解析、格式化和解释Shell脚本。需要注意的是shfmt和shellcheck都是shell的linter，但是确实不同，shellcheck 是个静态分析工具，更侧重于代码的逻辑和语法正确性，而 shfmt则是一个格式化工具，更侧重于代码的格式和可读性。
    - url: https://github.com/google/zx
      des: zx必须要安装nodejs才能跑。看到这类工具一定会有疑问“不就是给命令包了一层js，为啥不直接用命令呢？”，但是zx相较于命令，zx提供了更好的错误处理机制（在shell中，错误处理可能比较繁琐和复杂，而 zx 允许开发者使用 try-catch 语句来捕获和处理错误），zx还支持模块化（这点是shell的一大痛点）。说白了在nodejs生态下，是shell的不错的替代品。
    - url: https://github.com/com-lihaoyi/Ammonite
      des: 相当于是在命令行中直接用scala代码代替shell脚本，其实没啥意思。我为啥不直接用其他interpreter lang呢？同类工具也不如zx好用。这个工具适合java开发在JVM下直接跑scala代码（来代替shell脚本）的，确实有其合理性。
    - url: https://github.com/dwmkerr/effective-shell
      des: 相当于Modern Cpp之于Cpp，提供了一些高效实用shell的BP
    - url: https://github.com/fish-shell/fish-shell
      key: true
      des: 也是shell interpreter
      qs:
        - q: bash, zsh, fish 有啥区别?
      cmd:
        - c: fish_config
    - url: https://github.com/oh-my-fish/oh-my-fish
      cmd:
        - c: omf list
        - c: omf install
        - c: omf update
    - url: https://github.com/IlanCosman/tide
      des: 可以认为是类似omf这样的theme，但是tide更专注于用来自定义prompt，而omf则更全面，提供plugin, prompt, functions等等功能。tide自称inspired by p10k，其实二者也可以认为是zsh中omz和p10k的区别。个人感觉没啥用。

    - url: https://github.com/nicolargo/glances
      des: 更易用的top/htop，还支持web模式。但是其核心是“轻量级monitor系统”，glances还分可以分为server模式和client模式，所有slave机器都需要安装glances的server，master开启client模式就可以收集所有slave的数据（类似prometheus这样的pull模式）。所以也可以理解为局域网下的prom（glances不适合在公网做monitor），感觉意思不大。
    - url: https://github.com/withfig/autocomplete
      des: fig, 命令自动补全工具，需要自己维护commands(还需要写成ts代码)，才能使用类似效果



---


- type: alfred
  #  feats:
  #    - feat: 剪贴板
  #      des: Pin
  #    - feat: snippets
  #      des: SnippetsLab, Lepton, CodeExpander
  repo:
    - url: https://github.com/deanishe/awgo
      key: true
      des: = js的alfy, 用来实现alfred workflow
      qs:
        - q: 怎么设置给alfred的workflow设置proxy
        - q: alfred 怎么在后台执行耗时程序？
        - q: 怎么在awgo中实现输入主命令直接获取全部child commands？ # valid: false
        - q: 回显，并且按照child command继续执行？或者说，怎么在 alfred 中实现链式操作？就是把选定的 item 作为 workflow 的命令执行，继续执行
        - q: 使用 script filter 时，怎么把某个 item 始终置顶？fuzzy filter时会被滤掉，怎么处理？

        - q: workflow中item的icon的选择？ # 不要透明背景icon
        - q: How to add warning item in script filter? # wf.NewWarningItem()
        - q: Which methods are required in item? # NewItem().Title().Valid()
        - q: MagicAction
        - q: 什么情况下使用fuzzy filter？怎么自定义fuzzy filter的field？
        - q: 怎么在选中item后执行自定义outputs的方法？
        - q: Env和Config有啥区别？
          x: |
            **Env 通常是 wf 执行的必填项，比如说各种 token，比较隐私，默认是不导出的。并且一定是必填的，如果不填写会直接报错。Config 则是各种附加配置，默认是导出的，所以通常用来存一些不敏感的数据** Config 则如果没有规定必填，则可以选填，也不影响执行。
        - q: query和argv有啥区别？
        - q: workflow通常设计几个参数比较合理？ # arg最多1个，不要child commands
        - q: How to update config directly, other than use cache? Config.Set()
        - q: External Trigger
        - q: NewModifier
        - q: awgo搭配cobra使用时，使用哪个args
          x: 对于 cobra 来说，subcommand 并不是 args，但是对于awgo来说这些都是args，所以这里是有错位的。建议使用 cobra 提供的 args，因为它还提供了一些 args 的验证方法，可以直接使用，非常方便，使用参数要统一。
        - q: Automation 预制件
        - q: golang 调用 applescript
        - q: wf.Cache, wf.CacheDir()
        - q: 字符串被换行的问题？ #  script操作中使用 echo -n 输出，否则会换行
        - q: 怎么使用“Arg and Vars操作”
          x: Var(nextActionKey, nextActionCopy) 这个写法很有用，在items的每个item中都添加一个var返回，方便进行后续 filter/if 处理时通过 var 进行分支处理 copy或者open URL/play sound之类的操作。之前确实没搞过这种写法。
        - q: 怎么在 script 操作之后不需要选择 item，直接进行“输出操作”呢？ # 直接使用`script操作`，而非`script filter操作`（这个必须返回 item 作为展示项）
        - q: process input in alfred, utilities (transform, replace, ...)

    - url: https://github.com/cage1016/ak
      des: cli工具，基于awgo+cobra实现，用来初始化workflow，提高开发效率。
      qs:
        - q: ak的使用流程
          x: 开发阶段，不需要手动替换bin了，直接make build即可。发布阶段，不需要在本地打包、导出再上传，直接在cicd打包，非常简单。
      cmd:
        - c: ak add ga
          x: ak add githubAction
        - c: ak add ga -s
          x: ci中添加 Code Sign 及 Notarization 功能。如果没有苹果开发者账号的话，就不需要加 -s 参数。正常使用，毫无问题。
        - c: ak add ga -c
          x: ci中添加 Go test Codecov
    #    - des: CASK. 常用 APP 快捷键. used to replace Hyperdock, DockMate, Manico... nf.
    - url: https://github.com/hxhac/docs-alfred
      des: qs 快捷操作，并且代替掉之前的chrome-workflow, gh-workflow
    - url: https://github.com/hxhac/pwgen-alfredworkflow
      des: 密码生成工具 pwgen
    - url: https://github.com/hxhac/pix-alfredworkflow
      des: 全局图床工具，上传图片到cloudflare R2
    - url: https://github.com/vitorgalvao/shrieking-chimes-workflow
      des: 倒计时工具
    - url: https://github.com/roele/alfred-nosleep
      des: 相当于CoffeeCoffee或者Caffeinated APP。用来让 mac 扣盖后，继续播放音乐（也就是防止 mac 进入睡眠状态）。但是用了一年多之后，发现这种低频需求，实际上可能隔几个月才要用一次，所以还是用 shell 实现更好



- type: Security
  repo:
    - url: https://github.com/MatrixTM/MHDDoS
      des: DDos Attack Tools.
    - url: https://github.com/nmap/nmap
    - url: https://github.com/rapid7/metasploit-framework
    - url: https://github.com/robertdavidgraham/masscan
    - url: https://github.com/Ettercap/ettercap
    - url: https://github.com/shadow1ng/fscan
      des: 内网扫描工具
    - url: https://github.com/owasp-amass/amass
    - url: https://github.com/vidar-team/Cardinal
    - url: https://github.com/We5ter/Scanners-Box
    - url: https://github.com/RaiMan/SikuliX1
    - url: https://github.com/gophish/gophish
    - url: https://github.com/c0ny1/upload-labs
      des: 一个想帮你总结所有类型的上传漏洞的靶场
    - url: https://github.com/vulhub/vulhub
    - url: https://github.com/kismetwireless/kismet
  qs:
    - q: What about web security? 有哪些常见的 web 攻击手段？ # (SQL injection, XSS, CSRF, DDos, ARP attack, )
    - q: "***拿到一个待检测的站或给你一个网站，你觉得应该先做什么？***"
    - q: What's Sniffing and How To Prevent it? Why can't we capture Baidu's data? (SSL-pining, HPKP, HSTS, Expect-CT)
    - q: How to identify whether ddos? How to check if the server is DDosed?
    - q: Tell me in detail how to "monitor DDos attack + automatically apply for new VPS"?
    - q: (poc, vul, exp, payload, shellcode, cve, cvnd, 0day, APT)
    - q: (size, filetype(!js, !exe), rename)
    - q: 内网扫描器是啥？通常支持哪些功能？ # 端口扫描, 探测存活 IP, 漏洞检测, 其他功能如信息收集/存活主机/端口扫描/服务识别/密码爆破/漏洞检测/漏洞利用/远程执行命令/降权提权
    - q: 什么是文件上传攻击？ # 文件名（目录穿越）、文件路径、文件后缀、文件大小、文件内容（图片木马）
    - q: 文件上传攻击的原理？
    - q: 有哪些文件上传攻击？对应的防止方法？
    - q: DDos 有哪些类型？ #传输层、反射型
    - q: 详细说说怎么“监控 DDos 攻击 + 自动申请新 VPS”？ # 用一台服务器监控服务是否被 DDos，一旦被攻击，通过这台服务器，自动申请新的 ECS，自动加监控，自动响应攻击生成新的配置文件。把域名解析到新服务器。
    - q: pwn 专业术语 # poc, vul, exp, payload, shellcode, cve, cvnd, 0day, apt



- type: Browser
  md: true
  repo:
    - url: https://github.com/chromium/chromium
      des: Chrome Chromium.
    - url: https://github.com/WebKit/WebKit
      des: WebKit, Render Engine. WebCore 是 WebKit 的核心部分，它负责处理 HTML、CSS 和 XML 等标记语言的解析，以及布局和绘制等工作。JavaScriptCore 是 WebKit 中用于执行 JavaScript 代码的部分，它是一个独立的 JavaScript 引擎，负责将 JavaScript 代码编译成字节码并执行。因此，WebKit 可以被视为一个渲染引擎，而 JavaScriptCore 是它内部的 JavaScript 引擎。
    - url: https://github.com/mozilla/geckodriver
    - url: https://github.com/mozilla/gecko-dev
      des: js Engine for firefox.
    - url: https://github.com/v8/v8
      des: v8, 需要注意的是v8是js engine，而不仅仅是interpreter或者compiler. v8解析代码的具体流程是 Parser -> AST -> Interpreter -> Profiler -> Compiler -> Optimized Code.
    - url: https://github.com/v8/v8.dev
      des: js Engine for chrome.
    - url: https://github.com/ChromeDevTools/awesome-chrome-devtools
    - url: https://github.com/CN-Chrome-DevTools/CN-Chrome-DevTools
  qs:
    - q: "***How does browser rendering works?***"
      x: |
        js被webpack之类的compiler打包成静态资源，browser负责解析这些静态资源，render engine负责把html和css渲染成页面，js引擎负责解析和执行js代码。

        再具体一点来说，render engine的整个渲染过程由上面说的解析html为DOM树、解析css为构建渲染树、计算布局、绘制和合成展示这几步构成。而js引擎则负责所有交互时间，比如我们点击按钮时，browser就会通过js listen event，并在触发时执行相应的js函数。

        浏览器就是两部分，js引擎和渲染引擎

        渲染引擎就比如blink（负责整个渲染管道，包括 DOM 树、样式、事件和 V8 集成。它解析 DOM 树，解决样式问题，并确定所有元素的视觉几何）

        js引擎则是v8或者Gecko之类的，可以通常认为v8的核心就是Ignition这个interpreter，实际上v8还需要TurboFan 优化编译器、垃圾回收机制、内存管理等机制共同实现。是不是感觉这些东西跟一门编程语言需要实现的机制也差不多？换句话说，可以认为v8是js的一个实现，也就是clang之于cpp，pypy之于python。

    - q: CORS 跨域，怎么优化跨域？怎么优化CORS OPTIONS预检请求？
    - q: Cookie的SameSite策略
    - q: browser maxmum conn limit, same domain? # RFC2616, HTTP spec, six conns
    - q: render engine # blink(webkit, skia)
    - q: js engine # gecko, v8(Ignition)
    - q: 浏览器将标签转成 DOM 的过程
    - q: "*the process of page resource? (resouce-scheduling, conn-start, request/response) What does each of the include? (queueing, stalled, TTFB)*"
    - q: page loading lag, how to troubleshot the problem?

    - q: "*Browser Cache: Is there a relationship between browser cache and HTTP cache?*"
      x: (Cache-Control) (force cache (200, from-cache), negotiation cache (304))

    - q: How to validate TTL? # Last-Modified/If-Modified-since, ETag/If-None-Match
    - q: (max-age, private, ...)
    - q: (compare If-Modified-Since and If-None-Match, if equal 304, if not 200(, and reset Last-Modified and ETag))
    - q: chrome怎么做性能分析？ # disable cache, 模拟弱网条件, 模拟移动端 CPU 效果,



#- type: java
#  repo:
#    - url: https://github.com/dromara/hutool
#      des: java utils pkg




- type: Low-Code
  repo:
    - url: https://github.com/nocodb/nocodb
    - url: https://github.com/baidu/amis
      des: 之前用过
    - url: https://github.com/open-webui/open-webui
      des: 基于LLM的low-code工具，支持本地RAG集成、RLHF注释、对话标记、GGUF文件模型创建、多模型支持、多模态支持等功能
    - url: https://github.com/wandb/openui
      des: 类似open-webui，也是基于LLM的low-code工具
  des: low-code/no-code 没啥用，实际上使用场景相当受限，无非是后台页面这种高度规范化的页面，或者活动页这种既高度规范化，又用完即抛的页面。应该说，但凡是注意代码质量和后续需要维护的，就不应该，也不能用low-code生成。







- type: vps-libs
  repo:
    - url: https://github.com/awesome-selfhosted/awesome-selfhosted
    - url: https://github.com/typst/typst
      des: Typst 可以理解为更好用的 LaTeX，支持各种样式和排版。直接用在线编辑器，编译和响应速度还行，不算太慢。直接把简历存到typst上就可以了，也挺省心。
    - url: https://github.com/DIYgod/RSSHub
      des: rsshub
    - url: https://github.com/alist-org/alist
      des: alist, Better than Cloudreve. 我们可以把alist作为网盘文件管理工具或者图床使用。
    - url: https://github.com/ArchiveBox/ArchiveBox
      des: 网页存档 ArchiveBox
    - url: https://github.com/usememos/memos
      des: 更好用的开源的 flomo
    - url: https://github.com/koodo-reader/koodo-reader
      des: 在线电子书网站，类似的还有calibre或者talebook，很好用。但是我真用不到这东西。如果看小说，我还是喜欢直接下载到手机上，用手机看。微信读书支持 txt epub mobi azw3 pdf 常用格式。漫画我不看，kindle 我没有，pdf、富文本和超文本我用 chrome 看。
    - url: https://github.com/mastodon/mastodon
      des: 某种twitter或者微博嘛，但是其去中心化特征，与社交网络本身要求的规模效应是冲突的。我的评价是，不如“知识星球”和“小蜜圈”。
    - url: https://github.com/syncthing/syncthing
      des: |
        一个基于P2P实现的“远程同步文件”工具
        提供GUI和CLI（通过web操作）两种下载方式，用homebrew安装，默认CLI。用这个就可以代替之前用的坚果云了
    - url: https://github.com/navidrome/navidrome
      des: Music Server. 不太好用，内置的刮削器metadata-scraper/tagger非常难用，几乎是完全不可用状态，后来用alist替代掉了。
    - url: https://github.com/dushixiang/next-terminal
      des: Bastion Server
      doc: https://wiki-power.com/Homelab-%E6%94%AF%E6%8C%81%E5%A4%9A%E7%A7%8D%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%A0%A1%E5%9E%92%E6%9C%BANextTerminal/






- type: crawler
  repo:
    - url: https://github.com/scrapy/scrapy
      qs:
        - q: scrapy, config (AUTOTHROTTLE, HTTPCACHE, LOG, FEED)
        - q: scrapy arch? (schduler, downloader, spider, pipeline, engine, download middleware, crawler middleware)
      cmd:
        - c: scrapy fetch
          x: 查看爬取过程，生成日志
        - c: scrapy run
          x: 运行一个单独的爬虫程序
        - c: scrapy shell
          x: 启动shell交互终端
        - c: scrapy startproject
          x: 创建项目
        - c: scrapy version
        - c: scrapy view <url>
          x: 非常实用的命令
        - c: scrapy settings
        - c: scrapy genspider -l
          x: 创建爬虫文件，可以选择basic，crawl，csvfeed，xmlfeed
        - c: scrapy check
          x: 用来测试某个爬虫
        - c: scrapy crawl
          x: 运行某个爬虫
        - c: scrapy list
          x: 显示当前可用的所有爬虫
        - c: scrapy parse
          x: 获取给定的URL并使用处理它的爬虫解析它，使用通过--callback选项传递的方法，或者parse如果没有给出
        - c: scrapy bench
          x: 测试本地硬件性能
    - url: https://github.com/gocolly/colly
      des: crawler
    - url: https://github.com/projectdiscovery/katana
      des: = scrapy for python.
    - url: https://github.com/PuerkitoBio/goquery
      des: = bs for python.
      doc: https://juejin.cn/post/7145373304117788708
    - url: https://github.com/crawlab-team/crawlab
      des: 分布式爬虫管理平台
    - url: https://github.com/salesforce/ja3
      des: browser fingerprint
      qs:
        - q: ja3 fingerprint () ja3s
        - q: 怎么解决`JA3指纹`？解决 ja3 指纹的原理？
          x: ja3transport, CycleTLS (ja3transport 库会在三次握手后，即将发起 client hello 数据包时，拦截该包并用自定义 ja3 替换掉原有的)
        - q: 有哪些靠谱的 ja3 黑名单/已收录指纹？
    - url: https://github.com/CUCyber/ja3transport
    - url: https://github.com/Danny-Dasilva/CycleTLS
    - url: https://github.com/dgtlmoon/changedetection.io
      des: webpage changes detection. Better than LogicJake/WebMonitor. 但是这两个各有问题WebMonitor的notify有问题，changedetection又有中文乱码问题。
    - url: https://github.com/LoseNine/Restore-JS
      des: 反爬虫JS破解与混淆还原
    - url: https://github.com/apify/crawlee
    - url: https://github.com/slotix/dataflowkit
    - url: https://github.com/MontFerret/ferret
    - url: https://github.com/yields/ant
    - url: https://github.com/NaiboWang/EasySpider
    - url: https://github.com/go-rod/stealth
      des: 可以理解为stealth.js的golang实现？就是那个之前用selenium做crawler时防止直接被ban掉的pkg
    - url: https://github.com/pppscn/SmsForwarder
      des: ??? 短信转发器，一个Android APP，可以监听监听收到短信的事件，获取到短信的来源号码、接受卡槽、短信内容、接收时间等内容，然后将其通过一定的规则转发。转发渠道包括钉钉群自定义机器人、钉钉企业内机器人、企业微信群机器人、飞书机器人、企业微信应用消息、邮箱、bark、webhook、Telegram机器人、Server酱、PushPlus、手机短信等。搭配卡池设备就可以实现短信群发。
  qs:
    - q: crawler common questions? # BE, FE
    - q: headers (IP, UA, cookie(x-zse-86), referer), captcha(slider captcha, ReCaptcha)
    - q: PathMarker
    - q: webdriver feats
    - q: What about headless browser? What's CDP?
    - q: What's render-engine and js-engine? How does it works?
    - q: mock login
    - q: How does the crawler automatically accept SMS verification codes?
    - q: 怎么判断网页是否更新？?  # (HTTP code(304/200), LSH, WebMonitor)
    - q: How to monitor crawler is dead?
    - q: js 反调试
    - q: ast 混淆 花指令 流程平坦化
    - q: ast 反混淆 解密大数组
    - q: AST 嵌套解密函数：传参数量混淆 + 传参乱序混淆 + 传参加入运算符混淆
    - q: cloudflare 五秒盾
    - q: 爬虫怎么自动化接受手机短信验证码？ # SmsForwarder


- type: mitmproxy
  repo:
    - url: https://github.com/mitmproxy/mitmproxy
      qs:
        - q: How to use mitmproxy?
    - url: https://github.com/microsoft/playwright
    - url: https://github.com/playwright-community/playwright-go
    - url: https://github.com/alibaba/anyproxy
  qs:
    - q: jsrpc, mitmproxy, anyproxy, playwright
    - q: 怎么破解 js 反爬（混淆加密）？ # playwright



- type: headless
  repo:
    - url: https://github.com/dhamaniasad/HeadlessBrowsers
      des: 各种headless多如牛毛
    - url: https://github.com/go-rod/rod
    - url: https://github.com/chromedp/chromedp
    - url: https://github.com/SeleniumHQ/selenium
      qs:
        - q: selenium的changelog? 从selenium1到selenium4分别有哪些feat?
          x: 浏览器插件、webdriver、grid(selenium 的分布式部署)、bidi (selenium IDE(跨浏览器支持）)
        - q: selenium4之后使用bidi，但是应该从可用性、features以及开销各方面，仍然不如CDP
          x: selenium没有使用CDP，而是使用webdriver protocol，所以其跨平台性确实更好。但是如果只是搞crawler的话，则大可不必使用selenium。
    - url: https://github.com/puppeteer/puppeteer
      des: python 版本的 puppeteer 已经很久不更新了，现在最好使用 nodejs 的 puppeteer，是 chrome 官方团队维护的，生态很好。
    - url: https://github.com/cypress-io/cypress
      des: cypress 是基于 CDP 协议实现的 web 端的 E2E 测试框架。所以他支持所有测试框架的基本功能，比如断言、白页等待、重试，以及可视化调试、并发测试等附加功能。相比于UI测试，E2E测试更侧重业务逻辑。广义上的 UI 测试就包括 E2E。相比于selenium之类的headless browser，cypress则可以理解为headless+测试feats。
    - url: https://github.com/g1879/DrissionPage
      des: 相当于内置了stealth.js之类的反爬服务，但是服务端部署稳定性（保活之类的）不如selenium。据说能绕过cloudflare五秒盾、RS、AKM、jsvmp
  qs:
    - q: 对比一下 puppeteer, playwright, rod, selenium, chromedp这些headless




- type: cross-platform
  repo:
    - url: https://github.com/dcloudio/uni-app
    - url: https://github.com/flutter/flutter
    - url: https://github.com/facebook/react-native
  des: |
    *[跨平台开发该不该用Flutter？2023年版Flutter全面解析_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1D8411o71k/)* 视频不错，很喜欢这种娓娓道来的感觉

    看这个视频时，我想到了两个问题：

    - 这几种移动端跨平台方案，从现在的视角来看是一地鸡毛。大家还是转回移动端原生语言的方案。但是那个时候我们是真心认为“js统一大前端”的。
    - dart和ts都是对js类型支持的解决方案，那么为啥dart在和ts的竞争中失败了？

    这个视频也一下子把我拉回到6、7年前我刚刚入行的时候，那个时候移动端余温尚存，各种移动端跨平台方案层出不穷，大家都在讨论各种“三端一致”的方案。实话说如果不是这个视频，这部分记忆都要淡忘了。几种主流方案：

    - 移动端打包浏览器跨平台（比如Hbuilder, AppCan, Cordova）
    - react-native, uniapp(相当于vue的react-native)
    - flutter

    这三种方案各有优劣，第一种方案是最早的跨端方案，主打快糙猛，很快就被淘汰了。后两种方案，react-native以及uniapp这种就是用js来调用各种原生移动端语言的API的，可想而知，一定会存在适配问题，并且会很慢（因为走了两层，并且无论是js还是swift, OC, java, kotlin性能都不算很好）。flutter则使用dart实现，dart可以理解为某种js方言，flutter则是吸取了以上教训，直接自己（通过chrome的render engine, skia）实现各种移动端的UI，那么这种方案的问题也同样可想而知，生态问题！如果使用flutter就不能使用。

    *所以通过这两种解决方案，可以看到是左右为难，用粘合层来实现就会有性能问题，用类似flutter自己实现的方案则无法使用移动端现有生态。并且二者都会存在很多适配问题。*

    *至于为啥到最后一地鸡毛，大概还是因为跨平台本身可能还是个伪需求*。某种开发者认为很重要，技术管理者认为一般重要，但是老板认为不重要的东西。并且确实以上三种方案从开发角度，也都离原生应用差的有点远，可能会有各种延迟、不适配之类的bug。总结来说就是老板认为不重要，开发者认为重要但是实现不了。最后一地鸡毛也就不奇怪了。






- type: clash
  repo:
    - url: https://github.com/Kuingsmile/clash-core
      des: backup of clash core. 尝试了一下stash，clash套了个surge的壳，每年12英镑，离谱。
    - url: https://github.com/haishanh/yacd
      des: web 端 clash
    - url: https://github.com/XTLS/Trojan-killer
    - url: https://github.com/XTLS/Xray-core
    - url: https://github.com/surgioproject/surgio
      des: 各类代理规则生成器. Generating rules for Surge, Clash, Quantumult.
    - url: https://github.com/CareyWang/sub-web
      des: subscriber-converter
    - url: https://github.com/tindy2013/subconverter
    - url: https://github.com/ginuerzh/gost
      des: 网络代理服务，实现各种网络代理和转发功能，支持多种协议和加密方式。clash, v2ray, surge都是基于gost实现的。
    - url: https://github.com/go-gost/gost
      des: latest version
    - url: https://github.com/cloudflare/cloudflared
      des: 也是类似gost这样的tunnel proxy，但是cfd是专用于cf网络的，而gost则可以自己配置。cfd几个常用场景就是，把流量通过cf做forward到自己的VPS上，以实现反代或者WAF的作用。
    - url: https://github.com/mzz2017/gg
      des: 备用
    - url: https://github.com/apernet/hysteria
    - url: https://github.com/clash-verge-rev/clash-verge-rev
      des: 基于Tauri实现的GUI，服务端还是clash core。看了一下，一般般吧。
    - url: https://github.com/tailscale/tailscale
      des: 据说很牛逼的，Tailscale 提供了一种简单且安全的方式来使用 WireGuard VPN 和双因素认证（2FA）。它允许用户轻松创建一个私有的WireGuard网络，并通过命令行工具或守护进程管理网络连接。
    - url: https://github.com/juanfont/headscale
      des: Headscale 是 Tailscale 控制服务器的开源、自托管实现。它旨在为自托管用户和爱好者提供一个他们可以用于自己项目和实验室的开源服务器。
  qs:
    - q: Clash Relay 套壳 （链式代理）
    - q: Clash 还有三种分组：负载均衡、故障转移、⾃动选择
    - q: 比较几种mac端proxy软件 clashX, cp(clash-pro), cfw(clash-for-windows), ShadowsocksX-NG, QuantumultX, Gost （价格、增强模式（系统代理，网页代理））
    - q: “增强模式”的原理？
      x: 创建TUN虚拟网卡，并配置路由表，目的是将数据转发到TUN设备上，但是由于TUN模式处于网络层，需要通过gVisor/System网络栈来获取传输层的数据，经过本地端处理后，将数据转发到服务节点。
    - q: What feats does surge support?  # 增强模式, 抓包(MitM), DHCP server,
    - q: GFW 流量探测的具体原理？
    - q: 怎么解决clashx开启之后hosts失效的问题？
      x: proxyIgnoreList没用，直接在mac的Proxies里添加该域名即可



- type: PHP
  repo:
    - url: https://github.com/php/php-src
      des: The PHP Interpreter
      qs:
        - q: 怎么评价PHP # 有效负载
        - q: How does PHP works? PHP components? # Zend, Extensions, sapi, Application 如果 PHP 是一辆车，那么车的框架就是 PHP 本身，Zend 是车的引擎（发动机），Ext 下面的各种组件就是车的轮子，Sapi 可以看做是公路，车可以跑在不同类型的公路上，而一次 PHP 程序的执行就是汽车跑在公路上。因此，我们需要：性能优异的引擎 + 合适的车轮 + 正确的跑道。
        - q: PHP interpreter? # PHP code -> Token -> AST -> Opcodes -> Execute Opcodes
        - q: 默认的 PHP interpreter(sapi)，使用 OPcache，使用 JIT 动态编译，这三者有什么区别？
        - q: "***How to optimize PHP? Why has PHP7 perf improved so much?***"
        - q: 几种PSR规范 # Code Spec(PSR1, PSR2, 内容很多，但是无须注意直接用cs-fixer即可), logging(PSR3), Autoload(PSR4)
        - q: PHP 操作指针函数
        - q: PHP 数组函数 # 取差集和交集 diff函数, intersect
        - q: PHP 数组回调函数 # array_reduce(), array_map(), array_filter(), array_walk()
        - q: PHP 排序函数 # sort()/rsort(), asort()/arsort()
        - q: array_search(), in_array(), array_key_exists() 的区别？
        - q: array+array 和 array_merge()？
        - q: PHP 字符串函数 # pos, replace, slashes, cmp, 打印输出
        - q: strtr() 和 str_replace() 的区别 # perf, is case sensitive
        - q: PHP 文件相关函数
        - q: php 如何保留两位小数？
        - q: php 如何返回随机小数？
        - q: 类型声明（type hint）有哪些？
        - q: PHP的OOP语法
        - q: php 自动加载的演进过程？
        - q: PHP 的异常处理？PHP有哪些预定义Exception? # 错误和异常是两码事, try-catch, throwable(php7 之后才有的)
        - q: PHP 有哪些预定义接口类？ # Iterator, Generator, Closure, JsonSerializable, ...
        - q: PHP 闭包(Closure) # use, bindTo
        - q: PHP 魔术方法 # 4*2 + 2*4 = 16
        - q: PHP Attributes?
        - q: PHP 预定义变量
        - q: PHP 全局变量 (全局预定义变量) # $_GET, $_POST, $_COOKIE, ...
        - q: PHP 魔术常量都有哪些？
        - q: PHP 预定义常量都有哪些？
        - q: 怎么定义常量？ #（const 和 define）Const 关键字在类内定义常量，define 在类外定义常量
        - q: public, private, protected, final, static 各自的使用场景？
        - q: “三元运算符”的几种写法？tricks写法？ # ($a = $a ?: 1) ($a = $a ?? 1) ($a = $a ? $a : 1) ($len = $type == 'year' ? 4 : 2;)
        - q: instanceof
        - q: $data as &$key 是什么意思？
        - q: php的xdebug断点调试怎么搞？
          x: 其实php的xdebug断点调试也很简单，pecl install xdebug之后，把对应的 # [[php.ini] xdebug](https://gist.github.com/hxhac/4596477bd95bd797e5cb582d5f60abf4)
      qq:
        - topic: class
          qs:
            - q: 抽象类里可以没有抽象方法吗？ # 抽象类中可以没有抽象方法（全部都是普通方法），那么，抽象类和普通类的区别就在于：抽象类只能继承，不能实例化。
            - q: 抽象类和接口类的区别？ # 接口类是特殊的抽象类。接口类不能声明变量，只能声明常量。抽象类可以声明变量。接口类没有构造方法，抽象类可以有。接口类就是一个类的领导者，指明方向，子类必须完成他指定的方向，就是要实现什么都已经规定好了。抽象类就是把相同的抽出来了，不需要必须使用，继承的时候使用 extends 继承。
            - q: implements, extends # 接口继承用 implements，抽象类继承用 extends
            - q: trait # Trait 解决了 PHP 不能多继承的问题，“看起来像 interface，但是用起来像 class 的东西”
            - q: 如果两个 trait 里有同名方法或者属性怎么办？ # 使用 instanceof() 和 as 来解决。instanceof() 关键字用前者取代了后者，as 关键字给被取代的方法起了一个别名。
    - url: https://github.com/composer/composer
      des: PHP PKG Manager
      qs:
        - q: "**composer 自动加载原理？(有时间自己实现一下自动加载) 把 composer 包名字写到 require 里，执行 update，具体是怎么把包自动加载到 laravel 里的？能不能说一下？**"
        - q: composer.json 文件里都有什么？
        - q: PSR规范 (PSR-4)
        - q: composer SemVer
        - q: composer commands (remove/show/update/self-update/dump-autoload)
        - q: 怎么开发 Composer 包？实战
    - url: https://github.com/PHP-CS-Fixer/PHP-CS-Fixer
      des: 代码规范工具
      cmd:
        - c: php-cs-fixer fix $PWD --config=cs.php
      use:
        - url: https://gist.github.com/hxhac/8ba0b43a6d38906c12825d5dede1e22a
          des: PHP Linters
    - url: https://github.com/phpstan/phpstan
      des: 静态检查工具Static Analysis Tool，和 cs-fixer 一样，一种是作为服务，一种是作为一个 laravel 的 composer 包。建议作为服务使用，以免影响生产环境性能，当然作为包使用更方便。如果laravel项目可以使用larastan。除此之外，其他工具还有 phplint、phpqa、grumPHP。需要注意PHP作为Dynamic-Lang，SAT工具实际上很鸡肋。
    - url: https://github.com/larastan/larastan
      cmd:
        - c: php artisan code:analyse --level=4
    - url: https://github.com/laravel/laravel
      qs:
        - q: "***How to optimize laravel?***" # no way
        - q: laravel 里使用了哪些设计模式？
        - q: laravel 文件夹结构
        - q: laravel 的工作原理？laravel 路由加载原理？
        - q: laravel 不读某个字段？ # 用$hidden 属性在 model 里设置隐藏字段和安全字段
        - q: laravel 里 model 属性的隐藏，展示和临时隐藏？ # $hidden, $visible, 临时隐藏：return $user->makeVisible('attribute')->toArray();
        - q: laravel 的$appends 属性怎么用？ # appends 属性用来临时添加某个数据库里没有的字段，实现动态修改模型，使用 getColumnAttribute() 来定义字段数据
        - q: 同一个 model 使用不同 connections 连接不同数据库，使用事务时，即使报错也无法回滚，怎么处理？  # DB::connection('some_connection')->beginTransaction();
        - q: laravel 单元测试的文件上传？ # $fakeImg = UploadedFile::fake()->image('temp.jpg');
        - q: laravel 里多对多的写入和查询怎么做？
        - q: laravel 里服务容器的工作原理？
        - q: laravel 的 elq 关联关系中的 loadMissing() 和 getDirty() 方法的区别？
        - q: laravel 里多态关系的表单验证
        - q: laravel 怎么添加自定义校验规则？ # 在 AppServiceProvider 里通过 Validator::extend 注册自定义规则，如果规则比较复杂，也课可以通过 make:rule 生成一个对应的自定义规则类。
        - q: 为什么要用 service-container 呢？
      qq:
        - topic: service-provider
          qs:
            - q: laravel 为什么需要 service-provider # register() 就是 service-provider 用来往 service-container 里注册服务的
            - q: service-provider 的加载和执行过程
            - q: service-provider 的boot(), provides() 和$defer
        - topic: facade
          qs:
            - q: facade 是什么？
            - q: facade 的工作原理？
            - q: laravel 是怎么实现 facade 的？
        - topic: queue
          qs:
            - q: 多个 laravel 同时运行时，队列互串的问题，怎么解决？
            - q: laravel 里如何限制队列执行频率和队列长度？
            - q: laravel 里队列，如何给不同的队列设置不同的 list？如何修改某个队列的 driver？ # 这块还要注意 trait 属性不能通过重新定义直接重写的问题，最好在构造方法里重写
            - q: 消息推送是否应该放到队列里？队列里应该放什么逻辑？ # 应该放耗时任务，一些逻辑无关的业务，一些错误容忍性高的业务。比如一些使用了与逻辑无关的第三方应用（比如消息推送，一次两次的失败是可以接收的；当然，一些与逻辑有关的第三方应用应该做好容错）
            - q: laravel 队列的 fail, retry, delay
      cmd:
        - c: composer dump-autoload && php artisan optimize && php artisan cache:clear && php artisan config:clear && php artisan route:clear && php artisan view:clear && php artisan api:cache && php artisan config:clear
        - c: php artisan horizon
          x: horizon是laravel提供的background job工具，用来管理laravel的MQ，支持各种MQ服务包括beanstalked、redis、RabbitMQ之类的
        - c: php artisan serve --host=局域网ip --port=
          x: 怎么把laravel服务暴露在局域网？

    - url: https://github.com/laravel/valet
      des: |
        大概是最好用的laravel开发环境部署工具，比 Vagrant 和 Homestead 之类的都更易用。实话说PHP开发环境确实挺难搞的，要弄一堆东西，如果用valet的话，就舒服很多。另外，valet除了原生支持laravel以外，还支持slim, symfony, wordpress以及Drupal, CakePHP之类很多国外比较常用的PHP框架，如果官方不支持也可以从gh搜到类似 ThinkPHP5ValetDriver 这样的driver，非常实用，可以免受各种安装PHP环境之苦。

        吐槽一下valet，不得不说虽然已经，但是使用流程仍然很别扭，最核心的问题就是，不应该用composer来安装valet（而是应该用）。可以理解为层级问题，依赖关系为php -> composer -> valet，然后需要用valet再

        需要先park再link，park本身就可以给该dir下的所有

        pecl install igbinary

        pecl install redis

        我不理解，为啥用valet提供的虚拟域名，就会报“不支持: redis”的bug，用 run启动built-in的server，就没有这个问题。有点离谱，就这个问题至少搞了1h。
      cmd:
        - c: valet park
        - c: valet link <service>
        - c: valet forget
        - c: valet paths
          x: 用来查看所有link的服务
        - c: valet log
          x: 用来查看valet日志
        - c: valet start/restart/stop/
        - c: valet uninstall
          x: 需要先用这个命令卸载valet，再在composer全局卸载

    - url: https://github.com/shivammathur/homebrew-php
      des: 这个就是valet在用的用来切换PHP版本的repo，因为homebrew对
    - url: https://github.com/shivammathur/setup-php
      des: homebrew-php作者搞的，类似actions/setup-node这样的，用来在actions中打包PHP环境

    - url: https://github.com/dingo/api
      des: 已经EOL了。用来实现接口的路由版本管理，dingo 内置的异常处理（Http Exception）、多种认证方式、接口限流，以及最常用的 transformer
    - url: https://github.com/tymondesigns/jwt-auth
      des: JWT Token for laravel. 用来实现用户认证
      qs:
        - q: jwt 是什么？ # header(加密算法), payload(exp 过期时间，sub 是 jwt 的主体，通常是用户的 id), sign(保证 token 不被篡改)
        - q: 安装 jwt 以及配置
        - q: 为什么需要刷新 token？ # *因为设置有效期后，token 会失效，所以需要刷新 token*
        - q: 怎么使用刷新 token？
        - q: 如果 jwt 被截取了，怎么办？假设一个场景，黑客抓到了用户 a 的 jwt，使用用户 a 的 jwt 进行各种操作，怎么办？
        - q: token 的验证流程？要看源码
        - q: 如果刷新 token 过期了，怎么办？
        - q: 如果 refresh token 过期，就需要用户重新登录了
        - q: 当然还可以把这个机制设计得更复杂一些，比如，Refresh Token 每次使用的时候，都更新它的过期时间，直到与它的创建时间相比，已经超过了非常长的一段时间（比如三个月），这等于是在相当长一段时间内允许 Refresh Token 自动续期。
        - q: jwt-auth 黑名单
        - q: laravel+dingo 的第三方登录
        - q: jwt 怎么实现多表多用户系统的隔离？
    - url: https://github.com/thephpleague/fractal
      des: Used To Return RESTful API Data Format(JSON). 实际上就是 dingo 默认的 transformer 层
      qs:
        - q: fractal 的基本使用？ # DAS>AS>JAS
        - q: 怎么直接切换 fractal 提供给我们的三种数据结构？
        - q: 如何返回自定义格式的接口？ # CustomSerializer

    # [一份经过时间检验的 Laravel PHPUnit 测试经验分享 | Laravel China 社区](https://learnku.com/articles/44675)
    - url: https://github.com/sebastianbergmann/phpunit
      qs:
        - q: 断言有哪几种？
        - q: "**phpunit.xml 文件说明**" # 需要现在 phpunit.xml 里预定义各项配置
        - q: laravel 的 tests 文件夹的结构？ # tests 的两个子目录，Feature 用来功能测试，Unit 用来单元测试
        - q: "*多环境下，怎么使用对应环境的 phpunit？*" # 添加 .env.dev, .env.prod 之类的env文件
        - q: 怎么模拟认证用户？
        - q: 文件上传怎么单测？
        - q: 有哪些对于 phpunit 的增强方案？
        - q: phpunit 测试覆盖率
        - q: 怎么用单元测试来测试 laravel 中间件？
    - url: https://github.com/mikeerickson/phpunit-pretty-result-printer
      des: phpunit 美化
    - url: https://github.com/mockery/mockery
      des: Mock Test For PHP
      qs:
        - q: php 有哪些 stub 库？
    - url: https://github.com/spatie/laravel-query-builder
      des: query-builder嘛
    - url: https://github.com/orchestral/testbench
      des: benchmark test for PHP
    - url: https://github.com/DarkaOnLine/L5-Swagger
      des: swagger for laravel
      cmd:
        - c: php artisan l5-swagger:generate
    - url: https://github.com/perftools/xhgui
      des: PHP的性能分析工具都不太靠谱，差不多能用的只有只有这个了，其他的blackfire、z-ray、oneapm、new-relic都不太行。xhgui是基于tideways和xhprof实现的。
    - url: https://github.com/Jiannei/lumen-api-starter
      des: 非常完善的api-starter，可以参考，不逊于我的laravel-starter
    - url: https://github.com/z-song/laravel-admin
      des: 曾经
    - url: https://github.com/jqhph/dcat-admin
    - url: https://github.com/strapi/strapi
      des: 非常好用的后台，可以理解为某种js生态下的laravel-admin，通过定义一些schema或者meta数据，通过在该平台上点击就可以生成API，也内置了low-code来生成页面，通过后台操作把二者串起来就ok了。




- type: chrome
  repo:
    - url: https://github.com/AdguardTeam/AdguardBrowserExtension
      des: 广告拦截器 AdGuard
    - url: https://github.com/sergcen/recent-tabs
      des: Switch Recent Tabs
    - url: https://github.com/DIYgod/RSSHub-Radar
      des: RSSHub-Radar
    - url: https://github.com/ClearURLs/Addon
      des: ClearURLs. 用来清理 URL 无用参数。ClearURLS 目前还能用，但是无法自定义添加 url。Neat URL作者不更新了。我用来搭配快捷键获取URL的markdown格式来用，所以对我来说很重要。
    - url: https://github.com/Simple-Allow-Copy/chrome-extension-allow-copy
      des: Simple-Allow-Copy
    - url: https://github.com/Authenticator-Extension/Authenticator
      des: 非常牛逼，且好用的chrome插件，支持同账户下多端同步，支持Microsoft-Authenticator/Authy/1Password。远远比之前一直用的 https://github.com/gphper/toolbox (Developed by wails & TOTP auth & vue) 要好用很多。


- type: Mac
  repo:
    - url: https://github.com/jaywcjlove/awesome-mac
    - url: https://github.com/wireshark/wireshark
      des: |
        HTTP Sniffer/Capture
        还是得学学Wireshark，mac上 charles $50/license, proxyman $69/license, Fiddler $12/Month, 太离谱了，我还以为免费的呢。相比之下surge都不算贵了。
      qs:
        - q: wireshark不支持使用代理，那么怎么才能在使用clashx的情况下，使用wireshark抓包呢？
        - q: wireshark怎么抓HTTPS的包？
          x: |
            wireshark支持两种方式来解密SSL/TLS报文：

            通过网站的私钥
            通过浏览器的将 TLS 对称加密秘保存在外部文件中，以供 wireshark 加解密
          u: https://monkeywie.cn/2020/08/07/wireshark-capture-https/
    - url: https://github.com/zellij-org/zellij
      des: 相当于更好用的tmux


- type: goland
  repo:
    - url: https://github.com/subtheme-dev/monokai-pro
      des: Monokai Pro Theme
    - url: https://github.com/zeromicro/goctl-intellij
      des: goctl-plugins “Caret going back to the beginning of the line when line feed in .api files”


- type: User-Tracking
  repo:
    - url: https://github.com/mixpanel/mixpanel-js
      des: 用户数据的前端打点数据，这个repo是js的，另外还有iphone和android的repo。Mixpanel是一个用于用户分析和产品优化的平台。它提供了深入的用户行为分析，例如漏斗分析、事件跟踪和更复杂的用户细分。Mixpanel还提供了实时数据和A/B测试等功能。
    - url: https://github.com/PostHog/posthog
      doc: https://juejin.cn/post/7336973329429118985


- type: Linters
  repo:
    - url: https://github.com/pre-commit/pre-commit
      doc: https://pre-commit.com/hooks.html
      cmd:
        - c: pre-commit install
          x: 用来生成pre-commit的git hook
        - c: pre-commit autoupdate
          x: 升级配置文件中工具版本（执行之后，会自动修改config.yaml中该repo的version，这个命令仅限于使用remote（而不是local）的情况）
        - c: pre-commit run --all-files
          x: 提交前执行该命令，查看是否可以提交成功
        - c: pre-commit clean
        - c: pre-commit gc
        - c: pre-commit init-templatedir
        - c: pre-commit uninstall
        - c: pre-commit install-hooks
        - c: pre-commit migrate-config
        - c: pre-commit sample-config
        - c: pre-commit try-repo
      qs:
        - q: 怎么用？基本使用流程？pre-commit-config.yaml 和 pre-commit-hooks.yaml 有啥区别？配置文件中怎么使用本地服务，而不是远程 repo？
          x: |
            其实只需要config.yaml就足够了
            如果使用remote的话，pre-commit会在第一次执行时安装到本地，但是安装时经常会出现各种问题，所以推荐使用local

            - 直接在entry中使用该命令的参数
        - q: "***怎么自己实现 pre-commit 脚本？***"
        - q: 如何将 pre-commit 钩子集成到 CI 流程中？

      des: pre-commit是比husky更通用也更强大的选择
    - url: https://github.com/pre-commit/pre-commit-hooks
      des: pre-commit的一些OOTB的hooks
    - url: https://github.com/filyp/autocorrect
      des: 更好用的pangu，实际上一坨狗屎。主命令 autocorrect --fix，用来 Fix Chinese and English typesetting。
    - url: https://github.com/golangci/golangci-lint
    - url: https://github.com/mvdan/gofumpt
      des: go install mvdan.cc/gofumpt@latest
    - url: https://github.com/super-linter/super-linter
      key: true
      des: |
        superlint, almost contains all common used lints, such as
        - markdown
        - yaml
        - golang
        - github-actions
        - shellcheck
        - dockerfile
        - secrets(gitleaks)
        - ts/js(eslint)
    - url: https://github.com/jorisroovers/gitlint
      des: git commit msg linter.
      cmd:
        - c: gitlint install-hook
          x: 使用gitlint时，必须先用这个命令生成.git/hooks/commit-msg，才能正常使用
        - c: gitlint uninstall-hook



- type: Python
  repo:
    - url: https://github.com/python/cpython
      qs:
        - q: python, What's GIL? pseudo multithreading
        - q: python, magic methods? datatype? `*args` and `**kwargs`? yield?
        - q: Compare event-driven network libs, twisted(python), golang(gnet, netpoll), java(netty, guava, akka)
        - q: pipenv = pip + pyenv + virtualenv
        - q: Why choose pytest instead of unittest that comes with python?
        - q: Compare the coroutine between python and golang? (scheduler, mapping)
    - url: https://github.com/PyO3/pyo3
      des: Rust bindings for the Python interpreter
    - url: https://github.com/pypa/pip
      cmd:
        - c: pip list
          x: 查看所有本地的pip包
        - c: pip freeze > requirements.txt
          x: 记录依赖
        - c: pip install -r requirements.txt
          x: 怎么通过`requirements.txt`安装拓展包？
        - c: pip uninstall
    - url: https://github.com/pypa/pipenv
      cmd:
        - c: pipenv install
          x: 安装虚拟环境或者第三方库，如果没有pipenv环境，就会创建环境
        - c: pipenv install <service>
          x: 如果已经有pipenv环境，则直接安装拓展包。比如 pipenv install scrapy。也可以直接安装多个pkg，比如 pipenv install flask flask-wtf
        - c: pipenv shell
          x: 激活虚拟环境
        - c: pipenv lock
          x: 锁定并生成Pipfile.lock文件
        - c: pipenv lock -r
          x: 生成requirements.txt文件
        - c: pipenv uninstall --all
          x: 卸载全部包并从Pipfile中移除
        - c: pipenv lock -r --dev > requirements.txt
          x: 生成requirements.txt文件
        - c: pipenv install -r requirements.txt
          x: 在pipenv下通过requirements.txt安装拓展包
        - c: pipenv open <xxx>
          x: 在浏览器中查看对应拓展包
        - c: pipenv graph
          x: 显示当前依赖关系图信息
        - c: pipenv check
          x: 检查安全漏洞
        - c: pipenv update
          x: 升级所有拓展
        - c: pipenv update <pkg>
          x: 升级某个拓展
    - url: https://github.com/conda/conda
      qs:
        - q: "@miniconda"
      cmd:
        - c: conda init zsh
        - c: conda config --show
        - c: conda create -n newenv python=3.9
          x: 创建名为newenv的新环境，并安装Python 3.9
        - c: conda env list
        - c: conda search <pkg>
        - c: conda update <pkg>
        - c: conda remove <pkg>
        - c: conda list
    - url: https://github.com/encode/starlette
      des: |
        和FastAPI一样，也是支持ASGI的python生态下的web框架，不同于比较常见的Django和Flask之类的WSGI框架，

        ASGI, WSGI, uWSGI

        FastCGI

        说白了都是Gateway Interface是吧，其实这个概念如果跟k8s串起来的话，就类似CNI, Container Network Interface这样的东西，相当于istio, apisix, linkerd之类的gateway的一个interface，这两个从功能上来说，给我的感觉很相近，但是具体有啥区别呢？

        各种的语言的GI只是用来包一个指定application的，但是CNI则可以用来包k8s的node（虽然本质上也是application）
    - url: https://github.com/hhatto/autopep8
      cmd:
        - c: autopep8 --in-place --recursive .
          x: autopep8 怎么格式化整个项目？

- type: 内网穿透
  repo:
    - url: https://github.com/amalshaji/portr
      des: Portr是一个开源的ngrok替代品，它允许用户将本地的HTTP、TCP或WebSocket连接公开到公网。提供了管理团队和用户的管理员仪表板。包含Portr检查器，用于检查和重放请求。
    - url: https://github.com/fatedier/frp



- type: web3
  repo:
    - url: https://github.com/ethereum/solidity
    - url: https://github.com/AmazingAng/WTF-Solidity
