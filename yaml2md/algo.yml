# data structure


- type: Data-Structure
  tag: &tag ds
  repo:
    - url: https://github.com/chen3feng/stl4go
      qs: map, sorted map, set, sorted set, queue, skiplist
    - url: https://github.com/emirpasic/gods
    - url: https://github.com/bradenaw/juniper
      qs: Another utils for std.
    - url: https://github.com/axiomhq/hyperloglog
      #      qs: 用golang实现redis HLL，有助于理解其实现，仅供参考。
    - qs: redis HLL相比LogLog算法 做了哪些优化？
      sol: 伯努利试验、调和平均数、估算、偏差修正
    - qs: redis hyperloglog的密集和稀疏两种struct各自的实现？执行pfadd和pfcount两个命令的具体流程？
    - qs: hyperloglog 做一些日活、月活的统计之类的功能是很简单的，最低内存占用的去重统计方案，本质来说是一个字符串类型：kv 形式
      sol: bitmap, similar with bloomfilter(1% FPR)
    - qs: 为什么 redis 的 hyperloglog 能节约内存？
      sol: hyperloglog 和布隆过滤器的底层实现几乎相同，这也是为什么它们都能节约内存，误差率也都在 1% 左右，也都可以通过调整 bitmap 大小来调整误差率还是更节约内存。唯一区别就是

    - url: https://github.com/asim/kayvee
      qs: How to implement kvdb? (using hashicorp/memberlist)
    - url: https://github.com/scalalang2/golang-fifo
    - url: https://github.com/echoface/be_indexer
      qs: boolean indexing 广告定向索引实现
    - url: https://github.com/fatih/semgroup




- type: bitmap/bitset
  tag: *tag
  repo:
    - url: https://github.com/RoaringBitmap/roaring
    - qs: How to implement bitmap?
      sol: "[]bool 性能最好"
    - qs: 哪些algo是基于bitmap实现的?
    - url: https://github.com/bits-and-blooms/bitset

# qs: 可以认为bitmap就是个Array，只不过value只能存0/1，所以也可以称为“二进制位数组”。专门用来解决海量数据且数据无重复的场景，位图的每一位来存放某种状态，一般用来判断数据是否存在。


# string match
#- LIS (Longest Increasing Subsequence): used to find the longest increasing subsequence in a given sequence.
#- LCS (Longest Common Subsequence): used to find the longest common subsequence between two sequences.
#- LCP (Longest Common Prefix): used to find the longest common prefix among a set of strings.
#- LPS (Longest Palindromic Subsequence): used to find the longest palindromic subsequence in a given sequence.
#- ED (Edit Distance): used to calculate the minimum number of edit operations between two strings.
#- KMP (Knuth-Morris-Pratt): used to find the occurrences of a pattern string within a main string.




- type: string
  tag: *tag
  repo:
    - qs: 转换成小写字母
      sol: |
        用 range 遍历字符串，如遇到大写字母，其 ASCII 码就加 32 使其变为小写字母，再用 append 把字母一个个添加进 res 输出最后的字符串。
        背景知识：
        大写字母 A - Z 的 ASCII 码范围为 [65, 90]；
        小写字母 a - z 的 ASCII 码范围为 [97, 122]。
    - qs: 最长公共前缀
      sol:
    - qs: 有效的字母异位词
    - qs: 旋转字符串
    - qs: 字符串包含
    - qs: 字符串转换成整数
    - qs: 回文判断
    - qs: 最长回文子串
    - qs: 字符串的全排列




- type: string
  tag: *tag
  repo:
    - qs: 比较redis, golang, c, cpp, rust中string的实现 # (len, free, buf[]) (pointer(str), len, (cap->thread safe))
    - qs: 找到字符串的最长无重复字串
    - qs: 1000 万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。
    - qs: 给出 N 个小写英文字母串，以及 0 个询问，即询问某两个串的最长公共前级的长度是多少？
    - qs: 最长回文字串长度
    - qs: 最短回文串
    - qs: 两个字符串的最大公共子串
    - qs: 手写获取两个字符串的公共字符，返回一个字符串，需要返回的字符串不能重复
    - qs: "@string match"
    - qs: 比较几种“字符串比较算法” (LIS, LCS, LCP(TrieTree/二分法 + 哈希查找), LPS, ED, KMP, RK(Rabin-Karp, hash), RM(Boyer-Moore), BF, Horspool, Sunday)
    - qs: KMP # 通过`部分匹配值表`，在第一次匹配到子串的多位后，通过`部分匹配值表`直接进行移位操作`移动位数=已匹配的字符数-对应的部分匹配值`，匹配到完整子串。
    - qs: How does strings.Index() implemented in golang using RK+FNV? Why not use KMP?
    - qs: Why does golang use RK+FNV to implement string matching? Compare RK and KMP.
    - qs: BM # 坏字符规则、好后缀规则
    # qs: string
    - qs: "misuses: string (iterate, split, concat, convert to bytes, search, replace, compare, modify)"
    - qs: concat string, compare (strings.Builder(), ...) # memory allocation, data copy times
    - qs: How to concat string in golang? Which methods is better? Why?



- type: string
  tag: *tag
  repo:
    - url: https://github.com/antirez/sds
      qs: redis SDS. struct(free, len, []buf)
    - url: https://github.com/seatgeek/fuzzywuzzy
      des: Fuzzy String Matching
    - qs: Why not use FuzzyWuzzy? Why not to use Levenshtein?
    - qs: TF-IDF, KNN(KDTree, BallTree)
    - url: https://github.com/xrash/smetrics
      qs: smetrics = string metrics.
    - qs: WagnerFischer, Ukkonen, Jaro, JaroWinkler, Soundex, Hamming 这几种distance有啥区别?


- type: graph
  tag: *tag
  repo:
    - qs: 图的存储结构和基本操作（建立，遍历，删除节点，添加节点）
    - qs: 最小生成树
    - qs: 拓扑排序
    - qs: "@shortest-path"
    - qs: Compare Shortest Path algo. NW(floyd, bellman, SPFA) (dijkstra) # SPFA是对bellman-ford的优化。floyd 通用性更强，可以解决负权边和负权环问题，但是时间复杂度 `O(V^3)`，适用于复杂场景。Dijkstra 无法解决以上问题，但是时间复杂度 `O((V + E) log V)`，适用于大部分简单场景。
    - qs: 为什么Dijkstra算法每轮递推能够保证找到一个顶点的最短路径？
    - qs: 什么是负权边和负权环？既然 floyd 和 bellman 都可以处理负权边和负权环，那为什么 floyd 算法更好呢？
    - qs: 平面内有N个点，如何快速求出距离最近的点对？
    - qs: "@AVL(平衡二叉树)"
    - qs: "@RBT"
    - qs: What's RBT? Why is RBT the most widely used binary-tree? (binary-search-tree, auto balancing)


# 由node和edge组成的ds，包括有向图DG、无向图UG、有向无环图DAG三种
- type: graph
  tag: *tag
  repo:
    - url: https://github.com/mburst/dijkstras-algorithm
    - url: https://github.com/muzixing/graph_algorithm
    - url: https://github.com/daac-tools/vibrato
    - qs: viterbi, 基于DP的shortest-path
    - qs: 有向图、无向图、V表示点 E表示边
    - qs: Prim O(V^2)
      sol: 适合点少边多的
    - qs: Kruskal
      sol: 选短的边 且选的边能连接2个连通分量 换句话说，选中的边要减少1个连通分量，否者不选
    - qs: Dijkstra
      sol: 每次找到一个距离源点最近的点，然后用这个新找到的点更新路径长度，不能解决带负边的问题。因为每一轮都要扫描一边dist数组找最小的，一共循环V-1轮 邻接矩阵O(V^2) 邻接表O(V^2)
    - qs: dijkstra邻接表、逆邻接表
    - qs: Floyd
      sol: 核心是使用中转点让邻接矩阵的值变小
    - qs: 割点算法 Tarjan
      sol: 用于解决图的强连通分量问题。在有向图中，如果两个节点之间存在一条从任一节点到另一节点的路径，那么这两个节点就属于同一个强连通分量。基于DFS的线性时间算法，核心思想是维护一个栈和一个低链接值（low-link value），通过这些信息来识别和分割强连通分量。




# [Go语言实现多个方法解决10个经典数组问题 - 掘金](https://juejin.cn/post/7101464114924847117#heading-0)
- type: Array
  tag: *tag
  repo:
    - qs: 写一个算法，把一个二维数组顺时针旋转 90 度
    - qs: 求一个数组中连续子向量的最大和
    - qs: 寻找一个数组中前 k 个最大的数 (寻找 k 值)
    - qs: 一个数组，除了一个元素外，其他元素都是相等度，求那个元素？lc137
    - qs: 数组很长的情况下 N 个有序数组求交集并集

    - qs: 两个数组，求两个数组的交集
    - qs: 两个无序数组找到他们的交集
    - qs: 二维矩阵顺时针原地旋转 90 度

    - qs: 合并两个有序数组 lc88

    - qs: 连续子数组的最大和 offer42

    - qs: 数组中值出现一次的数字
    #*What's set? How to implement set? using (hashmap, RBT, array, linked-list) Compare these with time complexity, space complexity and usage scenarios*

    - qs: set 的两个特征？ # 没有重复对象 + 没有特定排序
    - qs: 怎么实现 set？ # struct 好于 map，因为空 struct 是零内存
    - qs: 手写用 map 实现 set，支持 CURD？





- type: List
  tag: *tag
  qs: 一些List(datatype)的实现，包括但不限于LL, DLL, skiplist, ziplist 等ds.
  repo:
    - url: https://github.com/huandu/skiplist
      qs: skiplist in golang. 插入/删除/搜索 都是 O(log n)，它最大的优势是原理简单、容易实现、方便扩展、效率更高。因此在一些热门的项目里用来替代平衡树，如 redis, leveldb 等。
      use:
    - url: https://gist.github.com/hxhac/ac4d4e3d808f7e26d94e117d420f16d3
      qs: skiplist
    - qs: skiplist 是什么？跳表有哪些特点？
      sol: |
        先来说说为什么跳表 niu bi。因为它在绝大多数情况下能代替平衡树，而且实现起来简单，性能还不比平衡树家族各位差（AVL 树，红黑树，这些我都不懂）。我想试问下，比如面试官让你手写树的前序遍历、中序遍历、后序遍历，假如你回忆半天，好不容易用递归的方式写出来了，面试官继续刁难，说不要用递归，你换种方式给我实现。是不是瞬间就崩溃了，可见非递归代码来操作树的复杂度有多高，反正我感觉我身边应该基本上没有能手写的。但是跳表不一样，它简简单单，在你仔细读完我这篇文章的时候，百分百能手写出跳表的查询、插入、删除。

        skiplist = 双向链表（前后节点和上下节点都是双向的） + 二分查找（通过给链表添加多层索引）

        跳表的平均读写操作的时间复杂度都为 O(logN)，可以看到各种操作的复杂度都和RBT相同，但是skiplist插入数据时，会动态维护索引，代价就是。，其实就是“空间换时间”，通过给链表建立索引，提高查找效率，空间复杂度为 O(N)。但是通过调整参数可以降低内存消耗，和那些平衡树结构达到差不多。

    - qs: "***skiplist有哪些独特的使用场景呢？***"
    - qs: 能否自己实现一下 skiplist？
      sol: |
        可以看到有几个关键点
        - maxLevel (maxLevel = log(1/p)/n) n=65535, 所以maxLevel = 8
        - p 抛硬币 (0.25)
        - skiplist 的本质是链表
        - 随机 level（每个节点随机 level）
        - 查找过程，从顶到底（从 maxlevel 开始逐层递减）
    - qs: skiplist 的 randomLevel 其实就是一个普通的随机算法是吗？那为什么不直接 rand.Int(1, 16) 获取区间随机值呢？
    - qs: 跳表怎么新增节点？
      sol: 随着新节点的增加，*让新插入节点随机晋升，晋升后，我们可以再进行一次随机晋升，如果晋升失败，插入操作结束*
    - qs: 跳表怎么删除节点？
    - qs: "***How to optimize skiplist?***"
      d: https://cloud.tencent.com/developer/article/2092420
      sol: |
        - 优化随机 level
        - 自适应 maxLevel
        - 优化插入和删除
        - 对某些数据类型优化
        - Cache Prevs 节点
        - 节点分配优化
    - qs: 为什么 Redis 选择使用skiplist而不是RBT来实现zset?
      sol: 各种操作的复杂度相同，但是 zrange以及 zrank操作，红黑树的效率没有跳表高。按照区间查找数据时，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了，非常高效。
    - url: https://github.com/staeter/ziplist
      qs: |
        ziplist 最大的特点在于节省内存。压缩编码、紧凑存储、连续的内存块。

        ziplist 可以理解为去掉了指针的 list，这么搞可以节省内存。但是实际上这种方案的使用场景是比较有限的，毕竟通常来说，是否占用太多内存并不重要。所以只针对对内存占用十分敏感的场景。也就可以理解为什么 redis 要搞出来这个数据结构了。
    - qs: How to implement ziplist?
      sol: similar with TLV
    - qs: redis ziplist 连锁更新 是啥? 会导致哪些问题? 怎么避免?

    - qs: Why redis using skiplist to implement list, hash and zset, rather than RBT?



- type: linked-list
  tag: *tag
  repo:
    - url: https://gist.github.com/hxhac/3de94ae15933d23d1772eaaacfe79eb4
    - qs: 分别实现单向链表、无序链表和双向链表，还有循环链表？linked-list, unordered-linked-list, double-linked-list, circular-linked-list
    - qs: 链表到底有序还是无序？
    - qs: 怎么对链表进行排序操作？
    - qs: 有一个链表，奇数位升序，偶数位降序，如何将链表变为升序？
    - qs: 如何翻转单链表（单链表逆序）？
    - qs: 现在有一个单链表，如何判断链表中出现了环？
    - qs: 两个单向链表交叉，获取首次交叉的点
    - qs: 单向链表排序
    - qs: 合并两个有序链表 (合并两个有序数组)
    - qs: 合并两个有序的单链表
    - qs: 判断链表是否成环（龟兔赛跑）？
    - qs: 双向链表的增删改查 golang 实现
    - qs: n 个有序的单链表取交集？
    - qs: 实现一个有 pop、push、max 的队列数据结构（list），要求尽可能降低时间复杂度？
    - qs: 能否聊聊redis ziplist，相比于skiplist，ziplist为什么更节省内存？
    - qs: Implementation of zset in redis? Why does redis zset use hashmap and skiplist (instead of RBT)?
    - qs: Compare ziplist and hashtable? # (time & space complexity)
    - qs: Why dose mysql use BPTree instead of skiplist?
    - qs: What's linked-list? Compare linked-list and array from (read and write operations).
    - qs: "**linked-list + HashMap is a very classic combination. What other algo are implemented using this combination as a data structure?**" # (LRU, LFU, HashSet, HashGraph, HashTable, ...)



# HashMap = Hash + Array + Linked List
- type: HashMap
  tag: *tag
  repo:
    - url: https://github.com/deckarep/golang-set
      qs: set
    - url: https://github.com/dustinxie/lockfree
      qs: lock-free hashmap and list
    - url: https://github.com/elliotchance/orderedmap
      qs: map如何顺序读取? 核心思路都是构建一个struct （map+线性数据结构）。只不过线性数据结构的选择不同，一个选择list，另一个选择slice。通过“线性数据结构”实现有序，读取数据时按照这个有序的字段进行读取就可以了。
    - url: https://github.com/iancoleman/orderedmap
      qs: Use slice as linear in struct.
    - url: https://github.com/orcaman/concurrent-map
      doc: https://colobu.com/2022/09/04/a-thread-safe-and-generic-supported-map/
      qs: concurrent-map. default 32 shards, better than https://github.com/cornelk/hashmap, 但是这个pkg的key不支持generics
    - url: https://github.com/alphadose/haxmap
      qs: 相比于concurrent-map，key和value都支持generics
    - url: https://github.com/puzpuzpuz/xsync
      qs: concurrent map的一种实现，仅供参考，不建议使用
    - url: https://github.com/zekroTJA/timedmap
      qs: A map which has expiring key-value pairs.
    - url: https://github.com/nitish6174/extendible-hashing
      qs: Extendible hashing 是哈希表的一种扩展，它用于在数据库管理系统中实现动态索引。它通过动态调整哈希表结构来优化数据访问性能。这种数据结构在数据库系统中广泛用于索引大量数据，尤其是在数据量会随时间变化的情况下。对我来说，最牛逼的是 Expand hashtable without rehash，在扩容或者缩容时不需要rehash。
    - qs: "***实现hashmap的keypoints?***"
      sol: |
        要选好hash func, 要设置合适的load factor, 要选择合适的hash collision解决方案, 以及渐进式扩容.

        - 哈希函数设置合理，不能太过复杂，成为性能瓶颈；
        - 设置装载因子阈值，支持动态扩容，装载因子阈值设置要充分权衡时间、空间复杂度；
        - 如果一次性扩容耗时长，可采取分批扩容的策略，达到阈值后只申请空间，不搬移数据，以后每插入一条数据，搬移一个旧数据，最后逐步完成搬移，期间为了兼容新老哈希表查询，可以先查新表，再查老表；
        - 哈希冲突解决办法：开放寻址法在数据量较小、装载因子小的时候（小于1）选用；链表法可以容忍装载因子大于1，适合存储大对象、大数据量的哈希表，且更加灵活，支持更多优化策略。

    - qs: Why need to rehash? (As the elements increases, hash-collision, perf) redis的HashMap是怎么扩容的？
      sol: (noverflow, load factor) (progressive rehash)
    - qs: "***请比较RBT, skiplist, hashtable***"
      sol: |
        除了ST在处理有序数据时，效率更高（比如说RDB的主键索引）以外，hashtable和skiplist在大多数情况下都能替代ST。比如说，hashtable除了不支持范围查找以外，在不需要这些场景的情况下，哈希表的时间复杂度 O(1) 就已经完胜了。而 skiplist 相比于搜索树，内存占用更高，时间复杂度相当，还支持更方便的范围查找。

         skiplist 与平衡树、哈希表的比较

        skiplist 和各种平衡树（如 AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个 key 的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。

        在做范围查找的时候，平衡树比 skiplist 操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在 skiplist 上进行范围查找就非常简单，只需要在找到小值之后，对第 1 层链表进行若干步的遍历就可以实现。

        平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而 skiplist 的插入和删除只需要修改相邻节点的指针，操作简单又快速。

        从内存占用上来说，skiplist 比平衡树更灵活一些。一般来说，平衡树每个节点包含 2 个指针（分别指向左右子树），而 skiplist 每个节点包含的指针数目平均为 1/(1-p)，具体取决于参数 p 的大小。如果像 Redis 里的实现一样，取 p=1/4，那么平均每个节点包含 1.33 个指针，比平衡树更有优势。

        查找单个 key，skiplist 和平衡树的时间复杂度都为 O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近 O(1)，性能更高一些。所以我们平常使用的各种 Map 或 dictionary 结构，大都是基于哈希表实现的。

        从算法实现难度上来比较，skiplist 比平衡树要简单得多。

        如果单纯比较性能，跳跃表和红黑树可以说相差不大，但是加上并发的环境就不一样了，如果要更新数据，跳跃表需要更新的部分就比较少，锁的东西也就比较少，所以不同线程争锁的代价就相对少了，而红黑树有个平衡的过程，牵涉到大量的节点，争锁的代价也就相对较高了。



















---



- type: Tree
  tag: &tag Tree
  repo:
    - qs: 分层遍历二叉树
    - qs: 二叉树节点的公共祖先
    - qs: 二叉树的最大深度
    - qs: 二叉树的中序遍历和层次遍历
    - qs: 二叉树的右视图
    - qs: 通过中序遍历序列和先序序列恢复二叉树
    - qs: 获取一个二叉树的最小深度
    - qs: 二叉搜索树，两个节点被交换了位置，怎么恢复？lc99
    - qs: 判断二叉树是否为平衡二叉树
    - qs: 蛇形打印二叉树 (之字层序打印二叉树)
    - qs: "[297. 二叉树的序列化与反序列化](https://leetcode-cn.com/problems/serialize-and-deserialize-binary-tree/)"
    - qs: "[124. 二叉树中的最大路径和](https://leetcode-cn.com/problems/binary-tree-maximum-path-sum/)"
    - qs: "[297. 二叉树的序列化与反序列化](https://leetcode-cn.com/problems/serialize-and-deserialize-binary-tree/)"
    - qs: "[104. 二叉树的最大深度](https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/)"
    - qs: "[101. 对称二叉树](https://leetcode-cn.com/problems/symmetric-tree/)"
    - qs: "[226. 翻转二叉树](https://leetcode-cn.com/problems/invert-binary-tree/)"
    - qs: "[543. 二叉树的直径](https://leetcode-cn.com/problems/diameter-of-binary-tree/)"
    - qs: "[257. 二叉树的所有路径](https://leetcode-cn.com/problems/binary-tree-paths/)"
    - qs: "[110. 平衡二叉树](https://leetcode-cn.com/problems/balanced-binary-tree/)"
    - qs: "[617. 合并二叉树](https://leetcode-cn.com/problems/merge-two-binary-trees/)"
    - qs: "[100. 相同的树](https://leetcode-cn.com/problems/same-tree/)"
    - qs: "[112. 路径总和](https://leetcode-cn.com/problems/path-sum/)"
    - qs: "[111. 二叉树的最小深度](https://leetcode-cn.com/problems/minimum-depth-of-binary-tree/)"
    - qs: "[236. 二叉树的最近公共祖先](https://leetcode-cn.com/problems/lowest-common-ancestor-of-a-binary-tree/)"
    - qs: "[222. 完全二叉树的节点个数](https://leetcode-cn.com/problems/count-complete-tree-nodes/)"
    - qs: "[113. 路径总和 II](https://leetcode-cn.com/problems/path-sum-ii/)"
    - qs: "[437. 路径总和 III](https://leetcode-cn.com/problems/path-sum-iii/)"
    - qs: "[129. 求根节点到叶节点数字之和](https://leetcode-cn.com/problems/sum-root-to-leaf-numbers/)"
    - qs: "[662. 二叉树最大宽度](https://leetcode-cn.com/problems/maximum-width-of-binary-tree/)"
    - qs: "[114. 二叉树展开为链表](https://leetcode-cn.com/problems/flatten-binary-tree-to-linked-list/)"
    - qs: "[199. 二叉树的右视图](https://leetcode-cn.com/problems/binary-tree-right-side-view/)"
    - qs: "[116. 填充每个节点的下一个右侧节点指针](https://leetcode-cn.com/problems/populating-next-right-pointers-in-each-node/)"
    - qs: "[515. 在每个树行中找最大值](https://leetcode-cn.com/problems/find-largest-value-in-each-tree-row/)"




- type: Trie Tree
  tag: *tag
  repo:
    - qs: trie
      url: https://gist.github.com/hxhac/205dd7bba11b34c888f5773f7ff112c8
    - qs: 手写 trie 树实现敏感词过滤？
    - qs: 用 hash 和堆、trie 树实现词频统计，比较一下
    - url: https://leetcode-cn.com/problems/longest-word-in-dictionary/
      qs: "[720. 词典中最长的单词]"
    - qs: "[208. 实现 Trie (前缀树)](https://leetcode-cn.com/problems/implement-trie-prefix-tree/)"
    - qs: "[692. 前 K 个高频单词](https://leetcode-cn.com/problems/top-k-frequent-words/)"
    - qs: "[421. 数组中两个数的最大异或值](https://leetcode-cn.com/problems/maximum-xor-of-two-numbers-in-an-array/)"
    - qs: "[212. 单词搜索 II](https://leetcode-cn.com/problems/word-search-ii/)"
    - qs: 需要屏蔽 10 万个关键字，用什么算法？



- type: Binary Search Tree (二叉搜索树)
  tag: *tag
  repo:
    - qs: "[108. 将有序数组转换为二叉搜索树](https://leetcode-cn.com/problems/convert-sorted-array-to-binary-search-tree/)"
    - qs: "[98. 验证二叉搜索树](https://leetcode-cn.com/problems/validate-binary-search-tree/)"
    - qs: "[96. 不同的二叉搜索树](https://leetcode-cn.com/problems/unique-binary-search-trees/)"
    - qs: "[95. 不同的二叉搜索树 II](https://leetcode-cn.com/problems/unique-binary-search-trees-ii/)"
    - qs: "[173. 二叉搜索树迭代器](https://leetcode-cn.com/problems/binary-search-tree-iterator/)"
    - qs: "[230. 二叉搜索树中第 K 小的元素](https://leetcode-cn.com/problems/kth-smallest-element-in-a-bst/)"
    - qs: "[99. 恢复二叉搜索树](https://leetcode-cn.com/problems/recover-binary-search-tree/)"
    - qs: 二叉搜索树，两个节点被交换位置了，怎么恢复？leetcode.99


- type: Binary Tree
  tag: *tag
  repo:
    - qs: 字典序的第 k 小数字 lc440
    - qs: 求二叉树的最大深度
    - qs: 求二叉树的最小深度
    - qs: 求二叉树中节点的个数
    - qs: 求二叉树中叶子节点的个数
    - qs: 求二叉树中第 k 层节点的个数
    - qs: 判断二叉树是否是平衡二叉树
    - qs: 判断二叉树是否是完全二叉树
    - qs: 两个二叉树是否完全相同？
    - qs: 两个二叉树是否互为镜像？
    - qs: 翻转二叉树 (镜像二叉树) 怎么实现？
    - qs: 求两个二叉树的最低公共祖先节点？
    - qs: 二叉树的前序遍历
    - qs: 二叉树的中序遍历 (非递归实现)
    - qs: 二叉树的后序遍历
    - qs: 前序遍历和后序遍历构造二叉树
    - qs: 在二叉树中插入节点
    - qs: 输入一个二叉树和一个整数，打印出二叉树中节点值的和等于输入整数所有的路径
    - qs: 二叉树的搜索区间
    - qs: 二叉树的层次遍历
    - qs: 二叉树内两个节点的最长距离？分为三种情况，使用递归解决
    - qs: 左⼦树的最⼤深度 + 右⼦树的最⼤深度为⼆叉树的最⻓距离
    - qs: 左⼦树中的最⻓距离即为⼆叉树的最⻓距离
    - qs: 右⼦树种的最⻓距离即为⼆叉树的最⻓距离
    - qs: 判断二叉树是否是合法的二叉查找树 (BST)？



- type: Tree
  tag: *tag
  repo:
    - url: https://github.com/google/btree
    - qs: btree, bptree, RBT, suffix-tree, trie-tree, binary-tree, AST
    - qs: BST(二叉查找树), bsp(Binary Space Partition Tree), bvh, kdt, quadtree, octree
    - qs: Blink-Tree, Bw-tree
    - qs: BST
      sol: |
        1.左子树上所有结点的值均小于或等于它的根结点的值。
        2.右子树上所有结点的值均大于或等于它的根结点的值。
        3.左、右子树也分别为二叉排序树。


    - url: https://github.com/tidwall/btree
    - url: https://github.com/roy2220/bptree
      qs: root和branch不存储数据，只存储指针地址，数据全部存储在Leaf Node，同时Leaf Node之间用双向链表链接。每个Leaf Node是三部分组成的，即前驱指针p_prev，数据data以及后继指针p_next，同时数据data是有序的，默认是升序ASC，分布在B+tree右边的键值总是大于左边的，同时从root到每个Leaf的距离是相等的，也就是访问任何一个Leaf Node需要的IO是一样的，即索引树的高度Level + 1次IO操作。我们可以将MySQL中的索引可以看成一张小表，占用磁盘空间，创建索引的过程其实就是按照索引列排序的过程，先在sort_buffer_size进行排序，如果排序的数据量大，sort_buffer_size容量不下，就需要通过临时文件来排序，最重要的是通过索引可以避免排序操作（distinct，group by，order by）。
    - qs: "B+Tree的特点"
      sol: |
        B+树是一种平衡的多叉树数据结构，它能够有效地支持范围查询和快速的数据插入与删除操作。B+树的特点包括：

        1. 所有数据都存储在叶子节点上，而非叶子节点只存储索引信息，这样可以减少磁盘访问次数。
        2. 叶子节点之间通过指针连接成一个有序链表，方便范围查询操作。
        3. B+树的节点是有序的，每个节点都有一个上下界，使得查找操作可以快速定位到目标节点。
        4. B+树的高度相对较低，使得磁盘IO开销较小。
        由于B+树的特性，它在数据库系统中被广泛应用于索引的实现。MySQL默认使用B+树作为索引算法，无论是主键索引、唯一索引还是普通索引，都是基于B+树实现的。这使得MySQL能够高效地支持各种查询和数据操作，并提供良好的性能和可扩展性。
    - qs: "***BTree和B+Tree有啥区别? (非常重要的问题，类似问题还有，为啥InnoDB使用B+tree而不是BTree?)***"
      sol: |
        - B+ 树的叶子节点形成有序链表，使得范围查询更加高效。在数据库中，范围查询是非常常见的操作，因此 B+ 树更适合处理这类查询。
        - B+ 树的内部节点只存储索引信息，相比之下，B 树的内部节点也存储实际数据。这使得 B+ 树更加紧凑，可以存储更多的索引数据在内存中，提高查询性能。
        - B+ 树的有序链表叶子节点可以更好地支持顺序访问，对于按顺序获取数据的查询操作，B+ 树的性能更好。
         综上所述，MySQL 选择使用 B+ 树作为其存储引擎是为了提高范围查询和顺序访问的性能，并且能够更好地利用内存空间。


    - url: https://github.com/golang-infrastructure/go-domain-suffix-trie
      qs: 后缀树的使用场景：比如域名匹配
    - qs: How to implement suffix-tree?
    - qs: What's the key feats and benefits of suffix-tree, compare with RBT?
    - qs: suffix-tree的使用场景
    - url: https://github.com/eileen-code4fun/LSM-Tree
      qs: Log Structured-Merge Tree. 磁盘顺序写.
    - qs: LSM-Tree是如何提高写性能的？
      sol: LSM 通过充分利用磁盘批量顺序写的优势来提高写性能。与传统的B+树或ISAM相比，LSM-Tree通过消除随机的本地更新操作，以追加的方式写入数据，这种方式的写入性能远高于随机写。
    - qs: LSM-Tree的结构有哪些特点？
      sol: LSM 是一种分层、有序、面向磁盘的数据结构。它由内存中的Memtable和多层磁盘上的SSTable（Sorted String Table）组成。写入数据时，首先写入WAL日志保证持久化，然后写入Memtable。当Memtable达到一定大小后，它会冻结并成为不可变的Memtable，同时生成新的Memtable继续接收写入。随后，冻结的Memtable会被dump到磁盘上的SSTable层，这个过程称为Minor Compaction。磁盘上的SSTable会定期进行Major Compaction，合并数据并清除被标记删除的数据。
    - qs: LSM-Tree在读操作上有哪些优化？
      sol: 为了支持更复杂和高效的读取，LSM-Tree采用了多种优化策略：压缩SSTable以提高读取效率，缓存Scan的Block以减少磁盘IO，使用Bloom filters减少不必要的磁盘扫描，以及定期的合并操作（Major Compaction）来瘦身和优化数据存储。
    - qs: 为什么LSM-Tree不适合原地更新和删除操作？
      sol: 由于LSM-Tree的设计是基于追加写入的，它不能直接在原地更新或删除数据。真正的更新和删除操作只能在Compaction过程中进行，这意味着LSM-Tree对事务的支持较弱，因为它不能保证在一个Page或Block中实时更新一个key的数据。
    - qs: LSM相比B+Tree的优缺点
      sol: LSM-Tree的优点是支持高吞吐的写操作，适合写多读少的场景，特别是在大数据领域。而B+树的优点是支持高效的读操作，适合读操作频繁的场景。但是，B+树在面对大规模写请求时效率较低，因为它需要维护树结构，涉及到节点的分裂和合并，增加了随机读写的概率。
    - url: https://github.com/paritytech/trie
      qs: trie-tree(dict-tree, prefix-tree, radix-tree)
    - url: https://github.com/gammazero/radixtree
    - url: https://github.com/beevik/prefixtree
    - url: https://github.com/alexkappa/exp
      qs: Binary Expression Tree
    - url: https://github.com/petar/GoLLRB






---


- type: Hash
  tag: &tag Algo
  repo:
    - url: https://github.com/spaolacci/murmur3
      des: MurmurHash = mu(multiply) + r(rotate). murmurhash是现在比较常用的一种hash算法，不少开源的布隆过滤器实现都是采用了murmurhash算法来实现。murmurhash算法的名字来源于它的两个重要操作MU（multiply）以及R（Rotate），它在设计上并不是为了密码学上增加单向加密的难度，所以它不适用于安全领域。如果是向做一个快速的hash且希望hash碰撞满足预设指标的话，murmurhash是一个不错的hash算法。
    - qs: Compare hash algo (murmurhash, CityHash, xxHash, FNV, SpookyHash, maphash, crc32, crc64)
      sol: 单向性，抗冲突，映射分布均匀性, 差分分布均匀性 (strong anti-collision, resistance to modification, )
    - qs: How it works?
    - qs: Compare pros and cons respectively.
    - qs: How to design hash algo?
    - qs: "***Why the load factor of redis's hashmap set to 1, while golang map is set to 0.8?***"
      sol: |
        LF的选择对性能有很大影响。较低的LF会减少冲突的概率，但会增加内存的浪费；较高的LF则会节省内存空间，但可能导致性能下降。。redis的hashmap与list类似，仍然是按需扩容，而不“预扩容”，这点与golang不同，golang都是预扩容
        对于OA而言，它只有数组一种数据结构就可完成存储，继承了数组的优点，对 CPU 缓存友好，易于序列化操作。但是它对内存的利用率不如CA，且发生冲突时代价更高。当数据量明确、LF小，适合采用OA。
        链表节点可以在需要时再创建，不必像OA那样事先申请好足够内存，因此CA对于内存的利用率会比OA高。CA对LF的容忍度会更高，并且适合存储大对象、大数据量的哈希表。而且相较于OA，它更加灵活，支持更多的优化策略，比如可采用红黑树代替链表。但是CA需要额外的空间来存储指针。
        值得一提的是，在 Python 中 dict 在发生哈希冲突时采用的OA，而 java 的 HashMap 采用的是CA。
        *这是为啥golang的map的load factor是固定的0.8，因为golang的map使用CA来解决哈希冲突。如果使用open addressing的话，就需要动态调整load factor了。*
        总结：OA适合数据量小、LF小、不易发生collision的场景。除此之外都应该使用CA。
    - url: https://github.com/Cyan4973/xxHash
    - url: https://github.com/cespare/xxhash
    - url: https://github.com/tkaitchuck/aHash
    - url: https://github.com/yanyiwu/simhash
      qs: 处理海量网页采用的文本相似判定方法。算法的主要思想是降维，将高维的特征向量映射成一个f-bit的指纹(fingerprint)，通过比较两篇文章的f-bit指纹的Hamming Distance来确定文章是否重复或者高度近似。


# 哈希的本质是某种“摘要算法”，或者说“压缩映射”（把任意长度的数据往固定长度上映射）。所以说之前想画个图把什么哈希查找、哈希加密、DHT、LSH这些哈希算法都整理起来，是很蠢的想法。这些东西本身就是“哈希”这种思想在不同方面的应用。哈希是一种思想，一种“压缩映射”的思想，把“无限数据”压缩为几乎不会重复的“有限数据”。



#         - topic: hash collision
#          qs:
#            - qs: How to resolve hash collision? 能否对比OA和CA在解决collision时的优缺点?
#              sol: 通常我们都使用OA来解决哈希冲突问题，如果拿电影院座位来类比collision的话，我们发现自己的位置已被占用，OH就是在某个位置拒绝了之后，逐个往后看是否有空位，CA则是直接坐在这个位置旁边。
#            - qs: open addressing 开链 (Double hashing, Linear probing(hard to delete key), Random hashing(high cost), Quadratic Probing)
#              sol: Double hashing相当于让电影院重新安排座位(用第二个hash func重新计算). Random hashing相当于随便找个空位. Quadratic Probing相当于backoff了，更快找到空位
#            - qs: close addressing 闭链 (Separate chaining)
#              sol: close hashing就像现在96号车位已经被占用了，那就给96号车位再建造一个小车库，所有应该停在96号车位的就都停在这个小车库里。

- type: DHT-hash
  tag: *tag
  repo:
    - url: https://github.com/libp2p/go-libp2p-kad-dht
      qs: kad-dht
    - url: https://github.com/tysonmote/rendezvous
      qs: rendezvous
    - qs: Compare DHT like (Consistent Hashing(hash ring), CARP(Cache Array Route Protocol), chord(Local Resilient Hashing), HRW, KAD, Rendezvous).
    - qs: Compare traditional hash and DHT?
      sol: balance, monotonicity, spread, load, smooth
    - qs: How does CH achieve balance through virtual nodes?
    - qs: How to implement DFA using trie tree in golang?




- type: bloomfilter
  tag: *tag
  repo:
    - url: https://github.com/bits-and-blooms/bloom
      qs: bloomfilter in golang, used by Milvus and Beego.
      use:
        - url: https://gist.github.com/hxhac/e0a9774d79d3340dee6c6bcd35f82bad
        - url: https://gist.github.com/hxhac/7b64f460ada820fd4467734fd9fe2e37
    - url: https://github.com/RedisBloom/redisbloom-go
    - url: https://github.com/alovn/go-bloomfilter
      qs: 比 hugh2632/bloomfilter 的实现更好
    - url: https://github.com/linvon/cuckoo-filter
      des: 布谷鸟过滤器
      qs: cuckoo为啥比bloomfilter更好?
      sol: 相比于 BF，CF 支持动态删除元素，更快的查找性能，空间开销更小。并且比其他过滤器方案（比如说 quotient filter）要更好实现。
    - url: https://github.com/seiflotfy/cuckoofilter
      qs: cuckoo-filter
    - qs: Implement BloomFilter (bitmap+)
    - qs: BF 有哪些使用场景？
      sol: 归根到底，是查重或者判断是否存在这两个使用场景。比如判断用户是否存在、是否重复购买、防止缓存穿透、敏感词过滤、爬虫URL去重
    - qs: BF 有哪些优缺点? (FPR)
    - qs: BF 的查询和写入流程？
    - qs: 怎么优化 BF？有哪些常见的bloomfilter变体？分别说明其实现方法和使用场景
      sol: Counting filters, Cache Filtering, Bloomier filters, Layered Bloom filters, ...

# des: bf = bitmap + hash. (核心就是构造 BloomFilter 结构体，搞个创建多个 hash 函数的方法，然后构造函数里调用) # 布隆过滤器是一个由「bit 类型数组」和「一些 hash 函数」组成的高效数据结构。核心流程是一个元素映射到布隆过滤器时，元素会被每个 hash 函数进行 hash 映射，每次映射出 bit 位数组下标后就会将其标记，所以一个元素可能会占用多个下标，多个元素因为哈希碰撞可能会共用同个下标。


- type: backoff
  tag: *tag
  repo:
    - url: https://github.com/cenkalti/backoff
      qs: 可以理解为某种interval的TCP window的AIMD。具体来说就是，指数退避算法会利用抖动（随机延迟）来防止连续的冲突，每次间隔的时间都是指数上升，以避免同一时间有很多请求在重试可能会造成无意义的请求。
    - url: https://github.com/avast/retry-go
      des: |
        retry
        通过 retry.OnRetry(func) 可以获得当前重试次数
        且支持backoff, random 等重试机制
      qs: 怎么获取当前attempts



- type: FTS
  tag: *tag
  repo:
    - url: https://github.com/akrylysov/simplefts
      qs: How to implement FTS using inverted index? Pretty good code.
    - url: https://github.com/quickwit-oss/tantivy
      qs: FTS inspired by Apache Lucene and written in Rust.


- type: Page-Replacement-Algo
  tag: *tag
  repo:
    - url: https://github.com/hashicorp/golang-lru
      qs: LRU/LFU
    - url: https://github.com/moovweb/go-cache
      qs: ARC = Adaptive Replacement Cache
    - url: https://github.com/ghulamghousdev/Clock-Replacement-Algorithm
    - qs: "***Implement LRU***"
      sol: (DLL(MoveToFront())+HashMap) 使用 HashMap 作为数据存储，把DLL本身的数据作为 HashMap 的 key 使用（既能排序又是基于hash的ds），这样可以直接获取 value。DLL要遍历才能查到某个 key 对应的 value，使用HashMap O(1)
    - qs: LFUDA = LFU Dynamic Aging
    - qs: Approximated LRU (second chance)
    - qs: 几种常见的variants，比如 LRU-DA, Approximated LRU, LRU-K, 2Q(LRU-2), ARC 的区别
      sol: |
        主要区别在于它们如何处理页面访问历史和如何做出置换决策。LRU-DA和近似LRU减少存储需求，LRU-K和2Q简化决策过程，而ARC则自适应调整以提高效率。

         LRU 理想算法，选择最久未使用的页面进行替换，但需要查询完整记录，开销很大。
         LRU-DA 限制访问记录长度，减少空间需求，但可能不如完整LRU准确。
         Approximated LRU 简化版LRU，使用时间戳或计数器近似模拟，减少实现复杂性。
         LRU-K 维护一个短期访问列表，快速选择置换候选页面，减少置换频率。
         2Q (Two-Queue) 分为两个队列处理最近和不经常访问的页面，简化决策过程。
         ARC 自适应算法，结合时钟算法和LRU-K，动态调整参数以优化性能。
    - qs: 能否给我讲讲Page Replacement Algo的second chance？是不是redis的approximeted LRU就是基于second chance实现的？
      sol: |
        我喜欢写笔记，但是我要求我的文档不能超过1w行，所以需要删除部分内容
        LRU：删除最久未编辑的笔记行，这需要您回顾整篇文档来找到那个最久未动的笔记行，准确但开销较大。
        LRU-DA：只回顾最近编辑的一部分笔记行来决定删除哪些，这减少了您需要检查的笔记数量，空间需求减少但可能不够准确。
        Approximated LRU：使用笔记旁边的时间戳或编辑次数来近似判断哪些笔记行不常用，简化了判断过程。
        LRU-K：维护一个短期编辑的笔记行列表，当需要删除笔记行时，优先考虑这个列表中的行，减少您需要考虑的笔记行数量
        2Q：将笔记行分为“最近编辑”和“不常编辑”两组，当需要删除笔记行时，先查看“不常编辑”的组，简化了决策过程
        ARC：结合多种策略，比如最近编辑频率和编辑时间，动态决定哪些笔记行可以删除，自适应调整以优化文档内容。


#   qs: PRA的核心思想是根据数据项的访问历史来预测未来的行为，从而选择最不可能被再次使用的数据项进行替换。可以看到很多置换算法和scheduler算法是类似的，是因为两者都涉及到在有限资源的环境下做出决策，以优化系统的整体性能。。然而，它们在目标、应用场景和实现机制上有所不同。置换算法主要用于操作系统中的虚拟内存管理。它们的目标是在物理内存有限的情况下，高效地管理内存页的置换，以减少页面错误（page faults）并提高内存的使用效率。




- type: Compression-Algo
  tag: *tag
  repo:
    - url: https://github.com/klauspost/compress
    - url: https://github.com/facebook/zstd
    - url: https://github.com/lz4/lz4
    - url: https://github.com/mcmilk/7-Zip-zstd
    - qs: 为啥不同压缩算法的通用性比较差，需要针对各种场景来进行优化?
    - qs: Compare compression algo (deflate, brotil, compress, snappy, gzip, lz4).


# qs: DCA 也可以认为是CFT (Crash Fault Tolerance) 算法，用来解决BFT问题的
- type: Distributed-Consensus-Algo
  tag: *tag
  repo:
    - qs: "***比较几种常见的分布式协议 (raft, gossip, paxos, zab, QuorumNWR)***"
      sol: |
        consistency, msg methods, elect, tolerance https://www.luozhiyun.com/archives/304
         paxos：我保证一旦观察到被多数承认的确定状态则该状态将一直有效。
         raft：都选我，只要大多数人承认我是头那我就把自己当头。
         zab：a：快告诉我谁是头？b：我告诉你现在我看到谁是头。a：大家认为谁是头我就认为谁是头。
         gossip: 嘿，我听说那个谁现在是头儿了，真的吗？让我去确认一下


- type: raft
  tag: *tag
  repo:
    - qs: Implement RAFT algo
      sol: (Id, IsLeader, term(logic timestamp))
    - qs: (Leader, Follower, Candidate), term, Raft 中服务器之间所有类型的通信通过两个 RPC 调用(RequestVote 用于选举, AppendEntries(一致性检查) 用于复制 log 和发送心跳)
    - qs: raft算法是啥？有哪些特性？
      sol: “raft 证明和 paxos 等价，raft 天生就是 paxos 协议的工程化”，raft相当于paxos的实现，也是BFT问题的解决方案
    - qs: raft算法的具体流程（把共识算法拆分成哪三个独立子问题？）
      sol: leader选举 + 主从日志复制 + 集群容错的安全性
    - qs: raft 算法与普通的共识算法相比，有哪些特性？
      sol: strong leader + leader election + membership changes
    - qs: raft 算法中`leader 选举`和`日志复制`的流程？
    - qs: raft 算法怎么保证`安全性`？
    - qs: raft 算法的`Figure8 问题`是什么？
    - qs: 通过raft日志的index和term来确保该日志唯一
    # [条分缕析 Raft 算法](https://mp.weixin.qq.com/s?__biz=MzIwODA2NjIxOA==&mid=2247484140&idx=1&sn=37876b5dda5294ea7f6211f0a3300ea5#tocbar-1plmehi)
    - url: https://github.com/hashicorp/raft
    - url: https://github.com/hashicorp/raft-wal
    - url: https://github.com/hashicorp/raft-boltdb
      qs: raft是separate storage设计，更灵活，可以在不同使用场景下使用各自最优的storage

- type: gossip
  tag: *tag
  repo:
    - url: https://github.com/hashicorp/memberlist
      qs: memberlist, gossip based membership and failure detection. 使用 gossip 协议来管理集群成员资格和节点故障检测。memberlist 通过在集群中的节点之间传播成员信息和故障报告，来维护集群的成员列表和状态。memberlist 通过引入一些额外的机制（如 Lifeguard 扩展），来提高协议在处理慢速消息处理、网络延迟或丢包等问题时的鲁棒性。
    - url: https://github.com/libopenstorage/gossip
    - qs: What's gossip, feats?
      sol: 随机性, 反熵Anti-Entropy, 最终一致性EC, 容错性, 去中心化
    - qs: How it works?
    - qs: gossip中的Anti-Entropy和Rumor-Mongering有啥区别?
    - qs: 哪些常用服务用到了gossip?
      sol: Cassandra, redis-cluster, consul. etcd和zk各自的主协议虽然是raft和zk，但是也用到gossip进行node之间通信
    - qs: gossip相比于raft，更适用于哪些场景? 性能、EC、弹性


- type: TimeWheel
  tag: *tag
  repo:
    - url: https://github.com/antlabs/timer
      qs: 最小堆实现的5级时间轮


- type: TopK
  tag: *tag
  repo:
    - url: https://github.com/DinghaoLI/TopK-URL
    - url: https://github.com/axiomhq/topkapi
    - url: https://github.com/segmentio/topk
    - qs: 10 亿的数据，每个文件 1000 万行，共 100 个文件，找出前 1 万大
    - qs: 求一个数组的中位数？用快速中位数算法或者最小堆
    - qs: 从 1000 万个数字中选择出 1000 最大的数。3 种方法，排序，再选前 1000 个，堆，快排
    - qs: 从海量数据 (int 数据类型) 中找到前 50 的数字
    - qs: 亿级数据里查找相同的字符以及出现次数
    - qs: 给你一个 1T 的文件，里面都是 IP 字段，需要对这个文件基于 IP 地址从小到大进行排序？
    - qs: 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前 10 个词，请给出思想，给出时间复杂度分析。
    - qs: 给出 N 个单词组成的熟词表，以及一篇全用小写英文书写的文章，请你按最早出现的顺序写出所有不在熟词表中的生词。
    - qs: 手写 TopK 算法：从 100 万条字符串中，找出出现频率最高的 10 条？（比如在搜索引擎中，统计搜索最热门的 10 个查询词；在歌曲库中统计下载最高的前 10 首歌等）
    - qs: 100GB url 文件，使用 1GB 内存计算出出现次数 top100 的 url 和出现的次数？尽量减少 sys call 和 IO。尽力使用完已给资源。
    - qs: 搜索引擎会通过日志文件把用户每次检索使用的字符串记录下来，每个查询串的长度为 1~255B。假设目前有 1000 万个记录（这些查询串的复杂度比较高，虽然总数是 1000 万，但如果出去重复后，那么不超过 300 万个。一个查询串的复杂度越高，说明查询它的用户越多，也就是越热门的 10 个查询串，要求使用的内存不能超过 1GB
    - qs: 有 10 个文件，每个文件 1GB，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。按照 query 的频度排序。
    - qs: 有一个 1GB 大小的文件，里面的每一行是一个词，词的大小不超过 16 个字节，内存限制大小是 1MB。返回频数最高的 100 个词。
    - qs: 提取某日访问网站次数最多的那个 IP。
    - qs: 10 亿个整数找出重复次数最多的 100 个整数。
    - qs: 搜索的输入信息是一个字符串，统计 300 万条输入信息中最热门的前 10 条，每次输入的一个字符串为不超过 255B，内存使用只有 1GB。
    - qs: 有 1000 万个身份证号以及他们对应的数据，身份证号可能重复，找出出现次数最多的身份证号。





- type: Reliability-Algo
  tag: *tag
  repo:
    - url: https://github.com/go-shiori/go-readability
      qs: Extract content from HTML. 可以理解为对mozilla readability算法的实现，或者说某种之前青南的那种GeneralNewsExtractor.
    - url: https://github.com/mozilla/readability
      qs: 基本原理就是通过遍历Dom之后，通过正则提取其中的内容，对不同标签有不同加权和降权，然后把div标签替换为p标签，重新遍历，计分。最后根据分值，重新拼接内容。Mozilla Ecosystem for readability, Fathom vs Mercury vs Readability.
    - url: https://github.com/go-kratos/aegis
    - url: https://github.com/GeneralNewsExtractor/GeneralNewsExtractor
      qs: GNE
    - url: https://github.com/extractus/article-extractor
      qs: 类似GNE. To extract main article from given URL with Node.js.


# 路径规划器，查找现实地理地址的最短距离
- type: OSRM
  tag: *tag
  repo:
    - url: https://github.com/Project-OSRM/osrm-backend
      qs: OSRM
    - url: https://github.com/perliedman/geojson-path-finder
      qs: 输入GeoJSON格式的地理数据，通过构建网络拓扑结构和路径算法来计算两个地理位置之间的最短距离。用来实现导航、路线规划和地理空间分析等应用非常有用。根据您提供的起始点、目标点和地理数据，geojson-path-finder会会决定具体使用Dijkstra算法还是A*算法来计算shortest-path


# qs: "多线程轮流打印问题(固定值打印和非固定值打印)" # 这几个都可以分别用 chan、mutex、wg和atomic实现一下
- type: 多线程轮流打印问题
  tag: *tag
  repo:
    - qs: 假设有 4 个协程，分别编号为 1/2/3/4，每秒钟会有一个协程打印出自己的编号，现在要求输出编号总是按照 1/2/3/4 这样的顺序打印，共打印 100 次
    - qs: 编写一个程序，开启 3 个线程，这 3 个线程的 ID 分别为 A、B、C，每个线程将自己的 ID 在屏幕上打印 10 遍，要求输出结果必须按 ABC 的顺序显示；如：ABCABC...依次递推
    - qs: 轮流打印 dog pig cat，共打印 10 次？
    - qs: 两个人 bob 和 annie，互相喊对方的名字 10 次后，最终 bob 对 annie 说 bye bye？
    - qs: 10 个线程依次打印 1-10,11-20 和到 100？
    - qs: 三个线程交替打印至 100：线程 1 打印 1、4、7，线程 2 打印 2、5、8，线程 3 打印 3、6、9，一直打印到 100 结束
    - qs: 如何让 10 个线程按照顺序打印 0123456789？
    - qs: 怎么开 10 个线程，每个线程打印 1000 个数字，要按照顺序从 1 打印到 1w？
    - qs: 用五个线程，顺序打印数字 1~无穷大，其中每 5 个数字为 1 组，如下：其中 id 代表线程的 id
    - qs: 使用两个协程交替打印序列，一个协程打印数字，另一个协程打印字母，最终效果如下`1A2B...26Z`
    - qs: 用三个线程，顺序打印字母 A-Z，输出结果是 1A 2B 3C 1D 2E...打印完毕最后输出一个 OK
    - qs: ~~实现两个协程，其中一个产生随机数并写入到 chan 中，另一个从 chan 中读取，并打印出来，最终输出 5 个随机数~~
    - qs: 给一个数组，并发交替打印奇数和偶数，请分别用 chan、sync 和原子操作实现？
    - qs: golang channel交替打印数字和字母，比如 1A2B...26Z
      url: https://go.dev/play/p/MbuQWq-kwl8
    - qs: 4个goroutine轮流打印1/2/3/4，共打印100次
      url: https://go.dev/play/p/qbZsYAKlj07





- type: sort
  tag: *tag
  repo:
    - qs: "@quick-sort"
      url: https://gist.github.com/hxhac/7e1b177bab0528d6f0a87717cd136be7
    - qs: 为什么快排是最常用的排序算法？和堆排和归并排序进行比较？三种排序算法分别的适用场景？
    - qs: (comparison sorts, non-comparison sorts)
    - qs: Compare quicksort, heapsort, mergesort # is_stable, complexity
    - qs: How to implement quicksort? # (dividing+recursive) (define pivot, lt, gt. then, traverse arr and set data to lt and data. finally, append data.)
    - qs: 说下快排的大概的操作过程？快排的平均的时间复杂度？快排什么情况下是最慢的？
    - qs: heapsort 堆排序 # Asymptotically optimal
    - qs: sort (bubble, selection)
      url: https://gist.github.com/hxhac/5f5ee18ac40dfd1efcf180d98c3b7c0b
    - qs: merge sort
      url: https://gist.github.com/hxhac/30c9b8883d764f52e34b0ab883a2b141
    - qs: 快排 quicksort 实现TopK
      url: https://go.dev/play/p/d91W5fi31zo
    - qs: heap sort实现TopK
      url: https://go.dev/play/p/hYMtKaeP84f
    - qs: 插入排序
      url: https://go.dev/play/p/Sxa1ovXRnYt





#  What's bit-manipulation? (used to operate binary) operations? (or(&), and(|), xor(^), and not(&^))
#
#  sliding-window
#
#  How does file compression algo(such as gzip, bz, rar, deflate, brotil, snappy, etc.) works? Are there any similarities?

#  data structure (linear, tree, graph, bitmap)




#    - qs: 有哪些常用的调度算法？分别是怎么实现的？请实现。有哪些需要使用调度算法的使用场景？这些场景分别使用什么调度算法？
#    - qs: 有哪些经典的动态规划问题？（背包问题（0-1背包、完全背包）、爬楼梯、不同路径、零钱兑换、打家劫舍、编辑距离、斐波那契数）



- type: 并发问题
  tag: *tag
  repo:
    - qs: Dining Philosophers Problem
      url: https://go.dev/play/p/oqBoIin8Y5l
    - qs: Banker's Algo, deadlock

# - Dining philosophers, deadlock.
#- 产生死锁的原因？产生死锁的4个必要条件？有哪些形象的类比？ 相互排斥、等待条件、没有抢占、循环等待 # 我说说我的理解哈，有 x 和 y 两个人，同时有 x 和 y 两个门，本来 x 拿着 x 钥匙进入 x 门，y 同样进入 y 门就可以了。那么死锁是怎么回事呢？x 和 y 都想进入 x 门，这就是互斥（x 门只能让 x 或者 y 其中一个人进入）。两个人都各自有一把钥匙了，但是又想要对方的那把钥匙（这个就是请求保持条件）。只能这两个人自己主动释放，没有其他人出来协调资源（这个就是不可剥夺）。两个人都在等对方主动让出钥匙（这个就是循环等待条件）。其实想想，不就是生活中大部分吵架打架不就是这么来的吗？这个就是死锁





- type: Encryption
  tag: *tag
  repo:
    - qs: Compare Symmetric and Asymmetric Key Encryption?
    - qs: "@symmetric-encryption"
    - qs: Compare symmetric encryption (DES, 3DES, AES, Blowfish, RC4, RC5, RC6)? # types
    - qs: types (stream ciphers, block ciphers)
    - qs: block ciphers (ECB, CBC, CFB, ...)
    - qs: How to implement a symmetric encryption??? (XOR)
    - qs: "@base64"
    - qs: How to implement base64?
    - qs: base64的原理？（base64怎么保证数据的完整性？）
    - qs: Why is base64 encoding needed? Why can base64 ensure data integrity? # (38, 64, 0, =)
    - qs: "@RSA"
    - qs: How to implement RSA??? (Diffie-Hellman) # 密钥交换算法的模幂运算，正向计算简单，逆向求解困难
    - qs: "***What is the process of RSA+AES hybrid encryption?***"




- type: golang笔试题
  tag: *tag
  repo:
    - qs: 怎么使用 golang 实现 java 的迭代器？想要支持所有 golang 类型，怎么封装
    - qs: timewheel
      doc: https://github.com/wuYin/timewheel
    - qs: 怎么实现 gin 的路由算法
    - qs: 怎么实现 gin 的中间件

    - qs: 怎么使用 golang 实现 wrr 算法？加权轮询算法(wrr). 几种实现方法 random, RBT, LVS, nginx
      url: https://github.com/wenj91/wrr
      doc: https://mp.weixin.qq.com/s?__biz=MzA4MTc4NTUxNQ==&mid=2650525165&idx=1&sn=136bf923194c8dea95f603c7b83baf57
      sol: |
        raft 和 wrr 感觉很像
        都是对 nodes 中多 node 的调度，wrr 有随机、LVS、nginx 好几种调度策略，实际上我现在这个 raft 里的选举不就是直接随机了吗？


    - qs: 怎么自己实现阻塞读并且并发安全的 map
      sol:

    - qs: 手写 retry 方法（retry 里面的 func）？核心是什么？
      doc: https://medium.com/@wojtekplatek529/go-worker-pool-with-retry-and-timeout-0e072acf8726
      url: https://go.dev/play/p/UTRnHf9zAjW
      sol: 设计Retry函数，三个参数嘛 max_attempts, func, sleep_time.


    - qs: slice of map 怎么去重（里面的 map）？核心是什么？
      sol: 还是很简单，直接把这个slice of map

    - qs: 用 golang 手写 redis 的 pub/sub？至少给出伪代码
    - qs: 写一个 golang 爬虫，自动伸缩，自适应流控，也就是说在对方限流时就减少并发数，没有限制时使用最大并发数？类似 TCP 的滑动窗口

    - qs: 检验字符串是一个回文字符串
      sol: O(n/2). fori 只需要遍历len/2就可以了，然后对比 res[i] != res[len-i-1] 即可


    - qs: 手写怎么用 chan 实现定时器
      doc: https://juejin.cn/post/7113553728954695693
      sol: time.NewTicker + for死循环 就ok了
    - qs: 实现一个 hashmap，解决 hash 冲突问题，解决 hash 倾斜问题？
      sol:
    - qs: golang 用 chan 实现排序（快排和归并排序
      doc: https://zhuanlan.zhihu.com/p/47383158
    - qs: 单链表和双链表的反转
      sol:
    - qs: 数组中有N+2个数，其中，N个数出现了偶数次，2个数出现了奇数次（这两个数不相等），请用O(1)的空间复杂度，找出这两个数。
      doc: https://zhuanlan.zhihu.com/p/373580530
      sol: 两种方法，hash法或者xor法，推荐hash法。也就是直接把array转hashmap，然后

    - qs: 数组中出现次数超过一半的数字
      sol: 很简单，直接array转hashmap（模拟PHP的array_count_values()），然后再遍历这个map判断一下就ok了

    - qs: 链表相加 [leetcode 链表相加 - 知乎](https://zhuanlan.zhihu.com/p/480342701)
    - qs: 手写“哲学家就餐问题”？

    # https://gist.github.com/hxhac/c1f5bf780fe968ebc3a56af86aeb90a8
    - qs: 使用 chan 下载远程文件，在控制台打印进度条
      url: https://gist.github.com/hxhac/b81e4a21a399567c7d8428709b168349


    - qs: 怎么实现单文件分块并发下载？
      url: https://go.dev/play/p/sVTuMqf6ZHv


    - qs: 并发去 ping n 个网站，最多重试 3 次，怎么提升该场景的性能
      sol: 其实就是


    - qs: 翻转字符串
      sol: 字符串先转 `[]rune()` 才能修改，否则是只读类型。其次以字符串⻓度的 1/2 为轴，前后赋值(str[l-1-i])。

    - qs: 翻转slice。能否用golang generics实现一个兼容string和int的SliceReverse的函数？
      url: https://gist.github.com/hxhac/f5f701cc3d2ae56eda905ce66bb3c7af
      sol: 方法很多，slices.Reverse()可以直接翻转。直接用fori双迭代器 + 直接交换，是最通用的实现。

    - qs: 判断两个给定的字符串排序后是否一致
      sol: O(n). 给定两个字符串，判断其中一个字符串的字符重新排列后，是否能变为另一个字符串。只需要一次循环遍历 s1 中的字符在 s2 是否都存在(strings.Contains())即可


    - qs: 实现阻塞读的并发安全Map
      url: https://gist.github.com/hxhac/0edf5f9f056d8199092876ca1bef8ead

    - qs: 高并发下的锁与map读写问题
    - qs: 为 sync.WaitGroup 中Wait函数支持 WaitTimeout 功能.
    - qs: 手撕代码生产者消费者模型
    - qs: 写个递归实现无限级分类
    - qs: 写一个验证标准 ipv4 的算法
    - qs: LB
      url: https://go.dev/play/p/7I7Ya3281fW
    - qs: 反向层序遍历二叉树
      url: https://go.dev/play/p/uNepsMLbeqp
    - qs: 反转链表
      url: https://go.dev/play/p/1dhO_6uGasT

    - qs: ???
      url: https://go.dev/play/p/hlzzGprVuxn

    - qs: convert to base7
      url: https://gist.github.com/hxhac/98339e52845bd88c367e0f4055893dda

    - qs: gossip
      url: https://gist.github.com/hxhac/164eec10b3fa3400f91e9cd44ec6a9bf
    - qs: snowflake
      url: https://gist.github.com/hxhac/d20944641ffcfe7ee776b21636a8b415

    - qs: 在线聊天服务
      url: https://gist.github.com/hxhac/ffbdc0100cb5fcf985427302e7d3321f
    - qs: url使用url.URL定义，而不是string，方便操作
      url: https://go.dev/play/p/CTbEqYxRSoK
    - qs: LRU
      url: https://go.dev/play/p/G5HXveY6I_v


    - qs: RingBuffer实现
      url: https://go.dev/play/p/uHZDuVYlET0

# [利用多线程在 Go 中更快地读取大文件 - 知乎](https://zhuanlan.zhihu.com/p/96898995)


# 并发笔试题
# - [lengocgiang/trivial_concurrency_exercises](https://github.com/lengocgiang/trivial_concurrency_exercises)
#- [mtyurt/go-concurrency-exercise: Solutions to Golang concurrency exercises](https://github.com/mtyurt/go-concurrency-exercise)
#- daily-walk
#- dinner
#- internet-cafe




- type: Search Algo
  tag: *tag
  repo:
    - qs: "@binary search algo"
    - qs: bs, bsc (binary-search)
      url: https://gist.github.com/hxhac/3ca15e0f80245836b8b2b3e8ee44196c
      doc: https://mp.weixin.qq.com/s?__biz=MzAxODQxMDM0Mw==&mid=2247485044&idx=1&sn=e6b95782141c17abe206bfe2323a4226
    - qs: "*Compare these common search-algo?*"
    - qs: 分别实现二分查找和哈希查找。用二分查找实现一个数在数组里出现的次数？
    - qs: 二分查找，一个数在数组里出现的次数？
      #除了数组 nums 外，还需要 num/low/high 三个参数
      #计算出中间元素 mid 后，判断待查找元素是否大于中间元素`nums[mid]`
      #如果大于，就往右区间查找
      #如果小于，就往左区间查找



#  // 2.Largest number
#  // 2.1 Given a list of non negative integers, arrange them such that they form the largest number. (You may implement your program in pseudocode or any programming language.)


#  // 1.Prime Factor Statistics
#  // Given a positive integer N, you need to factorize all integers between (1, N].Then you have to count the number of the total prime numbers.


#- 字符串之实现 Sunday 匹配
#- 字符串泄漏之反转字符串(301)
#- 字符串中的第一个唯一字符
#- 字符串之验证回文串
#- 滑动窗口最大值
#- 最长公共前缀
#- 两个数组的交集
#- 最接近的三数之和



# - 手写`胜者为王模式`多个协程对同一份资源进行处理，只要有一个协程完成了，我们就直接返回结果”。从而减少耗时，提高成功率。比如，一张图片存在 5 台 OSS 上，怎么加速获取呢？我们就可以开 5 个协程，同时获取这张图片，谁获取到了就使用谁的
#- 怎么用最快速度请求某个接口？
#- 手写`最终成功模式`，使用场景是，我们需要在 10 个文件中成功读取 7 个，怎么加速呢？最好的方式是，获取文件失败，就获取下一个，只要获取了 7 个，就直接返回
#- 要求我们在最短时间内抓取到某个新闻网站中的 1000 篇新闻详情，怎么实现？